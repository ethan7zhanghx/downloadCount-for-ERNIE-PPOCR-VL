#!/usr/bin/env python3
"""
å›å¡«1æœˆ16æ—¥æ‰€æœ‰è¡ç”Ÿæ¨¡å‹åˆ°å…¶last_modifiedæ—¥æœŸ

å¯¹äº2026-01-16è·å–çš„æ‰€æœ‰AI Studioå’ŒModelScopeè¡ç”Ÿæ¨¡å‹ï¼Œ
åªè¦last_modifiedæ—©äº2026-01-16ï¼Œå°±å›å¡«åˆ°last_modifiedæ—¥æœŸã€‚
"""

import sqlite3
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from ernie_tracker.config import DB_PATH, DATA_TABLE


def backfill_all_jan16_models():
    """å›å¡«1æœˆ16æ—¥æ‰€æœ‰è¡ç”Ÿæ¨¡å‹"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    target_date = '2026-01-16'
    target_repos = ['AI Studio', 'ModelScope']
    target_categories = ['ernie-4.5', 'paddleocr-vl']
    target_types = ['finetune', 'quantized', 'adapter', 'lora', 'merge']

    print("ğŸš€ å¼€å§‹å›å¡«1æœˆ16æ—¥æ‰€æœ‰è¡ç”Ÿæ¨¡å‹...")
    print(f"ç›®æ ‡æ—¥æœŸ: {target_date}")
    print()

    # è·å–1æœˆ16æ—¥çš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼ˆå»é‡ï¼‰
    print("Step 1: è·å–1æœˆ16æ—¥çš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹...")
    cursor.execute(f"""
        SELECT
            MAX(rowid) as rowid,
            repo,
            model_name,
            publisher,
            download_count,
            model_type,
            model_category,
            tags,
            base_model,
            data_source,
            likes,
            library_name,
            pipeline_tag,
            created_at,
            last_modified,
            fetched_at,
            base_model_from_api,
            search_keyword,
            url
        FROM {DATA_TABLE}
        WHERE date = ?
        AND repo IN ({','.join(['?' for _ in target_repos])})
        AND model_category IN ({','.join(['?' for _ in target_categories])})
        AND model_type IN ({','.join(['?' for _ in target_types])})
        GROUP BY repo, model_name
    """, [target_date] + target_repos + target_categories + target_types)

    target_records = cursor.fetchall()
    print(f"âœ… æ‰¾åˆ° {len(target_records)} ä¸ªè¡ç”Ÿæ¨¡å‹\n")

    # å¼€å§‹å›å¡«
    print("Step 2: å¼€å§‹å›å¡«...")
    backfilled_count = 0
    skipped_count = 0

    for record in target_records:
        (
            rowid,
            repo,
            model_name,
            publisher,
            download_count,
            model_type,
            model_category,
            tags,
            base_model,
            data_source,
            likes,
            library_name,
            pipeline_tag,
            created_at,
            last_modified,
            fetched_at,
            base_model_from_api,
            search_keyword,
            url
        ) = record

        # ç¡®å®šå›å¡«æ—¥æœŸï¼šä¼˜å…ˆä½¿ç”¨ last_modifiedï¼Œå¤‡é€‰ created_at
        backfill_date = last_modified if last_modified else created_at

        if not backfill_date:
            skipped_count += 1
            continue

        # åªå›å¡«æ—©äºç›®æ ‡æ—¥æœŸçš„è®°å½•
        if backfill_date >= target_date:
            skipped_count += 1
            continue

        # æ£€æŸ¥è¯¥æ—¥æœŸæ˜¯å¦å·²æœ‰è®°å½•
        cursor.execute(f"""
            SELECT COUNT(*)
            FROM {DATA_TABLE}
            WHERE date = ? AND repo = ? AND model_name = ?
        """, [backfill_date, repo, model_name])

        if cursor.fetchone()[0] > 0:
            skipped_count += 1
            continue

        # æ’å…¥å›å¡«è®°å½•ï¼ˆä¸‹è½½é‡ä¸º0ï¼‰
        cursor.execute(f"""
            INSERT INTO {DATA_TABLE} (
                date, repo, model_name, publisher, download_count,
                model_type, model_category, tags, base_model, data_source,
                likes, library_name, pipeline_tag,
                created_at, last_modified, fetched_at,
                base_model_from_api, search_keyword, url
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, [
            backfill_date, repo, model_name, publisher, '0',
            model_type, model_category, tags, base_model, data_source,
            likes, library_name, pipeline_tag,
            created_at, last_modified, fetched_at,
            base_model_from_api, search_keyword, url
        ])

        backfilled_count += 1
        print(f"âœ… å›å¡«: {repo} - {model_name} -> {backfill_date}")

    # æäº¤äº‹åŠ¡
    conn.commit()

    # æ˜¾ç¤ºç»“æœ
    print("\n" + "="*60)
    print("âœ… å›å¡«å®Œæˆï¼")
    print("="*60)
    print(f"æˆåŠŸå›å¡«: {backfilled_count} æ¡è®°å½•")
    print(f"è·³è¿‡è®°å½•: {skipped_count} æ¡")

    # æŒ‰å¹³å°ç»Ÿè®¡å›å¡«æƒ…å†µ
    print("\n" + "="*60)
    print("æŒ‰å¹³å°ç»Ÿè®¡å›å¡«æƒ…å†µ:")
    print("="*60)

    for repo in target_repos:
        cursor.execute(f"""
            SELECT COUNT(*)
            FROM {DATA_TABLE}
            WHERE date < ?
            AND repo = ?
            AND download_count = '0'
            AND model_category IN ({','.join(['?' for _ in target_categories])})
        """, [target_date, repo] + target_categories)

        zero_count = cursor.fetchone()[0]
        print(f"  {repo:20s}: {zero_count} æ¡å›å¡«è®°å½•")

    conn.close()
    print("\nâœ… æ‰€æœ‰æ“ä½œå·²å®Œæˆ")


if __name__ == '__main__':
    print("="*60)
    print("æ‰¹é‡å›å¡«1æœˆ16æ—¥è¡ç”Ÿæ¨¡å‹å·¥å…·")
    print("="*60)
    print()

    try:
        backfill_all_jan16_models()
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
