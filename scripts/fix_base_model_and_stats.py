"""
ä¿®å¤ Excel æ–‡ä»¶ä¸­çš„ base_model å’Œ model_groupï¼Œå¹¶é‡æ–°ç”Ÿæˆç»Ÿè®¡æ±‡æ€»è¡¨
"""
import pandas as pd
import re
import sys
from typing import List


def extract_model_group(model_id: str) -> str:
    """
    æå–æ¨¡åž‹åˆ†ç»„åç§°ï¼šæ‰¾åˆ°æœ€åŽä¸€æ¬¡å‡ºçŽ°çš„"æ•°å­—+B"ï¼Œä¹‹åŽçš„å†…å®¹åŽ»æŽ‰
    """
    model_name = model_id.split('/')[-1] if '/' in model_id else model_id
    pattern = r'[A]?\d+(?:\.\d+)?B'
    matches = list(re.finditer(pattern, model_name, re.IGNORECASE))

    if not matches:
        return model_name

    last_match = matches[-1]
    end_pos = last_match.end()
    group_name = model_name[:end_pos]

    return group_name


def infer_base_model(model_id: str, official_model_ids: List[str]) -> str:
    """
    ä»Žæ¨¡åž‹åç§°æŽ¨æ–­ base_model

    Args:
        model_id: æ¨¡åž‹ ID
        official_model_ids: å®˜æ–¹æ¨¡åž‹ ID åˆ—è¡¨

    Returns:
        str: æŽ¨æ–­çš„ base_modelï¼Œå¦‚æžœæ— æ³•æŽ¨æ–­åˆ™è¿”å›žç©ºå­—ç¬¦ä¸²
    """
    model_name_lower = model_id.lower()

    # æŒ‰å®˜æ–¹æ¨¡åž‹åç§°é•¿åº¦é™åºæŽ’åºï¼Œä¼˜å…ˆåŒ¹é…æ›´å…·ä½“çš„æ¨¡åž‹
    sorted_official = sorted(official_model_ids,
                            key=lambda x: len(x.split('/')[-1]),
                            reverse=True)

    for official_id in sorted_official:
        official_name = official_id.split('/')[-1].lower()

        # ç§»é™¤å¸¸è§åŽç¼€è¿›è¡ŒåŒ¹é…
        official_core = official_name.replace('-pt', '').replace('-paddle', '').replace('-base', '')

        if official_core in model_name_lower:
            return official_id

    return ''


def fix_excel_file(excel_file: str):
    """ä¿®å¤ Excel æ–‡ä»¶"""
    print(f"ðŸ“‚ è¯»å–æ–‡ä»¶: {excel_file}")

    xls = pd.ExcelFile(excel_file)
    sheet_names = xls.sheet_names

    print(f"âœ… æ‰¾åˆ° {len(sheet_names)} ä¸ª sheet: {sheet_names}")

    # è¯»å–æ‰€æœ‰ sheet
    sheets = {}
    for sheet_name in sheet_names:
        sheets[sheet_name] = pd.read_excel(excel_file, sheet_name=sheet_name)

    # æ”¶é›†æ‰€æœ‰å®˜æ–¹æ¨¡åž‹ ID
    all_official_ids = []
    for sheet_name in sheet_names:
        if sheet_name == 'ç»Ÿè®¡æ±‡æ€»':
            continue
        df = sheets[sheet_name]
        official_ids = df[df['is_base'] == True]['model_id'].tolist()
        all_official_ids.extend(official_ids)

    print(f"\næ‰¾åˆ° {len(all_official_ids)} ä¸ªå®˜æ–¹æ¨¡åž‹")

    # ä¿®å¤æ¯ä¸ªæ•°æ® sheet
    for sheet_name in sheet_names:
        if sheet_name == 'ç»Ÿè®¡æ±‡æ€»':
            continue

        print(f"\n{'='*80}")
        print(f"ðŸ”§ å¤„ç† sheet: {sheet_name}")
        print(f"{'='*80}")

        df = sheets[sheet_name]

        # èŽ·å–è¯¥ sheet çš„å®˜æ–¹æ¨¡åž‹
        sheet_official_ids = df[df['is_base'] == True]['model_id'].tolist()

        # ä¿®å¤ base_model å’Œ model_group
        fixed_count = 0
        for idx, row in df.iterrows():
            if row['is_base']:
                continue

            # å¦‚æžœ base_model æ˜¯ç©ºçš„ï¼Œå°è¯•æŽ¨æ–­
            if pd.isna(row['base_model']) or row['base_model'] == '':
                inferred_base = infer_base_model(row['model_id'], sheet_official_ids)
                if inferred_base:
                    df.at[idx, 'base_model'] = inferred_base
                    df.at[idx, 'model_group'] = extract_model_group(inferred_base)
                    fixed_count += 1
                    print(f"  âœ… {row['model_id']}")
                    print(f"     æŽ¨æ–­ base_model: {inferred_base}")
                else:
                    # æ— æ³•æŽ¨æ–­ï¼Œä½¿ç”¨æ¨¡åž‹è‡ªå·±çš„ group
                    df.at[idx, 'model_group'] = extract_model_group(row['model_id'])
                    print(f"  âš ï¸  {row['model_id']}")
                    print(f"     æ— æ³•æŽ¨æ–­ base_modelï¼Œä½¿ç”¨è‡ªèº«æå–çš„ group")

        print(f"\nä¿®å¤äº† {fixed_count} ä¸ªæ¨¡åž‹çš„ base_model")

        sheets[sheet_name] = df

    # é‡æ–°ç”Ÿæˆç»Ÿè®¡æ±‡æ€»è¡¨
    print(f"\n{'='*80}")
    print("ðŸ“Š é‡æ–°ç”Ÿæˆç»Ÿè®¡æ±‡æ€»è¡¨")
    print(f"{'='*80}")

    def create_stats(df, series_name):
        """åˆ›å»ºç»Ÿè®¡æ±‡æ€»è¡¨"""
        stats_data = []

        # æŒ‰ model_group åˆ†ç»„ç»Ÿè®¡
        for group_name in df[df['is_base'] == True]['model_group'].unique():
            # èŽ·å–è¯¥åˆ†ç»„çš„æ‰€æœ‰è¡ç”Ÿæ¨¡åž‹ï¼ˆåŒ…æ‹¬æŽ¨æ–­å¾—åˆ°çš„ï¼‰
            derivatives = df[(df['model_group'] == group_name) & (df['is_base'] == False)]

            if len(derivatives) == 0:
                continue

            # ç»Ÿè®¡å„ç±»åž‹æ•°é‡å’Œä¸‹è½½é‡
            type_stats = {}
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                type_models = derivatives[derivatives['model_type'] == model_type]
                type_stats[f'{model_type}_count'] = len(type_models)
                type_stats[f'{model_type}_downloads'] = int(type_models['download_count'].sum())

            # æ€»è®¡
            total_derivatives = len(derivatives)
            total_downloads = int(derivatives['download_count'].sum())

            # è®¡ç®—ç™¾åˆ†æ¯”
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                count = type_stats[f'{model_type}_count']
                downloads = type_stats[f'{model_type}_downloads']
                type_stats[f'{model_type}_count_pct'] = f"{count/total_derivatives*100:.1f}%" if total_derivatives > 0 else "0%"
                type_stats[f'{model_type}_downloads_pct'] = f"{downloads/total_downloads*100:.1f}%" if total_downloads > 0 else "0%"

            stats_row = {
                'series': series_name,
                'model_group': group_name,
                'total_derivatives': total_derivatives,
                'total_downloads': total_downloads,
                **type_stats
            }
            stats_data.append(stats_row)

            print(f"  {group_name}: {total_derivatives} ä¸ªè¡ç”Ÿæ¨¡åž‹, {total_downloads:,} æ€»ä¸‹è½½é‡")

        return pd.DataFrame(stats_data)

    # ç”Ÿæˆå„ä¸ªç³»åˆ—çš„ç»Ÿè®¡
    all_stats = []
    for sheet_name in sheet_names:
        if sheet_name == 'ç»Ÿè®¡æ±‡æ€»':
            continue
        df = sheets[sheet_name]
        stats = create_stats(df, sheet_name)
        all_stats.append(stats)

    stats_combined = pd.concat(all_stats, ignore_index=True)
    sheets['ç»Ÿè®¡æ±‡æ€»'] = stats_combined

    # ä¿å­˜ä¿®å¤åŽçš„æ–‡ä»¶
    print(f"\n{'='*80}")
    print("ðŸ’¾ ä¿å­˜ä¿®å¤åŽçš„æ–‡ä»¶")
    print(f"{'='*80}")

    with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
        for sheet_name, df in sheets.items():
            df.to_excel(writer, sheet_name=sheet_name, index=False)
            print(f"  âœ… {sheet_name}: {len(df)} è¡Œ")

    print(f"\nâœ… æ–‡ä»¶å·²æ›´æ–°: {excel_file}")


if __name__ == "__main__":
    if len(sys.argv) > 1:
        excel_file = sys.argv[1]
    else:
        print("ç”¨æ³•: python fix_base_model_and_stats.py <excel_file>")
        sys.exit(1)

    fix_excel_file(excel_file)
