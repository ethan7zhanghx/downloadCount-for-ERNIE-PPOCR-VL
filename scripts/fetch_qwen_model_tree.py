"""
è·å– Qwen æ¨¡å‹çš„ Model Tree æ•°æ®
è¿™æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„è„šæœ¬ï¼Œä¸é›†æˆåˆ°ä¸‹è½½æ•°æ®ç»Ÿè®¡ç³»ç»Ÿä¸­
"""
from huggingface_hub import list_models, model_info
from datetime import datetime
import pandas as pd
import json
from typing import List, Dict
from ernie_tracker.fetchers.fetchers_modeltree import classify_model, classify_model_type


# è¦è·å–çš„ Qwen æ¨¡å‹åˆ—è¡¨
# Qwen3 ç³»åˆ—
QWEN3_MODELS = [
    # 2507 ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "Qwen/Qwen3-30B-A3B-Thinking-2507-FP8",
    "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "Qwen/Qwen3-4B-Thinking-2507-FP8",
    "Qwen/Qwen3-4B-Thinking-2507",
    "Qwen/Qwen3-4B-Instruct-2507-FP8",
    "Qwen/Qwen3-4B-Instruct-2507",
    # åŸºç¡€ç³»åˆ—
    "Qwen/Qwen3-235B-A22B",
    "Qwen/Qwen3-30B-A3B",
    "Qwen/Qwen3-32B",
    "Qwen/Qwen3-14B",
    "Qwen/Qwen3-8B",
    "Qwen/Qwen3-4B",
    "Qwen/Qwen3-1.7B",
    "Qwen/Qwen3-0.6B",
    # FP8 ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-FP8",
    "Qwen/Qwen3-30B-A3B-FP8",
    "Qwen/Qwen3-32B-FP8",
    "Qwen/Qwen3-14B-FP8",
    "Qwen/Qwen3-8B-FP8",
    "Qwen/Qwen3-4B-FP8",
    "Qwen/Qwen3-1.7B-FP8",
    "Qwen/Qwen3-0.6B-FP8",
    # GPTQ/AWQ ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-GPTQ-Int4",
    "Qwen/Qwen3-30B-A3B-GPTQ-Int4",
    "Qwen/Qwen3-32B-AWQ",
    "Qwen/Qwen3-14B-AWQ",
    "Qwen/Qwen3-8B-AWQ",
    "Qwen/Qwen3-4B-AWQ",
    "Qwen/Qwen3-1.7B-GPTQ-Int8",
    "Qwen/Qwen3-0.6B-GPTQ-Int8",
    # GGUF ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-GGUF",
    "Qwen/Qwen3-30B-A3B-GGUF",
    "Qwen/Qwen3-32B-GGUF",
    "Qwen/Qwen3-14B-GGUF",
    "Qwen/Qwen3-8B-GGUF",
    "Qwen/Qwen3-4B-GGUF",
    "Qwen/Qwen3-1.7B-GGUF",
    "Qwen/Qwen3-0.6B-GGUF",
    # Base ç³»åˆ—
    "Qwen/Qwen3-30B-A3B-Base",
    "Qwen/Qwen3-14B-Base",
    "Qwen/Qwen3-8B-Base",
    "Qwen/Qwen3-4B-Base",
    "Qwen/Qwen3-1.7B-Base",
    "Qwen/Qwen3-0.6B-Base",
    # MLX ç³»åˆ—
    "Qwen/Qwen3-4B-MLX-8bit",
    "Qwen/Qwen3-4B-MLX-bf16",
    "Qwen/Qwen3-4B-MLX-6bit",
    "Qwen/Qwen3-4B-MLX-4bit",
    "Qwen/Qwen3-8B-MLX-4bit",
    "Qwen/Qwen3-8B-MLX-6bit",
    "Qwen/Qwen3-8B-MLX-8bit",
    "Qwen/Qwen3-8B-MLX-bf16",
    "Qwen/Qwen3-0.6B-MLX-6bit",
    "Qwen/Qwen3-0.6B-MLX-4bit",
    "Qwen/Qwen3-0.6B-MLX-bf16",
    "Qwen/Qwen3-0.6B-MLX-8bit",
    "Qwen/Qwen3-32B-MLX-8bit",
    "Qwen/Qwen3-1.7B-MLX-6bit",
    "Qwen/Qwen3-1.7B-MLX-bf16",
    "Qwen/Qwen3-1.7B-MLX-8bit",
    "Qwen/Qwen3-1.7B-MLX-4bit",
    "Qwen/Qwen3-14B-MLX-6bit",
    "Qwen/Qwen3-14B-MLX-8bit",
    "Qwen/Qwen3-14B-MLX-4bit",
    "Qwen/Qwen3-14B-MLX-bf16",
    "Qwen/Qwen3-32B-MLX-6bit",
    "Qwen/Qwen3-32B-MLX-bf16",
    "Qwen/Qwen3-32B-MLX-4bit",
    "Qwen/Qwen3-30B-A3B-MLX-4bit",
    "Qwen/Qwen3-30B-A3B-MLX-bf16",
    "Qwen/Qwen3-30B-A3B-MLX-8bit",
    "Qwen/Qwen3-30B-A3B-MLX-6bit",
    "Qwen/Qwen3-235B-A22B-MLX-bf16",
    "Qwen/Qwen3-235B-A22B-MLX-6bit",
    "Qwen/Qwen3-235B-A22B-MLX-4bit",
    "Qwen/Qwen3-235B-A22B-MLX-8bit",
]

# Qwen3-VL ç³»åˆ—
QWEN3_VL_MODELS = [
    # Thinking/Instruct ç³»åˆ—
    "Qwen/Qwen3-VL-235B-A22B-Thinking",
    "Qwen/Qwen3-VL-235B-A22B-Instruct",
    "Qwen/Qwen3-VL-235B-A22B-Thinking-FP8",
    "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
    "Qwen/Qwen3-VL-30B-A3B-Thinking",
    "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "Qwen/Qwen3-VL-30B-A3B-Thinking-FP8",
    "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8",
    "Qwen/Qwen3-VL-8B-Thinking",
    "Qwen/Qwen3-VL-8B-Instruct",
    "Qwen/Qwen3-VL-8B-Thinking-FP8",
    "Qwen/Qwen3-VL-8B-Instruct-FP8",
    "Qwen/Qwen3-VL-4B-Thinking",
    "Qwen/Qwen3-VL-4B-Instruct",
    "Qwen/Qwen3-VL-4B-Thinking-FP8",
    "Qwen/Qwen3-VL-4B-Instruct-FP8",
    "Qwen/Qwen3-VL-2B-Instruct",
    "Qwen/Qwen3-VL-2B-Thinking",
    "Qwen/Qwen3-VL-2B-Thinking-FP8",
    "Qwen/Qwen3-VL-32B-Instruct",
    "Qwen/Qwen3-VL-32B-Thinking",
    "Qwen/Qwen3-VL-32B-Thinking-FP8",
    "Qwen/Qwen3-VL-32B-Instruct-FP8",
    "Qwen/Qwen3-VL-2B-Instruct-FP8",
    # GGUF ç³»åˆ—
    "Qwen/Qwen3-VL-2B-Instruct-GGUF",
    "Qwen/Qwen3-VL-4B-Instruct-GGUF",
    "Qwen/Qwen3-VL-4B-Thinking-GGUF",
    "Qwen/Qwen3-VL-8B-Instruct-GGUF",
    "Qwen/Qwen3-VL-32B-Instruct-GGUF",
    "Qwen/Qwen3-VL-32B-Thinking-GGUF",
    "Qwen/Qwen3-VL-235B-A22B-Instruct-GGUF",
    "Qwen/Qwen3-VL-235B-A22B-Thinking-GGUF",
    "Qwen/Qwen3-VL-30B-A3B-Instruct-GGUF",
    "Qwen/Qwen3-VL-30B-A3B-Thinking-GGUF",
    "Qwen/Qwen3-VL-2B-Thinking-GGUF",
    "Qwen/Qwen3-VL-8B-Thinking-GGUF",
]


def extract_model_group(model_id: str) -> str:
    """
    æå–æ¨¡å‹åˆ†ç»„åç§°ï¼šæ‰¾åˆ°æœ€åä¸€æ¬¡å‡ºç°çš„"æ•°å­—+B"ï¼Œä¹‹åçš„å†…å®¹å»æ‰

    ä¾‹å¦‚ï¼š
    - Qwen/Qwen3-235B-A22B-Thinking-2507-FP8 â†’ Qwen3-235B-A22B
    - Qwen/Qwen3-4B-MLX-4bit â†’ Qwen3-4B
    - Qwen/Qwen3-VL-30B-A3B-Instruct â†’ Qwen3-VL-30B-A3B

    Args:
        model_id: å®Œæ•´çš„æ¨¡å‹ ID

    Returns:
        str: åˆ†ç»„åç§°
    """
    import re

    # å»æ‰ "Qwen/" å‰ç¼€
    model_name = model_id.replace('Qwen/', '')

    # åŒ¹é…æ‰€æœ‰çš„"æ•°å­—+B"æ¨¡å¼ï¼ˆåŒ…æ‹¬å°æ•°å’Œ A22B/A3B è¿™ç§æ ¼å¼ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼šå¯é€‰çš„ A + æ•°å­—ï¼ˆå¯èƒ½åŒ…å«å°æ•°ç‚¹ï¼‰ + B
    # ä¾‹å¦‚ï¼š235B, 30B, A22B, A3B, 1.7B, 0.6B
    pattern = r'[A]?\d+(?:\.\d+)?B'

    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…
    matches = list(re.finditer(pattern, model_name, re.IGNORECASE))

    if not matches:
        # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè¿”å›åŸå§‹åç§°
        return model_name

    # è·å–æœ€åä¸€ä¸ªåŒ¹é…
    last_match = matches[-1]
    end_pos = last_match.end()

    # æˆªå–åˆ°æœ€åä¸€ä¸ª"æ•°å­—+B"çš„ä½ç½®
    group_name = model_name[:end_pos]

    return group_name


def get_all_model_info_fields(model_id: str) -> Dict:
    """
    è·å–æ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯å­—æ®µï¼ˆå°½å¯èƒ½ä¿ç•™ API è¿”å›çš„æ‰€æœ‰å­—æ®µï¼‰

    Args:
        model_id: æ¨¡å‹ID

    Returns:
        Dict: åŒ…å«æ‰€æœ‰å¯ç”¨å­—æ®µçš„å­—å…¸
    """
    try:
        # è·å–æ¨¡å‹è¯¦ç»†ä¿¡æ¯ï¼Œä½¿ç”¨ expand å‚æ•°è·å–æ›´å¤šå­—æ®µ
        info = model_info(model_id, expand=["downloadsAllTime", "trendingScore"])
        card_data = None
        if hasattr(info, 'cardData') and info.cardData:
            if isinstance(info.cardData, dict):
                card_data = info.cardData
            elif hasattr(info.cardData, '__dict__'):
                card_data = info.cardData.__dict__

        # ä» list_models è·å–å®Œæ•´æ¨¡å‹å¯¹è±¡ï¼ˆåŒ…å« tags ç­‰å­—æ®µï¼‰
        model_obj = None
        try:
            models = list(list_models(model_name=model_id, full=True, limit=1))
            if models:
                model_obj = models[0]
        except Exception as e:
            print(f"    âš ï¸ æ— æ³•ä» list_models è·å– {model_id}: {e}")

        # æ”¶é›†æ‰€æœ‰å­—æ®µ
        model_data = {}

        # ä» model_info è·å–çš„å­—æ®µ
        info_fields = [
            'modelId', 'sha', 'author', 'private', 'disabled', 'gated',
            'downloads', 'downloads_all_time', 'likes', 'library_name',
            'pipeline_tag', 'created_at', 'last_modified', 'card_data',
            'siblings', 'spaces', 'safetensors', 'config'
        ]

        for field in info_fields:
            if hasattr(info, field):
                value = getattr(info, field)
                # å¤„ç†ç‰¹æ®Šç±»å‹
                if field in ['created_at', 'last_modified'] and value:
                    model_data[field] = value.isoformat() if hasattr(value, 'isoformat') else str(value)
                elif field == 'card_data' and value:
                    # å°† card_data è½¬æ¢ä¸ºå­—å…¸
                    model_data[field] = value.__dict__ if hasattr(value, '__dict__') else str(value)
                elif field == 'siblings' and value:
                    # siblings æ˜¯æ–‡ä»¶åˆ—è¡¨
                    model_data[field] = [s.__dict__ if hasattr(s, '__dict__') else str(s) for s in value]
                elif field == 'config' and value:
                    # config å¯èƒ½æ˜¯å­—å…¸æˆ–å¯¹è±¡
                    model_data[field] = value if isinstance(value, dict) else (value.__dict__ if hasattr(value, '__dict__') else str(value))
                else:
                    model_data[field] = value

        # ä» model_obj è·å–çš„å­—æ®µï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if model_obj:
            model_obj_fields = ['tags', 'trending_score', 'sdk']
            for field in model_obj_fields:
                if hasattr(model_obj, field):
                    value = getattr(model_obj, field)
                    model_data[field] = value
        # ä¼˜å…ˆä½¿ç”¨ model_info æä¾›çš„ tagsï¼Œå…¶æ¬¡ fallback åˆ° model_obj çš„ tags
        if hasattr(info, 'tags') and info.tags:
            model_data['tags'] = info.tags
        elif 'tags' not in model_data and hasattr(model_obj, 'tags'):
            model_data['tags'] = getattr(model_obj, 'tags')

        # æ˜¾å¼ä¿å­˜æ¨¡å‹å¡å†…å®¹ï¼Œæ–¹ä¾¿åç»­ä½¿ç”¨
        if card_data and 'card_data' not in model_data:
            model_data['card_data'] = card_data

        # æ·»åŠ æˆ‘ä»¬ç³»ç»Ÿä½¿ç”¨çš„åˆ†ç±»å­—æ®µ
        publisher = model_data.get('author', 'Unknown')
        tags = model_data.get('tags', [])
        pipeline_tag = model_data.get('pipeline_tag', None)

        model_data['model_category'] = classify_model(model_id, publisher)
        model_data['model_type'] = classify_model_type(model_id, tags, pipeline_tag, card_data)

        # æ·»åŠ ä¸‹è½½é‡ç»Ÿä¸€å­—æ®µï¼ˆä¼˜å…ˆä½¿ç”¨ downloads_all_timeï¼‰
        model_data['download_count'] = model_data.get('downloads_all_time') or model_data.get('downloads', 0) or 0

        # æ·»åŠ è·å–æ—¶é—´
        model_data['fetched_at'] = datetime.now().isoformat()

        return model_data

    except Exception as e:
        print(f"    âŒ è·å–æ¨¡å‹ {model_id} ä¿¡æ¯å¤±è´¥: {e}")
        return None


def get_model_tree_with_full_info(base_model_id: str) -> Dict:
    """
    è·å–æŒ‡å®šæ¨¡å‹çš„å®Œæ•´ Model Tree ä¿¡æ¯ï¼ˆåŒ…å«æ‰€æœ‰ API å­—æ®µï¼‰

    Args:
        base_model_id: åŸºç¡€æ¨¡å‹ID

    Returns:
        Dict: åŒ…å«åŸºç¡€æ¨¡å‹å’Œæ‰€æœ‰è¡ç”Ÿæ¨¡å‹çš„å®Œæ•´ä¿¡æ¯
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š è·å– {base_model_id} çš„ Model Tree")
    print(f"{'='*80}")

    result = {
        'base_model_id': base_model_id,
        'base_model_info': None,
        'derivatives': [],
        'summary': {
            'total_derivatives': 0,
            'by_type': {},
            'by_category': {},
            'total_downloads': 0
        }
    }

    # 1. è·å–åŸºç¡€æ¨¡å‹çš„å®Œæ•´ä¿¡æ¯
    print(f"\n1ï¸âƒ£ è·å–åŸºç¡€æ¨¡å‹ä¿¡æ¯...")
    base_info = get_all_model_info_fields(base_model_id)
    if not base_info:
        print(f"  âŒ æ— æ³•è·å–åŸºç¡€æ¨¡å‹ {base_model_id} çš„ä¿¡æ¯")
        return result

    result['base_model_info'] = base_info
    print(f"  âœ… åŸºç¡€æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ")
    print(f"     ä¸‹è½½é‡: {base_info.get('download_count', 0):,}")
    print(f"     åˆ†ç±»: {base_info.get('model_category', 'N/A')}")
    print(f"     ç±»å‹: {base_info.get('model_type', 'N/A')}")

    # 2. è·å–è¡ç”Ÿæ¨¡å‹åˆ—è¡¨
    print(f"\n2ï¸âƒ£ æŸ¥æ‰¾è¡ç”Ÿæ¨¡å‹...")
    try:
        derivatives = list(list_models(
            filter=f"base_model:{base_model_id}",
            full=True,
            limit=1000
        ))

        if not derivatives:
            print(f"  âšª æ²¡æœ‰æ‰¾åˆ°è¡ç”Ÿæ¨¡å‹")
            return result

        print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ªè¡ç”Ÿæ¨¡å‹")

    except Exception as e:
        print(f"  âŒ æŸ¥æ‰¾è¡ç”Ÿæ¨¡å‹å¤±è´¥: {e}")
        return result

    # 3. è·å–æ¯ä¸ªè¡ç”Ÿæ¨¡å‹çš„å®Œæ•´ä¿¡æ¯
    print(f"\n3ï¸âƒ£ è·å–è¡ç”Ÿæ¨¡å‹è¯¦ç»†ä¿¡æ¯...")
    for idx, deriv in enumerate(derivatives, 1):
        print(f"  [{idx}/{len(derivatives)}] {deriv.id}")

        deriv_info = get_all_model_info_fields(deriv.id)
        if deriv_info:
            # ç¡®ä¿ model_id è¢«æ­£ç¡®è®¾ç½®ï¼ˆä½¿ç”¨ deriv.idï¼‰
            if 'modelId' not in deriv_info or not deriv_info['modelId']:
                deriv_info['modelId'] = deriv.id
            # ç¡®ä¿ author è¢«æ­£ç¡®è®¾ç½®
            if 'author' not in deriv_info or not deriv_info['author']:
                deriv_info['author'] = deriv.author if hasattr(deriv, 'author') else ''

            deriv_info['base_model'] = base_model_id
            result['derivatives'].append(deriv_info)

            # æ›´æ–°ç»Ÿè®¡
            model_type = deriv_info.get('model_type', 'other')
            model_category = deriv_info.get('model_category', 'other')
            downloads = deriv_info.get('download_count', 0)

            result['summary']['by_type'][model_type] = result['summary']['by_type'].get(model_type, 0) + 1
            result['summary']['by_category'][model_category] = result['summary']['by_category'].get(model_category, 0) + 1
            result['summary']['total_downloads'] += downloads

            print(f"     âœ… ä¸‹è½½é‡: {downloads:,} | ç±»å‹: {model_type} | åˆ†ç±»: {model_category}")

    result['summary']['total_derivatives'] = len(result['derivatives'])

    # 4. æ‰“å°æ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*80}")
    print(f"ğŸ“Š {base_model_id} - Model Tree æ±‡æ€»")
    print(f"{'='*80}")
    print(f"è¡ç”Ÿæ¨¡å‹æ€»æ•°: {result['summary']['total_derivatives']}")
    print(f"æ€»ä¸‹è½½é‡: {result['summary']['total_downloads']:,}")
    print(f"\næŒ‰ç±»å‹åˆ†å¸ƒ:")
    for model_type, count in sorted(result['summary']['by_type'].items(), key=lambda x: x[1], reverse=True):
        print(f"  {model_type}: {count}")
    print(f"\næŒ‰åˆ†ç±»åˆ†å¸ƒ:")
    for category, count in sorted(result['summary']['by_category'].items(), key=lambda x: x[1], reverse=True):
        print(f"  {category}: {count}")

    return result


def main():
    """
    ä¸»å‡½æ•°ï¼šè·å–æ‰€æœ‰ Qwen æ¨¡å‹çš„ Model Tree æ•°æ®
    """
    print("ğŸš€ å¼€å§‹è·å– Qwen æ¨¡å‹çš„ Model Tree æ•°æ®")
    print(f"ç›®æ ‡æ¨¡å‹æ•°: {len(QWEN_MODELS)}")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    all_results = {}

    for model_id in QWEN_MODELS:
        result = get_model_tree_with_full_info(model_id)
        all_results[model_id] = result

    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # 1. ä¿å­˜ä¸º JSONï¼ˆåŒ…å«æ‰€æœ‰åŸå§‹å­—æ®µï¼‰
    json_filename = f"qwen_model_tree_{timestamp}.json"
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False, default=str)
    print(f"\nğŸ’¾ JSON æ•°æ®å·²ä¿å­˜åˆ°: {json_filename}")

    # 2. ä¿å­˜ä¸º Excelï¼ˆæ‰å¹³åŒ–çš„è¡¨æ ¼æ•°æ®ï¼‰
    excel_data = []
    for base_model_id, result in all_results.items():
        # æ·»åŠ åŸºç¡€æ¨¡å‹è¡Œ
        if result['base_model_info']:
            base_row = {
                'model_id': base_model_id,  # ç¬¬ä¸€åˆ—
                'base_model': base_model_id,
                'is_base': True,
                'model_name': base_model_id.split('/')[-1],
                'publisher': result['base_model_info'].get('author', ''),
                'model_type': result['base_model_info'].get('model_type', ''),
                'model_category': result['base_model_info'].get('model_category', ''),
                'download_count': result['base_model_info'].get('download_count', 0),
                'downloads_all_time': result['base_model_info'].get('downloads_all_time', 0),
                'downloads': result['base_model_info'].get('downloads', 0),
                'likes': result['base_model_info'].get('likes', 0),
                'pipeline_tag': result['base_model_info'].get('pipeline_tag', ''),
                'library_name': result['base_model_info'].get('library_name', ''),
                'tags': str(result['base_model_info'].get('tags', [])),
                'created_at': result['base_model_info'].get('created_at', ''),
                'last_modified': result['base_model_info'].get('last_modified', ''),
                'trending_score': result['base_model_info'].get('trending_score', 0),
                'fetched_at': result['base_model_info'].get('fetched_at', '')
            }
            excel_data.append(base_row)

        # æ·»åŠ è¡ç”Ÿæ¨¡å‹è¡Œ
        for deriv_info in result['derivatives']:
            deriv_row = {
                'model_id': deriv_info.get('modelId', ''),  # ç¬¬ä¸€åˆ—
                'base_model': base_model_id,
                'is_base': False,
                'model_name': deriv_info.get('modelId', '').split('/')[-1] if deriv_info.get('modelId') else '',
                'publisher': deriv_info.get('author', ''),
                'model_type': deriv_info.get('model_type', ''),
                'model_category': deriv_info.get('model_category', ''),
                'download_count': deriv_info.get('download_count', 0),
                'downloads_all_time': deriv_info.get('downloads_all_time', 0),
                'downloads': deriv_info.get('downloads', 0),
                'likes': deriv_info.get('likes', 0),
                'pipeline_tag': deriv_info.get('pipeline_tag', ''),
                'library_name': deriv_info.get('library_name', ''),
                'tags': str(deriv_info.get('tags', [])),
                'created_at': deriv_info.get('created_at', ''),
                'last_modified': deriv_info.get('last_modified', ''),
                'trending_score': deriv_info.get('trending_score', 0),
                'fetched_at': deriv_info.get('fetched_at', '')
            }
            excel_data.append(deriv_row)

    if excel_data:
        df = pd.DataFrame(excel_data)

        # åˆ›å»ºç»Ÿè®¡æ•°æ®
        # 1. æ¯ä¸ª base model çš„è¡ç”Ÿæ¨¡å‹æ•°é‡ç»Ÿè®¡ï¼ˆæŒ‰ç±»å‹ï¼‰
        stats_data = []
        for base_model_id, result in all_results.items():
            if result['derivatives']:
                # ç»Ÿè®¡å„ç±»å‹æ•°é‡
                type_counts = {}
                for deriv in result['derivatives']:
                    model_type = deriv.get('model_type', 'other')
                    type_counts[model_type] = type_counts.get(model_type, 0) + 1

                # è®¡ç®—æ€»ä¸‹è½½é‡
                total_downloads = sum(deriv.get('download_count', 0) for deriv in result['derivatives'])

                stats_row = {
                    'base_model': base_model_id,
                    'total_derivatives': len(result['derivatives']),
                    'quantized': type_counts.get('quantized', 0),
                    'finetune': type_counts.get('finetune', 0),
                    'adapter': type_counts.get('adapter', 0),
                    'lora': type_counts.get('lora', 0),
                    'merge': type_counts.get('merge', 0),
                    'other': type_counts.get('other', 0),
                    'total_derivative_downloads': total_downloads,
                    'avg_downloads_per_derivative': total_downloads / len(result['derivatives']) if result['derivatives'] else 0
                }
                stats_data.append(stats_row)

        stats_df = pd.DataFrame(stats_data)

        # ä¿å­˜åˆ° Excelï¼ŒåŒ…å«å¤šä¸ª sheet
        excel_filename = f"qwen_model_tree_{timestamp}.xlsx"
        with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
            # Sheet 1: ç»Ÿè®¡æ±‡æ€»
            stats_df.to_excel(writer, sheet_name='ç»Ÿè®¡æ±‡æ€»', index=False)

            # Sheet 2: æ‰€æœ‰æ¨¡å‹è¯¦ç»†ä¿¡æ¯
            df.to_excel(writer, sheet_name='è¯¦ç»†æ•°æ®', index=False)

            # Sheet 3-N: æ¯ä¸ª base model å•ç‹¬ä¸€ä¸ª sheet
            for base_model_id, result in all_results.items():
                sheet_name = base_model_id.split('/')[-1][:31]  # Excel sheet åç§°é™åˆ¶ 31 å­—ç¬¦

                # è¯¥ base model çš„æ‰€æœ‰æ•°æ®ï¼ˆåŒ…æ‹¬ base model è‡ªå·±å’Œè¡ç”Ÿæ¨¡å‹ï¼‰
                base_df = df[df['base_model'] == base_model_id].copy()
                base_df.to_excel(writer, sheet_name=sheet_name, index=False)

        print(f"ğŸ“Š Excel æ•°æ®å·²ä¿å­˜åˆ°: {excel_filename}")
        print(f"   - ç»Ÿè®¡æ±‡æ€»: æ¯ä¸ª base model çš„è¡ç”Ÿæ¨¡å‹ç±»å‹ç»Ÿè®¡")
        print(f"   - è¯¦ç»†æ•°æ®: æ‰€æœ‰æ¨¡å‹çš„å®Œæ•´ä¿¡æ¯")
        print(f"   - å„ base model ç‹¬ç«‹ sheet: {len(all_results)} ä¸ª")

        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        print(f"\n{'='*80}")
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡")
        print(f"{'='*80}")
        print(f"åŸºç¡€æ¨¡å‹æ•°: {len(QWEN_MODELS)}")
        print(f"è¡ç”Ÿæ¨¡å‹æ€»æ•°: {len(df[~df['is_base']])}")
        print(f"æ€»è®°å½•æ•°: {len(df)}")

        if not df[~df['is_base']].empty:
            print(f"\nè¡ç”Ÿæ¨¡å‹æŒ‰ç±»å‹åˆ†å¸ƒ:")
            type_counts = df[~df['is_base']]['model_type'].value_counts()
            for model_type, count in type_counts.items():
                print(f"  {model_type}: {count}")

            print(f"\nè¡ç”Ÿæ¨¡å‹æŒ‰åŸºç¡€æ¨¡å‹åˆ†å¸ƒ:")
            base_counts = df[~df['is_base']]['base_model'].value_counts()
            for base_model, count in base_counts.items():
                print(f"  {base_model}: {count}")

            print(f"\næ€»ä¸‹è½½é‡ç»Ÿè®¡:")
            total_downloads = df['download_count'].sum()
            base_downloads = df[df['is_base']]['download_count'].sum()
            deriv_downloads = df[~df['is_base']]['download_count'].sum()
            print(f"  åŸºç¡€æ¨¡å‹æ€»ä¸‹è½½é‡: {base_downloads:,}")
            print(f"  è¡ç”Ÿæ¨¡å‹æ€»ä¸‹è½½é‡: {deriv_downloads:,}")
            print(f"  æ€»è®¡: {total_downloads:,}")

            # è¯¦ç»†ç»Ÿè®¡è¡¨æ ¼
            print(f"\n{'='*80}")
            print(f"ğŸ“‹ å„åŸºç¡€æ¨¡å‹çš„è¡ç”Ÿæ¨¡å‹ç±»å‹ç»Ÿè®¡")
            print(f"{'='*80}")
            print(stats_df.to_string(index=False))

    print(f"\nâœ… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"âœ… æ‰€æœ‰æ•°æ®å·²ä¿å­˜")


if __name__ == "__main__":
    main()
