"""
æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–ä¿®å¤
éªŒè¯ç´¯è®¡ã€å½“å‰ã€å·²åˆ é™¤æ¨¡å‹æ•°çš„æ•°å­¦å…³ç³»æ˜¯å¦æ­£ç¡®
"""
import sys
sys.path.insert(0, '..')

from ernie_tracker.db import load_data_from_db
from ernie_tracker.analysis import get_deleted_or_hidden_models, normalize_model_names
import pandas as pd

def test_model_series(date, series_name):
    """æµ‹è¯•æŒ‡å®šæ¨¡å‹ç³»åˆ—çš„æ•°å­¦å…³ç³»"""
    print(f"\n{'='*60}")
    print(f"æµ‹è¯• {series_name} ({date})")
    print('='*60)

    category = 'ernie-4.5' if series_name == 'ERNIE-4.5' else 'paddleocr-vl'

    # 1. è·å–ç´¯è®¡æ•°æ®ï¼ˆåº”ç”¨æ ‡å‡†åŒ–ï¼‰
    backfill = load_data_from_db(date_filter=date, last_value_per_model=True)

    # åº”ç”¨æ ‡å‡†åŒ–é€»è¾‘
    backfill['publisher'] = backfill['publisher'].astype(str).apply(
        lambda x: x.title() if x.lower() != 'nan' else x
    )
    backfill = normalize_model_names(backfill)
    backfill['download_count'] = pd.to_numeric(backfill['download_count'], errors='coerce').fillna(0)
    backfill = backfill.sort_values(by='download_count', ascending=False).drop_duplicates(
        subset=['date', 'repo', 'publisher', 'model_name'], keep='first'
    )

    cumulative = backfill[
        (backfill['model_category'] == category) &
        (backfill['model_type'] != 'original')
    ]

    # 2. è·å–å½“å‰æ•°æ®
    current = load_data_from_db(date_filter=date, last_value_per_model=False)
    current_derivatives = current[
        (current['model_category'] == category) &
        (current['model_type'] != 'original')
    ]

    # 3. è·å–å·²åˆ é™¤æ¨¡å‹
    deleted = get_deleted_or_hidden_models(date, model_series=series_name)

    # 4. éªŒè¯æ•°å­¦å…³ç³»
    cumulative_count = len(cumulative)
    current_count = len(current_derivatives)
    deleted_count = len(deleted)
    expected_cumulative = current_count + deleted_count

    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"  ç´¯è®¡è¡ç”Ÿæ¨¡å‹ï¼ˆæ ‡å‡†åŒ–åï¼‰: {cumulative_count} ä¸ª")
    print(f"  å½“å‰æ—¥æœŸè¡ç”Ÿæ¨¡å‹: {current_count} ä¸ª")
    print(f"  å·²åˆ é™¤/éšè—æ¨¡å‹: {deleted_count} ä¸ª")

    print(f"\nğŸ”¢ æ•°å­¦éªŒè¯:")
    print(f"  {current_count} + {deleted_count} = {expected_cumulative}")

    if expected_cumulative == cumulative_count:
        print(f"  âœ… æ­£ç¡®ï¼ç­‰äºç´¯è®¡æ•° {cumulative_count}")
        success = True
    else:
        print(f"  âŒ é”™è¯¯ï¼ä¸ç­‰äºç´¯è®¡æ•° {cumulative_count}")
        print(f"  å·®å¼‚: {abs(expected_cumulative - cumulative_count)} ä¸ªæ¨¡å‹")
        success = False

    # 5. æ˜¾ç¤ºéƒ¨åˆ†å·²åˆ é™¤æ¨¡å‹
    if deleted_count > 0:
        print(f"\nğŸ—‘ï¸  å·²åˆ é™¤æ¨¡å‹ç¤ºä¾‹ï¼ˆå‰5ä¸ªï¼‰:")
        for model in deleted[:5]:
            print(f"  - {model['publisher']}/{model['model_name']}")
            print(f"    æœ€åå‡ºç°: {model['last_seen_date']}, ä¸‹è½½é‡: {model['last_download_count']}")

    return success

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("="*60)
    print("æ•°æ®æ ‡å‡†åŒ–ä¿®å¤éªŒè¯æµ‹è¯•")
    print("="*60)

    test_date = '2026-01-02'

    # æµ‹è¯• ERNIE-4.5
    result1 = test_model_series(test_date, 'ERNIE-4.5')

    # æµ‹è¯• PaddleOCR-VL
    result2 = test_model_series(test_date, 'PaddleOCR-VL')

    # æ€»ç»“
    print("\n" + "="*60)
    print("æµ‹è¯•æ€»ç»“")
    print("="*60)

    if result1 and result2:
        print("âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ•°å­¦å…³ç³»æ­£ç¡®ã€‚")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼è¯·æ£€æŸ¥æ ‡å‡†åŒ–é€»è¾‘ã€‚")
        return 1

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)
