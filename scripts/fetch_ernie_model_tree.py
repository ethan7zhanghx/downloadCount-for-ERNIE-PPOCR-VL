"""
è·å– ERNIE æ¨¡å‹çš„ Model Tree å’Œ Search æ•°æ®
æ”¯æŒ ERNIE-4.5 å’Œ PaddleOCR-VL åˆ†å¼€ç»Ÿè®¡ï¼Œå¹¶æŒ‰æ¨¡å‹åˆ†ç»„
åŒæ—¶åŒ…å« Model Tree å’Œ Search è·å–çš„è¡ç”Ÿæ¨¡å‹
"""
from huggingface_hub import list_models, model_info
from datetime import datetime
import pandas as pd
import json
import re
from typing import List, Dict, Set
import sys
sys.path.append('/Users/zhanghaoxin/Desktop/Baidu/DownloadData')
from ernie_tracker.fetchers.fetchers_modeltree import classify_model, classify_model_type


# ERNIE-4.5 å®˜æ–¹æ¨¡å‹åˆ—è¡¨
ERNIE_45_MODELS = [
    # 0.3B ç³»åˆ—
    "baidu/ERNIE-4.5-0.3B-PT",
    "baidu/ERNIE-4.5-0.3B-Paddle",
    "baidu/ERNIE-4.5-0.3B-Base-PT",
    "baidu/ERNIE-4.5-0.3B-Base-Paddle",
    # 21B-A3B ç³»åˆ—
    "baidu/ERNIE-4.5-21B-A3B-PT",
    "baidu/ERNIE-4.5-21B-A3B-Paddle",
    "baidu/ERNIE-4.5-21B-A3B-Base-PT",
    "baidu/ERNIE-4.5-21B-A3B-Base-Paddle",
    "baidu/ERNIE-4.5-21B-A3B-Thinking",
    # 300B-A47B ç³»åˆ—
    "baidu/ERNIE-4.5-300B-A47B-PT",
    "baidu/ERNIE-4.5-300B-A47B-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-Base-PT",
    "baidu/ERNIE-4.5-300B-A47B-Base-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-FP8-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-W4A8C8-TP4-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-2Bits-TP2-Paddle",
    "baidu/ERNIE-4.5-300B-A47B-2Bits-TP4-Paddle",
    # VL-28B-A3B ç³»åˆ—
    "baidu/ERNIE-4.5-VL-28B-A3B-PT",
    "baidu/ERNIE-4.5-VL-28B-A3B-Paddle",
    "baidu/ERNIE-4.5-VL-28B-A3B-Base-PT",
    "baidu/ERNIE-4.5-VL-28B-A3B-Base-Paddle",
    "baidu/ERNIE-4.5-VL-28B-A3B-Thinking",
    # VL-424B-A47B ç³»åˆ—
    "baidu/ERNIE-4.5-VL-424B-A47B-PT",
    "baidu/ERNIE-4.5-VL-424B-A47B-Paddle",
    "baidu/ERNIE-4.5-VL-424B-A47B-Base-PT",
    "baidu/ERNIE-4.5-VL-424B-A47B-Base-Paddle",
]

# PaddleOCR-VL å®˜æ–¹æ¨¡å‹åˆ—è¡¨
PADDLEOCR_VL_MODELS = [
    "PaddlePaddle/PaddleOCR-VL",
]


def extract_model_group(model_id: str) -> str:
    """
    æå–æ¨¡å‹åˆ†ç»„åç§°ï¼šæ‰¾åˆ°æœ€åä¸€æ¬¡å‡ºç°çš„"æ•°å­—+B"ï¼Œä¹‹åçš„å†…å®¹å»æ‰

    ä¾‹å¦‚ï¼š
    - baidu/ERNIE-4.5-300B-A47B-2Bits-Paddle â†’ ERNIE-4.5-300B-A47B
    - baidu/ERNIE-4.5-21B-A3B-Thinking â†’ ERNIE-4.5-21B-A3B
    - baidu/ERNIE-4.5-0.3B-PT â†’ ERNIE-4.5-0.3B

    Args:
        model_id: å®Œæ•´çš„æ¨¡å‹ ID

    Returns:
        str: åˆ†ç»„åç§°
    """
    # å»æ‰å‘å¸ƒè€…å‰ç¼€
    model_name = model_id.split('/')[-1] if '/' in model_id else model_id

    # åŒ¹é…æ‰€æœ‰çš„"æ•°å­—+B"æ¨¡å¼ï¼ˆåŒ…æ‹¬å°æ•°å’Œ A47B/A3B è¿™ç§æ ¼å¼ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼šå¯é€‰çš„ A + æ•°å­—ï¼ˆå¯èƒ½åŒ…å«å°æ•°ç‚¹ï¼‰ + B
    # ä¾‹å¦‚ï¼š300B, 21B, A47B, A3B, 0.3B
    pattern = r'[A]?\d+(?:\.\d+)?B'

    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…
    matches = list(re.finditer(pattern, model_name, re.IGNORECASE))

    if not matches:
        # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè¿”å›åŸå§‹åç§°
        return model_name

    # è·å–æœ€åä¸€ä¸ªåŒ¹é…
    last_match = matches[-1]
    end_pos = last_match.end()

    # æˆªå–åˆ°æœ€åä¸€ä¸ª"æ•°å­—+B"çš„ä½ç½®
    group_name = model_name[:end_pos]

    return group_name


def get_all_model_info_fields(model_id: str) -> Dict:
    """è·å–æ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯å­—æ®µï¼ŒåŒ…æ‹¬å°è¯•è·å– base_model"""
    try:
        info = model_info(model_id, expand=["downloadsAllTime", "trendingScore"])

        model_obj = None
        try:
            models = list(list_models(model_name=model_id, full=True, limit=1))
            if models:
                model_obj = models[0]
        except:
            pass

        model_data = {}
        card_data = None
        if hasattr(info, 'cardData') and info.cardData:
            if isinstance(info.cardData, dict):
                card_data = info.cardData
            elif hasattr(info.cardData, '__dict__'):
                card_data = info.cardData.__dict__

        # åŸºæœ¬å­—æ®µ
        if hasattr(info, 'modelId'):
            model_data['modelId'] = info.modelId
        if hasattr(info, 'author'):
            model_data['author'] = info.author
        if hasattr(info, 'downloads_all_time'):
            model_data['downloads_all_time'] = info.downloads_all_time
        if hasattr(info, 'downloads'):
            model_data['downloads'] = info.downloads
        if hasattr(info, 'likes'):
            model_data['likes'] = info.likes
        if hasattr(info, 'library_name'):
            model_data['library_name'] = info.library_name
        if hasattr(info, 'pipeline_tag'):
            model_data['pipeline_tag'] = info.pipeline_tag
        if hasattr(info, 'created_at'):
            model_data['created_at'] = info.created_at.isoformat() if hasattr(info.created_at, 'isoformat') else str(info.created_at)
        if hasattr(info, 'last_modified'):
            model_data['last_modified'] = info.last_modified.isoformat() if hasattr(info.last_modified, 'isoformat') else str(info.last_modified)

        # å°è¯•ä» API è·å– base_model
        if card_data:
            if 'base_model' in card_data:
                base_model_from_api = card_data['base_model']
                # base_model å¯èƒ½æ˜¯å­—ç¬¦ä¸²æˆ–åˆ—è¡¨
                if isinstance(base_model_from_api, list) and len(base_model_from_api) > 0:
                    model_data['base_model_from_api'] = base_model_from_api[0]
                elif isinstance(base_model_from_api, str) and base_model_from_api:
                    model_data['base_model_from_api'] = base_model_from_api

        # ä¼˜å…ˆä½¿ç”¨ model_info æä¾›çš„ tagsï¼Œå…¶æ¬¡ fallback åˆ° list_models è¿”å›çš„ tags
        if hasattr(info, 'tags') and info.tags:
            model_data['tags'] = info.tags
        elif model_obj and hasattr(model_obj, 'tags'):
            model_data['tags'] = model_obj.tags
        else:
            model_data['tags'] = []

        if model_obj and hasattr(model_obj, 'trending_score'):
            model_data['trending_score'] = model_obj.trending_score

        # åˆ†ç±»å­—æ®µ
        publisher = model_data.get('author', 'Unknown')
        tags = model_data.get('tags', [])
        pipeline_tag = model_data.get('pipeline_tag', None)

        model_data['model_category'] = classify_model(model_id, publisher)
        model_data['model_type'] = classify_model_type(model_id, tags, pipeline_tag, card_data)
        model_data['download_count'] = model_data.get('downloads_all_time') or model_data.get('downloads', 0) or 0
        model_data['fetched_at'] = datetime.now().isoformat()

        return model_data

    except Exception as e:
        print(f"    âŒ è·å–æ¨¡å‹ {model_id} ä¿¡æ¯å¤±è´¥: {e}")
        return None


def search_models_with_keyword(keyword: str, exclude_ids: Set[str] = None) -> List[Dict]:
    """
    é€šè¿‡å…³é”®è¯æœç´¢æ¨¡å‹

    Args:
        keyword: æœç´¢å…³é”®è¯
        exclude_ids: éœ€è¦æ’é™¤çš„æ¨¡å‹ ID é›†åˆï¼ˆå·²åœ¨ Model Tree ä¸­è·å–çš„ï¼‰

    Returns:
        List[Dict]: æœç´¢åˆ°çš„æ¨¡å‹ä¿¡æ¯åˆ—è¡¨
    """
    if exclude_ids is None:
        exclude_ids = set()

    print(f"\nğŸ” æœç´¢åŒ…å« '{keyword}' çš„æ¨¡å‹...")

    try:
        search_results = list(list_models(
            search=keyword,
            full=True,
            limit=1000,
            sort="downloads",
            direction=-1
        ))

        print(f"  âœ… æœç´¢åˆ° {len(search_results)} ä¸ªæ¨¡å‹")

        # è¿‡æ»¤æ‰å·²ç»åœ¨ Model Tree ä¸­çš„æ¨¡å‹
        filtered_results = []
        for model in search_results:
            if model.id not in exclude_ids:
                filtered_results.append(model)

        print(f"  âœ… å»é‡åå‰©ä½™ {len(filtered_results)} ä¸ªæ–°æ¨¡å‹")
        return filtered_results

    except Exception as e:
        print(f"  âŒ æœç´¢å¤±è´¥: {e}")
        return []


def get_model_tree_and_search(base_model_id: str, search_keywords: List[str] = None) -> Dict:
    """
    è·å–æŒ‡å®šæ¨¡å‹çš„å®Œæ•´ Model Tree å’Œ Search ä¿¡æ¯

    Args:
        base_model_id: åŸºç¡€æ¨¡å‹ ID
        search_keywords: ç”¨äºæœç´¢è¡ç”Ÿæ¨¡å‹çš„å…³é”®è¯åˆ—è¡¨

    Returns:
        Dict: åŒ…å«åŸºç¡€æ¨¡å‹ä¿¡æ¯å’Œè¡ç”Ÿæ¨¡å‹åˆ—è¡¨çš„å­—å…¸
    """
    print(f"\n{'='*80}")
    print(f"ğŸ“Š è·å– {base_model_id} çš„ Model Tree å’Œ Search æ•°æ®")
    print(f"{'='*80}")

    result = {
        'base_model_id': base_model_id,
        'base_model_info': None,
        'derivatives': []
    }

    # è·å–åŸºç¡€æ¨¡å‹ä¿¡æ¯
    print(f"\n1ï¸âƒ£ è·å–åŸºç¡€æ¨¡å‹ä¿¡æ¯...")
    base_info = get_all_model_info_fields(base_model_id)
    if not base_info:
        print(f"  âŒ æ— æ³•è·å–åŸºç¡€æ¨¡å‹ {base_model_id} çš„ä¿¡æ¯")
        return result

    result['base_model_info'] = base_info
    print(f"  âœ… åŸºç¡€æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ | ä¸‹è½½é‡: {base_info.get('download_count', 0):,}")

    # ç”¨äºè®°å½•å·²è·å–çš„æ¨¡å‹ ID
    seen_model_ids = {base_model_id}

    # è·å– Model Tree è¡ç”Ÿæ¨¡å‹
    print(f"\n2ï¸âƒ£ æŸ¥æ‰¾ Model Tree è¡ç”Ÿæ¨¡å‹...")
    model_tree_derivatives = []
    try:
        derivatives = list(list_models(
            filter=f"base_model:{base_model_id}",
            full=True,
            limit=1000
        ))

        if derivatives:
            print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ª Model Tree è¡ç”Ÿæ¨¡å‹")
            model_tree_derivatives = derivatives
        else:
            print(f"  âšª æ²¡æœ‰æ‰¾åˆ° Model Tree è¡ç”Ÿæ¨¡å‹")
    except Exception as e:
        print(f"  âŒ æŸ¥æ‰¾ Model Tree è¡ç”Ÿæ¨¡å‹å¤±è´¥: {e}")

    # è·å– Model Tree è¡ç”Ÿæ¨¡å‹è¯¦æƒ…
    if model_tree_derivatives:
        print(f"\n3ï¸âƒ£ è·å– Model Tree è¡ç”Ÿæ¨¡å‹è¯¦ç»†ä¿¡æ¯...")
        for idx, deriv in enumerate(model_tree_derivatives, 1):
            print(f"  [{idx}/{len(model_tree_derivatives)}] {deriv.id}")

            deriv_info = get_all_model_info_fields(deriv.id)
            if deriv_info:
                # ç¡®ä¿å­—æ®µæ­£ç¡®
                if 'modelId' not in deriv_info or not deriv_info['modelId']:
                    deriv_info['modelId'] = deriv.id
                if 'author' not in deriv_info or not deriv_info['author']:
                    deriv_info['author'] = deriv.author if hasattr(deriv, 'author') else ''

                deriv_info['base_model'] = base_model_id
                deriv_info['data_source'] = 'model_tree'
                result['derivatives'].append(deriv_info)
                seen_model_ids.add(deriv.id)

                print(f"     âœ… ä¸‹è½½é‡: {deriv_info.get('download_count', 0):,} | ç±»å‹: {deriv_info.get('model_type', 'N/A')}")

    # é€šè¿‡ Search æŸ¥æ‰¾è¡ç”Ÿæ¨¡å‹
    if search_keywords:
        print(f"\n4ï¸âƒ£ é€šè¿‡å…³é”®è¯æœç´¢è¡ç”Ÿæ¨¡å‹...")
        for keyword in search_keywords:
            search_results = search_models_with_keyword(keyword, exclude_ids=seen_model_ids)

            if search_results:
                print(f"\n5ï¸âƒ£ è·å– Search è¡ç”Ÿæ¨¡å‹è¯¦ç»†ä¿¡æ¯ (å…³é”®è¯: {keyword})...")
                for idx, model in enumerate(search_results, 1):
                    # è·³è¿‡åŸºç¡€æ¨¡å‹æœ¬èº«
                    if model.id == base_model_id:
                        continue

                    # è·³è¿‡å·²å¤„ç†çš„æ¨¡å‹
                    if model.id in seen_model_ids:
                        continue

                    print(f"  [{idx}/{len(search_results)}] {model.id}")

                    deriv_info = get_all_model_info_fields(model.id)
                    if deriv_info:
                        # ç¡®ä¿å­—æ®µæ­£ç¡®
                        if 'modelId' not in deriv_info or not deriv_info['modelId']:
                            deriv_info['modelId'] = model.id
                        if 'author' not in deriv_info or not deriv_info['author']:
                            deriv_info['author'] = model.author if hasattr(model, 'author') else ''

                        # Search è·å–çš„æ¨¡å‹å¯èƒ½æ²¡æœ‰ base_modelï¼Œå°è¯•æ¨æ–­
                        deriv_info['base_model'] = base_model_id
                        deriv_info['data_source'] = 'search'
                        result['derivatives'].append(deriv_info)
                        seen_model_ids.add(model.id)

                        print(f"     âœ… ä¸‹è½½é‡: {deriv_info.get('download_count', 0):,} | ç±»å‹: {deriv_info.get('model_type', 'N/A')}")

    print(f"\nğŸ“Š æ±‡æ€»:")
    print(f"  æ€»è¡ç”Ÿæ¨¡å‹æ•°: {len(result['derivatives'])}")
    model_tree_count = sum(1 for d in result['derivatives'] if d.get('data_source') == 'model_tree')
    search_count = sum(1 for d in result['derivatives'] if d.get('data_source') == 'search')
    print(f"  - Model Tree: {model_tree_count}")
    print(f"  - Search: {search_count}")

    return result


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è·å– ERNIE æ¨¡å‹æ•°æ®")
    print(f"ERNIE-4.5 æ¨¡å‹æ•°: {len(ERNIE_45_MODELS)}")
    print(f"PaddleOCR-VL æ¨¡å‹æ•°: {len(PADDLEOCR_VL_MODELS)}")
    print(f"æ€»è®¡: {len(ERNIE_45_MODELS) + len(PADDLEOCR_VL_MODELS)} ä¸ªæ¨¡å‹")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # ========== ERNIE-4.5 ç³»åˆ— ==========
    print(f"\n{'#'*80}")
    print("ğŸ“¦ å¤„ç† ERNIE-4.5 ç³»åˆ—")
    print(f"{'#'*80}")

    # 1. å…¨å±€æœç´¢ "ERNIE-4.5"
    print(f"\n{'='*80}")
    print(f"ğŸ” æ­¥éª¤ 1: å…¨å±€æœç´¢ 'ERNIE-4.5'")
    print(f"{'='*80}")
    ernie_45_search_results = search_models_with_keyword("ERNIE-4.5", exclude_ids=set())

    # ç”¨äºå­˜å‚¨æ‰€æœ‰æ¨¡å‹ä¿¡æ¯
    ernie_45_all_models = {}

    # æ·»åŠ æœç´¢åˆ°çš„æ¨¡å‹
    print(f"\nè·å–æœç´¢æ¨¡å‹è¯¦ç»†ä¿¡æ¯...")
    for idx, model in enumerate(ernie_45_search_results, 1):
        print(f"  [{idx}/{len(ernie_45_search_results)}] {model.id}")
        model_data = get_all_model_info_fields(model.id)
        if model_data:
            model_data['modelId'] = model.id
            model_data['author'] = model.author if hasattr(model, 'author') else model_data.get('author', '')
            model_data['data_source'] = 'search'

            # å°è¯•è®¾ç½® base_model
            if 'base_model_from_api' in model_data and model_data['base_model_from_api']:
                model_data['base_model'] = model_data['base_model_from_api']
                print(f"     âœ… base_model (ä»API): {model_data['base_model']}")

            ernie_45_all_models[model.id] = model_data
            print(f"     âœ… ä¸‹è½½é‡: {model_data.get('download_count', 0):,} | created_at: {model_data.get('created_at', 'N/A')}")

    # 2. è·å–å®˜æ–¹æ¨¡å‹çš„ Model Tree
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ­¥éª¤ 2: è·å–å®˜æ–¹æ¨¡å‹çš„ Model Tree")
    print(f"{'='*80}")

    for model_id in ERNIE_45_MODELS:
        print(f"\nå¤„ç†å®˜æ–¹æ¨¡å‹: {model_id}")

        # å¦‚æœå®˜æ–¹æ¨¡å‹ä¸åœ¨æœç´¢ç»“æœä¸­ï¼Œå•ç‹¬è·å–
        if model_id not in ernie_45_all_models:
            print(f"  è·å–å®˜æ–¹æ¨¡å‹ä¿¡æ¯...")
            base_info = get_all_model_info_fields(model_id)
            if base_info:
                base_info['modelId'] = model_id
                base_info['data_source'] = 'original'
                ernie_45_all_models[model_id] = base_info
                print(f"  âœ… å®˜æ–¹æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ")
        else:
            # æ ‡è®°ä¸ºå®˜æ–¹æ¨¡å‹
            ernie_45_all_models[model_id]['data_source'] = 'original'
            print(f"  âœ… å®˜æ–¹æ¨¡å‹å·²åœ¨æœç´¢ç»“æœä¸­")

        # è·å–è¯¥å®˜æ–¹æ¨¡å‹çš„ Model Tree
        print(f"  è·å– Model Tree...")
        try:
            derivatives = list(list_models(
                filter=f"base_model:{model_id}",
                full=True,
                limit=1000
            ))

            if derivatives:
                print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ª Model Tree è¡ç”Ÿæ¨¡å‹")
                for idx, deriv in enumerate(derivatives, 1):
                    if deriv.id not in ernie_45_all_models:
                        # æ–°æ¨¡å‹ï¼Œå®Œæ•´è·å–ä¿¡æ¯
                        print(f"    [{idx}/{len(derivatives)}] {deriv.id}")
                        deriv_info = get_all_model_info_fields(deriv.id)
                        if deriv_info:
                            deriv_info['modelId'] = deriv.id
                            deriv_info['author'] = deriv.author if hasattr(deriv, 'author') else deriv_info.get('author', '')
                            deriv_info['base_model'] = model_id  # ä¿å­˜ base_model
                            deriv_info['data_source'] = 'model_tree'
                            ernie_45_all_models[deriv.id] = deriv_info
                            print(f"       âœ… ä¸‹è½½é‡: {deriv_info.get('download_count', 0):,} | created_at: {deriv_info.get('created_at', 'N/A')}")
                    else:
                        # æ¨¡å‹å·²å­˜åœ¨ï¼ˆä¹‹å‰é€šè¿‡ search æ·»åŠ çš„ï¼‰ï¼Œæ›´æ–° base_model å’Œ data_source
                        print(f"    [{idx}/{len(derivatives)}] {deriv.id} (å·²å­˜åœ¨ï¼Œæ›´æ–° base_model)")
                        ernie_45_all_models[deriv.id]['base_model'] = model_id
                        ernie_45_all_models[deriv.id]['data_source'] = 'both'  # åŒæ—¶åœ¨ search å’Œ model_tree é‡Œ
            else:
                print(f"  âšª æ²¡æœ‰æ‰¾åˆ° Model Tree è¡ç”Ÿæ¨¡å‹")
        except Exception as e:
            print(f"  âŒ è·å– Model Tree å¤±è´¥: {e}")

    # ========== PaddleOCR-VL ç³»åˆ— ==========
    print(f"\n{'#'*80}")
    print("ğŸ“¦ å¤„ç† PaddleOCR-VL ç³»åˆ—")
    print(f"{'#'*80}")

    # 1. å…¨å±€æœç´¢ "PaddleOCR-VL"
    print(f"\n{'='*80}")
    print(f"ğŸ” æ­¥éª¤ 1: å…¨å±€æœç´¢ 'PaddleOCR-VL'")
    print(f"{'='*80}")
    paddleocr_vl_search_results = search_models_with_keyword("PaddleOCR-VL", exclude_ids=set())

    paddleocr_vl_all_models = {}

    # æ·»åŠ æœç´¢åˆ°çš„æ¨¡å‹
    print(f"\nè·å–æœç´¢æ¨¡å‹è¯¦ç»†ä¿¡æ¯...")
    for idx, model in enumerate(paddleocr_vl_search_results, 1):
        print(f"  [{idx}/{len(paddleocr_vl_search_results)}] {model.id}")
        model_data = get_all_model_info_fields(model.id)
        if model_data:
            model_data['modelId'] = model.id
            model_data['author'] = model.author if hasattr(model, 'author') else model_data.get('author', '')
            model_data['data_source'] = 'search'

            # å°è¯•è®¾ç½® base_model
            if 'base_model_from_api' in model_data and model_data['base_model_from_api']:
                model_data['base_model'] = model_data['base_model_from_api']
                print(f"     âœ… base_model (ä»API): {model_data['base_model']}")

            paddleocr_vl_all_models[model.id] = model_data
            print(f"     âœ… ä¸‹è½½é‡: {model_data.get('download_count', 0):,} | created_at: {model_data.get('created_at', 'N/A')}")

    # 2. è·å–å®˜æ–¹æ¨¡å‹çš„ Model Tree
    print(f"\n{'='*80}")
    print(f"ğŸ“Š æ­¥éª¤ 2: è·å–å®˜æ–¹æ¨¡å‹çš„ Model Tree")
    print(f"{'='*80}")

    for model_id in PADDLEOCR_VL_MODELS:
        print(f"\nå¤„ç†å®˜æ–¹æ¨¡å‹: {model_id}")

        # å¦‚æœå®˜æ–¹æ¨¡å‹ä¸åœ¨æœç´¢ç»“æœä¸­ï¼Œå•ç‹¬è·å–
        if model_id not in paddleocr_vl_all_models:
            print(f"  è·å–å®˜æ–¹æ¨¡å‹ä¿¡æ¯...")
            base_info = get_all_model_info_fields(model_id)
            if base_info:
                base_info['modelId'] = model_id
                base_info['data_source'] = 'original'
                paddleocr_vl_all_models[model_id] = base_info
                print(f"  âœ… å®˜æ–¹æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ")
        else:
            # æ ‡è®°ä¸ºå®˜æ–¹æ¨¡å‹
            paddleocr_vl_all_models[model_id]['data_source'] = 'original'
            print(f"  âœ… å®˜æ–¹æ¨¡å‹å·²åœ¨æœç´¢ç»“æœä¸­")

        # è·å–è¯¥å®˜æ–¹æ¨¡å‹çš„ Model Tree
        print(f"  è·å– Model Tree...")
        try:
            derivatives = list(list_models(
                filter=f"base_model:{model_id}",
                full=True,
                limit=1000
            ))

            if derivatives:
                print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ª Model Tree è¡ç”Ÿæ¨¡å‹")
                for idx, deriv in enumerate(derivatives, 1):
                    if deriv.id not in paddleocr_vl_all_models:
                        # æ–°æ¨¡å‹ï¼Œå®Œæ•´è·å–ä¿¡æ¯
                        print(f"    [{idx}/{len(derivatives)}] {deriv.id}")
                        deriv_info = get_all_model_info_fields(deriv.id)
                        if deriv_info:
                            deriv_info['modelId'] = deriv.id
                            deriv_info['author'] = deriv.author if hasattr(deriv, 'author') else deriv_info.get('author', '')
                            deriv_info['base_model'] = model_id  # ä¿å­˜ base_model
                            deriv_info['data_source'] = 'model_tree'
                            paddleocr_vl_all_models[deriv.id] = deriv_info
                            print(f"       âœ… ä¸‹è½½é‡: {deriv_info.get('download_count', 0):,} | created_at: {deriv_info.get('created_at', 'N/A')}")
                    else:
                        # æ¨¡å‹å·²å­˜åœ¨ï¼ˆä¹‹å‰é€šè¿‡ search æ·»åŠ çš„ï¼‰ï¼Œæ›´æ–° base_model å’Œ data_source
                        print(f"    [{idx}/{len(derivatives)}] {deriv.id} (å·²å­˜åœ¨ï¼Œæ›´æ–° base_model)")
                        paddleocr_vl_all_models[deriv.id]['base_model'] = model_id
                        paddleocr_vl_all_models[deriv.id]['data_source'] = 'both'  # åŒæ—¶åœ¨ search å’Œ model_tree é‡Œ
            else:
                print(f"  âšª æ²¡æœ‰æ‰¾åˆ° Model Tree è¡ç”Ÿæ¨¡å‹")
        except Exception as e:
            print(f"  âŒ è·å– Model Tree å¤±è´¥: {e}")

    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # åˆ›å»º DataFrame
    def create_dataframe(all_models_dict, official_model_ids):
        """
        å°†æ¨¡å‹å­—å…¸è½¬æ¢ä¸º DataFrame

        Args:
            all_models_dict: æ‰€æœ‰æ¨¡å‹ä¿¡æ¯çš„å­—å…¸ {model_id: model_info}
            official_model_ids: å®˜æ–¹æ¨¡å‹ ID åˆ—è¡¨
        """
        data = []

        for model_id, model_info in all_models_dict.items():
            # åˆ¤æ–­æ˜¯å¦æ˜¯å®˜æ–¹åŸºç¡€æ¨¡å‹
            is_base = model_id in official_model_ids

            # å°è¯•ä»æ¨¡å‹ä¿¡æ¯ä¸­æ¨æ–­ base_model
            base_model = model_id if is_base else ''

            # å¯¹äºè¡ç”Ÿæ¨¡å‹ï¼Œå°è¯•ä»åç§°æˆ–å…¶ä»–ä¿¡æ¯æ¨æ–­ base_model
            if not is_base:
                # æ£€æŸ¥æ˜¯å¦æœ‰æ˜ç¡®çš„ base_model å­—æ®µï¼ˆä» Model Tree è·å–çš„ï¼‰
                if 'base_model' in model_info and model_info['base_model']:
                    base_model = model_info['base_model']
                else:
                    # å°è¯•ä»æ¨¡å‹åç§°æ¨æ–­
                    for official_id in official_model_ids:
                        official_name = official_id.split('/')[-1]
                        if official_name in model_id:
                            base_model = official_id
                            break

            row = {
                'model_id': model_id,
                'base_model': base_model,
                'model_group': extract_model_group(base_model) if base_model else extract_model_group(model_id),
                'is_base': is_base,
                'data_source': model_info.get('data_source', 'unknown'),
                'model_name': model_id.split('/')[-1],
                'publisher': model_info.get('author', ''),
                'model_type': model_info.get('model_type', ''),
                'download_count': model_info.get('download_count', 0),
                'likes': model_info.get('likes', 0),
                'library_name': model_info.get('library_name', ''),
                'pipeline_tag': model_info.get('pipeline_tag', ''),
                'created_at': model_info.get('created_at', ''),
                'last_modified': model_info.get('last_modified', ''),
                'fetched_at': model_info.get('fetched_at', '')
            }
            data.append(row)

        return pd.DataFrame(data)

    # åˆ›å»ºä¸¤ä¸ª DataFrame
    df_ernie_45 = create_dataframe(ernie_45_all_models, ERNIE_45_MODELS)
    df_paddleocr_vl = create_dataframe(paddleocr_vl_all_models, PADDLEOCR_VL_MODELS)

    # åˆ›å»ºç»Ÿè®¡æ±‡æ€»
    def create_stats(df, series_name):
        """åˆ›å»ºç»Ÿè®¡æ±‡æ€»è¡¨"""
        stats_data = []

        # æŒ‰ model_group åˆ†ç»„ç»Ÿè®¡ï¼ˆåŒ…æ‹¬æ‰€æœ‰ model_groupï¼Œä¸åªæ˜¯å®˜æ–¹çš„ï¼‰
        all_model_groups = df[df['is_base'] == False]['model_group'].unique()

        for group_name in all_model_groups:
            # è·å–è¯¥åˆ†ç»„çš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹
            derivatives = df[(df['model_group'] == group_name) & (df['is_base'] == False)]

            if len(derivatives) == 0:
                continue

            # ç»Ÿè®¡å„ç±»å‹æ•°é‡å’Œä¸‹è½½é‡
            type_stats = {}
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                type_models = derivatives[derivatives['model_type'] == model_type]
                type_stats[f'{model_type}_count'] = len(type_models)
                type_stats[f'{model_type}_downloads'] = int(type_models['download_count'].sum())

            # æ€»è®¡
            total_derivatives = len(derivatives)
            total_downloads = int(derivatives['download_count'].sum())

            # è®¡ç®—ç™¾åˆ†æ¯”
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                count = type_stats[f'{model_type}_count']
                downloads = type_stats[f'{model_type}_downloads']
                type_stats[f'{model_type}_count_pct'] = f"{count/total_derivatives*100:.1f}%" if total_derivatives > 0 else "0%"
                type_stats[f'{model_type}_downloads_pct'] = f"{downloads/total_downloads*100:.1f}%" if total_downloads > 0 else "0%"

            stats_row = {
                'series': series_name,
                'model_group': group_name,
                'total_derivatives': total_derivatives,
                'total_downloads': total_downloads,
                **type_stats
            }
            stats_data.append(stats_row)

        # æŒ‰ total_downloads é™åºæ’åº
        stats_df = pd.DataFrame(stats_data)
        if len(stats_df) > 0:
            stats_df = stats_df.sort_values('total_downloads', ascending=False)

        return stats_df

    stats_ernie_45 = create_stats(df_ernie_45, 'ERNIE-4.5')
    stats_paddleocr_vl = create_stats(df_paddleocr_vl, 'PaddleOCR-VL')
    stats_combined = pd.concat([stats_ernie_45, stats_paddleocr_vl], ignore_index=True)

    # ä¿å­˜åˆ° Excelï¼ˆ3ä¸ª sheetï¼‰
    excel_filename = f"ernie_model_tree_{timestamp}.xlsx"
    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
        # Sheet 1: ç»Ÿè®¡æ±‡æ€»
        stats_combined.to_excel(writer, sheet_name='ç»Ÿè®¡æ±‡æ€»', index=False)
        # Sheet 2: ERNIE-4.5
        df_ernie_45.to_excel(writer, sheet_name='ERNIE-4.5', index=False)
        # Sheet 3: PaddleOCR-VL
        df_paddleocr_vl.to_excel(writer, sheet_name='PaddleOCR-VL', index=False)

    print(f"\nâœ… Excel æ•°æ®å·²ä¿å­˜åˆ°: {excel_filename}")
    print(f"   - ç»Ÿè®¡æ±‡æ€»: æŒ‰æ¨¡å‹åˆ†ç»„çš„ç»Ÿè®¡ï¼ˆåŒ…å«æ•°é‡å’Œä¸‹è½½é‡ç™¾åˆ†æ¯”ï¼‰")
    print(f"   - ERNIE-4.5: {len(df_ernie_45)} æ¡è®°å½•")
    print(f"   - PaddleOCR-VL: {len(df_paddleocr_vl)} æ¡è®°å½•")

    # ç»Ÿè®¡ data_source åˆ†å¸ƒ
    print(f"\nğŸ“Š æ•°æ®æ¥æºç»Ÿè®¡:")
    print(f"   ERNIE-4.5:")
    if len(df_ernie_45) > 0:
        for source in ['original', 'model_tree', 'search']:
            count = len(df_ernie_45[df_ernie_45['data_source'] == source])
            if count > 0:
                print(f"     - {source}: {count} æ¡")
    print(f"   PaddleOCR-VL:")
    if len(df_paddleocr_vl) > 0:
        for source in ['original', 'model_tree', 'search']:
            count = len(df_paddleocr_vl[df_paddleocr_vl['data_source'] == source])
            if count > 0:
                print(f"     - {source}: {count} æ¡")

    print(f"\nâœ… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
