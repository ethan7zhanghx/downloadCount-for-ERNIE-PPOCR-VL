"""
è·å– Qwen æ¨¡å‹çš„ Model Tree æ•°æ® - ç‰ˆæœ¬2
æ”¯æŒ Qwen3 å’Œ Qwen3-VL åˆ†å¼€ç»Ÿè®¡ï¼Œå¹¶æŒ‰æ¨¡å‹åˆ†ç»„
"""
from huggingface_hub import list_models, model_info
from datetime import datetime
import pandas as pd
import json
import re
from typing import List, Dict
import sys
sys.path.append('/Users/zhanghaoxin/Desktop/Baidu/DownloadData')
from ernie_tracker.fetchers.fetchers_modeltree import classify_model, classify_model_type


# è¦è·å–çš„ Qwen æ¨¡å‹åˆ—è¡¨
# Qwen3 ç³»åˆ—
QWEN3_MODELS = [
    # 2507 ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-Thinking-2507-FP8",
    "Qwen/Qwen3-235B-A22B-Thinking-2507",
    "Qwen/Qwen3-235B-A22B-Instruct-2507-FP8",
    "Qwen/Qwen3-235B-A22B-Instruct-2507",
    "Qwen/Qwen3-30B-A3B-Thinking-2507-FP8",
    "Qwen/Qwen3-30B-A3B-Thinking-2507",
    "Qwen/Qwen3-30B-A3B-Instruct-2507-FP8",
    "Qwen/Qwen3-30B-A3B-Instruct-2507",
    "Qwen/Qwen3-4B-Thinking-2507-FP8",
    "Qwen/Qwen3-4B-Thinking-2507",
    "Qwen/Qwen3-4B-Instruct-2507-FP8",
    "Qwen/Qwen3-4B-Instruct-2507",
    # åŸºç¡€ç³»åˆ—
    "Qwen/Qwen3-235B-A22B",
    "Qwen/Qwen3-30B-A3B",
    "Qwen/Qwen3-32B",
    "Qwen/Qwen3-14B",
    "Qwen/Qwen3-8B",
    "Qwen/Qwen3-4B",
    "Qwen/Qwen3-1.7B",
    "Qwen/Qwen3-0.6B",
    # FP8 ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-FP8",
    "Qwen/Qwen3-30B-A3B-FP8",
    "Qwen/Qwen3-32B-FP8",
    "Qwen/Qwen3-14B-FP8",
    "Qwen/Qwen3-8B-FP8",
    "Qwen/Qwen3-4B-FP8",
    "Qwen/Qwen3-1.7B-FP8",
    "Qwen/Qwen3-0.6B-FP8",
    # GPTQ/AWQ ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-GPTQ-Int4",
    "Qwen/Qwen3-30B-A3B-GPTQ-Int4",
    "Qwen/Qwen3-32B-AWQ",
    "Qwen/Qwen3-14B-AWQ",
    "Qwen/Qwen3-8B-AWQ",
    "Qwen/Qwen3-4B-AWQ",
    "Qwen/Qwen3-1.7B-GPTQ-Int8",
    "Qwen/Qwen3-0.6B-GPTQ-Int8",
    # GGUF ç³»åˆ—
    "Qwen/Qwen3-235B-A22B-GGUF",
    "Qwen/Qwen3-30B-A3B-GGUF",
    "Qwen/Qwen3-32B-GGUF",
    "Qwen/Qwen3-14B-GGUF",
    "Qwen/Qwen3-8B-GGUF",
    "Qwen/Qwen3-4B-GGUF",
    "Qwen/Qwen3-1.7B-GGUF",
    "Qwen/Qwen3-0.6B-GGUF",
    # Base ç³»åˆ—
    "Qwen/Qwen3-30B-A3B-Base",
    "Qwen/Qwen3-14B-Base",
    "Qwen/Qwen3-8B-Base",
    "Qwen/Qwen3-4B-Base",
    "Qwen/Qwen3-1.7B-Base",
    "Qwen/Qwen3-0.6B-Base",
    # MLX ç³»åˆ—
    "Qwen/Qwen3-4B-MLX-8bit",
    "Qwen/Qwen3-4B-MLX-bf16",
    "Qwen/Qwen3-4B-MLX-6bit",
    "Qwen/Qwen3-4B-MLX-4bit",
    "Qwen/Qwen3-8B-MLX-4bit",
    "Qwen/Qwen3-8B-MLX-6bit",
    "Qwen/Qwen3-8B-MLX-8bit",
    "Qwen/Qwen3-8B-MLX-bf16",
    "Qwen/Qwen3-0.6B-MLX-6bit",
    "Qwen/Qwen3-0.6B-MLX-4bit",
    "Qwen/Qwen3-0.6B-MLX-bf16",
    "Qwen/Qwen3-0.6B-MLX-8bit",
    "Qwen/Qwen3-32B-MLX-8bit",
    "Qwen/Qwen3-1.7B-MLX-6bit",
    "Qwen/Qwen3-1.7B-MLX-bf16",
    "Qwen/Qwen3-1.7B-MLX-8bit",
    "Qwen/Qwen3-1.7B-MLX-4bit",
    "Qwen/Qwen3-14B-MLX-6bit",
    "Qwen/Qwen3-14B-MLX-8bit",
    "Qwen/Qwen3-14B-MLX-4bit",
    "Qwen/Qwen3-14B-MLX-bf16",
    "Qwen/Qwen3-32B-MLX-6bit",
    "Qwen/Qwen3-32B-MLX-bf16",
    "Qwen/Qwen3-32B-MLX-4bit",
    "Qwen/Qwen3-30B-A3B-MLX-4bit",
    "Qwen/Qwen3-30B-A3B-MLX-bf16",
    "Qwen/Qwen3-30B-A3B-MLX-8bit",
    "Qwen/Qwen3-30B-A3B-MLX-6bit",
    "Qwen/Qwen3-235B-A22B-MLX-bf16",
    "Qwen/Qwen3-235B-A22B-MLX-6bit",
    "Qwen/Qwen3-235B-A22B-MLX-4bit",
    "Qwen/Qwen3-235B-A22B-MLX-8bit",
]

# Qwen3-VL ç³»åˆ—
QWEN3_VL_MODELS = [
    # Thinking/Instruct ç³»åˆ—
    "Qwen/Qwen3-VL-235B-A22B-Thinking",
    "Qwen/Qwen3-VL-235B-A22B-Instruct",
    "Qwen/Qwen3-VL-235B-A22B-Thinking-FP8",
    "Qwen/Qwen3-VL-235B-A22B-Instruct-FP8",
    "Qwen/Qwen3-VL-30B-A3B-Thinking",
    "Qwen/Qwen3-VL-30B-A3B-Instruct",
    "Qwen/Qwen3-VL-30B-A3B-Thinking-FP8",
    "Qwen/Qwen3-VL-30B-A3B-Instruct-FP8",
    "Qwen/Qwen3-VL-8B-Thinking",
    "Qwen/Qwen3-VL-8B-Instruct",
    "Qwen/Qwen3-VL-8B-Thinking-FP8",
    "Qwen/Qwen3-VL-8B-Instruct-FP8",
    "Qwen/Qwen3-VL-4B-Thinking",
    "Qwen/Qwen3-VL-4B-Instruct",
    "Qwen/Qwen3-VL-4B-Thinking-FP8",
    "Qwen/Qwen3-VL-4B-Instruct-FP8",
    "Qwen/Qwen3-VL-2B-Instruct",
    "Qwen/Qwen3-VL-2B-Thinking",
    "Qwen/Qwen3-VL-2B-Thinking-FP8",
    "Qwen/Qwen3-VL-32B-Instruct",
    "Qwen/Qwen3-VL-32B-Thinking",
    "Qwen/Qwen3-VL-32B-Thinking-FP8",
    "Qwen/Qwen3-VL-32B-Instruct-FP8",
    "Qwen/Qwen3-VL-2B-Instruct-FP8",
    # GGUF ç³»åˆ—
    "Qwen/Qwen3-VL-2B-Instruct-GGUF",
    "Qwen/Qwen3-VL-4B-Instruct-GGUF",
    "Qwen/Qwen3-VL-4B-Thinking-GGUF",
    "Qwen/Qwen3-VL-8B-Instruct-GGUF",
    "Qwen/Qwen3-VL-32B-Instruct-GGUF",
    "Qwen/Qwen3-VL-32B-Thinking-GGUF",
    "Qwen/Qwen3-VL-235B-A22B-Instruct-GGUF",
    "Qwen/Qwen3-VL-235B-A22B-Thinking-GGUF",
    "Qwen/Qwen3-VL-30B-A3B-Instruct-GGUF",
    "Qwen/Qwen3-VL-30B-A3B-Thinking-GGUF",
    "Qwen/Qwen3-VL-2B-Thinking-GGUF",
    "Qwen/Qwen3-VL-8B-Thinking-GGUF",
]


def extract_model_group(model_id: str) -> str:
    """
    æå–æ¨¡å‹åˆ†ç»„åç§°ï¼šæ‰¾åˆ°æœ€åä¸€æ¬¡å‡ºç°çš„"æ•°å­—+B"ï¼Œä¹‹åçš„å†…å®¹å»æ‰

    ä¾‹å¦‚ï¼š
    - Qwen/Qwen3-235B-A22B-Thinking-2507-FP8 â†’ Qwen3-235B-A22B
    - Qwen/Qwen3-4B-MLX-4bit â†’ Qwen3-4B
    - Qwen/Qwen3-VL-30B-A3B-Instruct â†’ Qwen3-VL-30B-A3B

    Args:
        model_id: å®Œæ•´çš„æ¨¡å‹ ID

    Returns:
        str: åˆ†ç»„åç§°
    """
    # å»æ‰ "Qwen/" å‰ç¼€
    model_name = model_id.replace('Qwen/', '')

    # åŒ¹é…æ‰€æœ‰çš„"æ•°å­—+B"æ¨¡å¼ï¼ˆåŒ…æ‹¬å°æ•°å’Œ A22B/A3B è¿™ç§æ ¼å¼ï¼‰
    # åŒ¹é…æ¨¡å¼ï¼šå¯é€‰çš„ A + æ•°å­—ï¼ˆå¯èƒ½åŒ…å«å°æ•°ç‚¹ï¼‰ + B
    # ä¾‹å¦‚ï¼š235B, 30B, A22B, A3B, 1.7B, 0.6B
    pattern = r'[A]?\d+(?:\.\d+)?B'

    # æ‰¾åˆ°æ‰€æœ‰åŒ¹é…
    matches = list(re.finditer(pattern, model_name, re.IGNORECASE))

    if not matches:
        # æ²¡æœ‰æ‰¾åˆ°åŒ¹é…ï¼Œè¿”å›åŸå§‹åç§°
        return model_name

    # è·å–æœ€åä¸€ä¸ªåŒ¹é…
    last_match = matches[-1]
    end_pos = last_match.end()

    # æˆªå–åˆ°æœ€åä¸€ä¸ª"æ•°å­—+B"çš„ä½ç½®
    group_name = model_name[:end_pos]

    return group_name


def get_all_model_info_fields(model_id: str) -> Dict:
    """è·å–æ¨¡å‹çš„æ‰€æœ‰ä¿¡æ¯å­—æ®µ"""
    try:
        info = model_info(model_id, expand=["downloadsAllTime", "trendingScore"])
        card_data = None
        if hasattr(info, 'cardData') and info.cardData:
            if isinstance(info.cardData, dict):
                card_data = info.cardData
            elif hasattr(info.cardData, '__dict__'):
                card_data = info.cardData.__dict__

        model_obj = None
        try:
            models = list(list_models(model_name=model_id, full=True, limit=1))
            if models:
                model_obj = models[0]
        except:
            pass

        model_data = {}

        # åŸºæœ¬å­—æ®µ
        if hasattr(info, 'modelId'):
            model_data['modelId'] = info.modelId
        if hasattr(info, 'author'):
            model_data['author'] = info.author
        if hasattr(info, 'downloads_all_time'):
            model_data['downloads_all_time'] = info.downloads_all_time
        if hasattr(info, 'downloads'):
            model_data['downloads'] = info.downloads
        if hasattr(info, 'likes'):
            model_data['likes'] = info.likes
        if hasattr(info, 'library_name'):
            model_data['library_name'] = info.library_name
        if hasattr(info, 'pipeline_tag'):
            model_data['pipeline_tag'] = info.pipeline_tag
        if hasattr(info, 'created_at'):
            model_data['created_at'] = info.created_at.isoformat() if hasattr(info.created_at, 'isoformat') else str(info.created_at)
        if hasattr(info, 'last_modified'):
            model_data['last_modified'] = info.last_modified.isoformat() if hasattr(info.last_modified, 'isoformat') else str(info.last_modified)

        # ä¼˜å…ˆä½¿ç”¨ model_info æä¾›çš„ tagsï¼Œå…¶æ¬¡ fallback åˆ° list_models è¿”å›çš„ tags
        if hasattr(info, 'tags') and info.tags:
            model_data['tags'] = info.tags
        elif model_obj and hasattr(model_obj, 'tags'):
            model_data['tags'] = model_obj.tags
        else:
            model_data['tags'] = []

        if model_obj and hasattr(model_obj, 'trending_score'):
            model_data['trending_score'] = model_obj.trending_score

        # åˆ†ç±»å­—æ®µ
        publisher = model_data.get('author', 'Unknown')
        tags = model_data.get('tags', [])
        pipeline_tag = model_data.get('pipeline_tag', None)

        model_data['model_category'] = classify_model(model_id, publisher)
        model_data['model_type'] = classify_model_type(model_id, tags, pipeline_tag, card_data)
        model_data['download_count'] = model_data.get('downloads_all_time') or model_data.get('downloads', 0) or 0
        model_data['fetched_at'] = datetime.now().isoformat()

        return model_data

    except Exception as e:
        print(f"    âŒ è·å–æ¨¡å‹ {model_id} ä¿¡æ¯å¤±è´¥: {e}")
        return None


def get_model_tree_with_full_info(base_model_id: str) -> Dict:
    """è·å–æŒ‡å®šæ¨¡å‹çš„å®Œæ•´ Model Tree ä¿¡æ¯"""
    print(f"\n{'='*80}")
    print(f"ğŸ“Š è·å– {base_model_id} çš„ Model Tree")
    print(f"{'='*80}")

    result = {
        'base_model_id': base_model_id,
        'base_model_info': None,
        'derivatives': []
    }

    # è·å–åŸºç¡€æ¨¡å‹ä¿¡æ¯
    print(f"\n1ï¸âƒ£ è·å–åŸºç¡€æ¨¡å‹ä¿¡æ¯...")
    base_info = get_all_model_info_fields(base_model_id)
    if not base_info:
        print(f"  âŒ æ— æ³•è·å–åŸºç¡€æ¨¡å‹ {base_model_id} çš„ä¿¡æ¯")
        return result

    result['base_model_info'] = base_info
    print(f"  âœ… åŸºç¡€æ¨¡å‹ä¿¡æ¯è·å–æˆåŠŸ | ä¸‹è½½é‡: {base_info.get('download_count', 0):,}")

    # è·å–è¡ç”Ÿæ¨¡å‹
    print(f"\n2ï¸âƒ£ æŸ¥æ‰¾è¡ç”Ÿæ¨¡å‹...")
    try:
        derivatives = list(list_models(
            filter=f"base_model:{base_model_id}",
            full=True,
            limit=1000
        ))

        if not derivatives:
            print(f"  âšª æ²¡æœ‰æ‰¾åˆ°è¡ç”Ÿæ¨¡å‹")
            return result

        print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ªè¡ç”Ÿæ¨¡å‹")
    except Exception as e:
        print(f"  âŒ æŸ¥æ‰¾è¡ç”Ÿæ¨¡å‹å¤±è´¥: {e}")
        return result

    # è·å–è¡ç”Ÿæ¨¡å‹è¯¦æƒ…
    print(f"\n3ï¸âƒ£ è·å–è¡ç”Ÿæ¨¡å‹è¯¦ç»†ä¿¡æ¯...")
    for idx, deriv in enumerate(derivatives, 1):
        print(f"  [{idx}/{len(derivatives)}] {deriv.id}")

        deriv_info = get_all_model_info_fields(deriv.id)
        if deriv_info:
            # ç¡®ä¿å­—æ®µæ­£ç¡®
            if 'modelId' not in deriv_info or not deriv_info['modelId']:
                deriv_info['modelId'] = deriv.id
            if 'author' not in deriv_info or not deriv_info['author']:
                deriv_info['author'] = deriv.author if hasattr(deriv, 'author') else ''

            deriv_info['base_model'] = base_model_id
            result['derivatives'].append(deriv_info)

            print(f"     âœ… ä¸‹è½½é‡: {deriv_info.get('download_count', 0):,} | ç±»å‹: {deriv_info.get('model_type', 'N/A')}")

    return result


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹è·å– Qwen æ¨¡å‹çš„ Model Tree æ•°æ®")
    print(f"Qwen3 æ¨¡å‹æ•°: {len(QWEN3_MODELS)}")
    print(f"Qwen3-VL æ¨¡å‹æ•°: {len(QWEN3_VL_MODELS)}")
    print(f"æ€»è®¡: {len(QWEN3_MODELS) + len(QWEN3_VL_MODELS)} ä¸ªæ¨¡å‹")
    print(f"å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # åˆ†åˆ«è·å–ä¸¤ä¸ªç³»åˆ—
    qwen3_results = {}
    qwen3_vl_results = {}

    print(f"\n{'#'*80}")
    print("ğŸ“¦ è·å– Qwen3 ç³»åˆ—")
    print(f"{'#'*80}")
    for model_id in QWEN3_MODELS:
        result = get_model_tree_with_full_info(model_id)
        qwen3_results[model_id] = result

    print(f"\n{'#'*80}")
    print("ğŸ“¦ è·å– Qwen3-VL ç³»åˆ—")
    print(f"{'#'*80}")
    for model_id in QWEN3_VL_MODELS:
        result = get_model_tree_with_full_info(model_id)
        qwen3_vl_results[model_id] = result

    # ä¿å­˜ç»“æœ
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # åˆ›å»º DataFrame
    def create_dataframe(results_dict):
        """å°†ç»“æœå­—å…¸è½¬æ¢ä¸º DataFrame"""
        data = []
        for base_model_id, result in results_dict.items():
            # æ·»åŠ åŸºç¡€æ¨¡å‹
            if result['base_model_info']:
                base_row = {
                    'model_id': base_model_id,
                    'base_model': base_model_id,
                    'model_group': extract_model_group(base_model_id),
                    'is_base': True,
                    'model_name': base_model_id.split('/')[-1],
                    'publisher': result['base_model_info'].get('author', ''),
                    'model_type': result['base_model_info'].get('model_type', ''),
                    'download_count': result['base_model_info'].get('download_count', 0),
                    'likes': result['base_model_info'].get('likes', 0),
                    'library_name': result['base_model_info'].get('library_name', ''),
                    'pipeline_tag': result['base_model_info'].get('pipeline_tag', ''),
                    'created_at': result['base_model_info'].get('created_at', ''),
                    'last_modified': result['base_model_info'].get('last_modified', ''),
                    'fetched_at': result['base_model_info'].get('fetched_at', '')
                }
                data.append(base_row)

            # æ·»åŠ è¡ç”Ÿæ¨¡å‹
            for deriv_info in result['derivatives']:
                deriv_row = {
                    'model_id': deriv_info.get('modelId', ''),
                    'base_model': base_model_id,
                    'model_group': extract_model_group(base_model_id),
                    'is_base': False,
                    'model_name': deriv_info.get('modelId', '').split('/')[-1] if deriv_info.get('modelId') else '',
                    'publisher': deriv_info.get('author', ''),
                    'model_type': deriv_info.get('model_type', ''),
                    'download_count': deriv_info.get('download_count', 0),
                    'likes': deriv_info.get('likes', 0),
                    'library_name': deriv_info.get('library_name', ''),
                    'pipeline_tag': deriv_info.get('pipeline_tag', ''),
                    'created_at': deriv_info.get('created_at', ''),
                    'last_modified': deriv_info.get('last_modified', ''),
                    'fetched_at': deriv_info.get('fetched_at', '')
                }
                data.append(deriv_row)

        return pd.DataFrame(data)

    # åˆ›å»ºä¸¤ä¸ª DataFrame
    df_qwen3 = create_dataframe(qwen3_results)
    df_qwen3_vl = create_dataframe(qwen3_vl_results)

    # åˆ›å»ºç»Ÿè®¡æ±‡æ€»
    def create_stats(df, series_name):
        """åˆ›å»ºç»Ÿè®¡æ±‡æ€»è¡¨"""
        stats_data = []

        # æŒ‰ model_group åˆ†ç»„ç»Ÿè®¡
        for group_name in df[df['is_base'] == True]['model_group'].unique():
            # è·å–è¯¥åˆ†ç»„çš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹
            derivatives = df[(df['model_group'] == group_name) & (df['is_base'] == False)]

            if len(derivatives) == 0:
                continue

            # ç»Ÿè®¡å„ç±»å‹æ•°é‡å’Œä¸‹è½½é‡
            type_stats = {}
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                type_models = derivatives[derivatives['model_type'] == model_type]
                type_stats[f'{model_type}_count'] = len(type_models)
                type_stats[f'{model_type}_downloads'] = int(type_models['download_count'].sum())

            # æ€»è®¡
            total_derivatives = len(derivatives)
            total_downloads = int(derivatives['download_count'].sum())

            # è®¡ç®—ç™¾åˆ†æ¯”
            for model_type in ['quantized', 'finetune', 'adapter', 'lora', 'merge', 'other']:
                count = type_stats[f'{model_type}_count']
                downloads = type_stats[f'{model_type}_downloads']
                type_stats[f'{model_type}_count_pct'] = f"{count/total_derivatives*100:.1f}%" if total_derivatives > 0 else "0%"
                type_stats[f'{model_type}_downloads_pct'] = f"{downloads/total_downloads*100:.1f}%" if total_downloads > 0 else "0%"

            stats_row = {
                'series': series_name,
                'model_group': group_name,
                'total_derivatives': total_derivatives,
                'total_downloads': total_downloads,
                **type_stats
            }
            stats_data.append(stats_row)

        return pd.DataFrame(stats_data)

    stats_qwen3 = create_stats(df_qwen3, 'Qwen3')
    stats_qwen3_vl = create_stats(df_qwen3_vl, 'Qwen3-VL')
    stats_combined = pd.concat([stats_qwen3, stats_qwen3_vl], ignore_index=True)

    # ä¿å­˜åˆ° Excelï¼ˆ3ä¸ª sheetï¼‰
    excel_filename = f"qwen_model_tree_{timestamp}.xlsx"
    with pd.ExcelWriter(excel_filename, engine='openpyxl') as writer:
        # Sheet 1: ç»Ÿè®¡æ±‡æ€»
        stats_combined.to_excel(writer, sheet_name='ç»Ÿè®¡æ±‡æ€»', index=False)
        # Sheet 2: Qwen3
        df_qwen3.to_excel(writer, sheet_name='Qwen3', index=False)
        # Sheet 3: Qwen3-VL
        df_qwen3_vl.to_excel(writer, sheet_name='Qwen3-VL', index=False)

    print(f"\nâœ… Excel æ•°æ®å·²ä¿å­˜åˆ°: {excel_filename}")
    print(f"   - ç»Ÿè®¡æ±‡æ€»: æŒ‰æ¨¡å‹åˆ†ç»„çš„ç»Ÿè®¡ï¼ˆåŒ…å«æ•°é‡å’Œä¸‹è½½é‡ç™¾åˆ†æ¯”ï¼‰")
    print(f"   - Qwen3: {len(df_qwen3)} æ¡è®°å½•")
    print(f"   - Qwen3-VL: {len(df_qwen3_vl)} æ¡è®°å½•")

    print(f"\nâœ… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")


if __name__ == "__main__":
    main()
