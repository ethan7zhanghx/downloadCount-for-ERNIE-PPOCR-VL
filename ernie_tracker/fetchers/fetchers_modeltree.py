"""
Model Tree åŠŸèƒ½æ¨¡å— - è·å–å®˜æ–¹æ¨¡å‹çš„è¡ç”Ÿæ¨¡å‹
æ”¯æŒè·å– Finetune å’Œ Adapter æ¨¡å‹ï¼Œå¹¶æ™ºèƒ½åˆ†ç±»
"""
from huggingface_hub import list_models, model_info
from datetime import date
import pandas as pd
import time
import re
from typing import List, Dict, Set, Tuple
from ..db import save_to_db, get_last_model_count, update_last_model_count
from ..config import DB_PATH


def classify_model(model_name: str, publisher: str, base_model: str = None) -> str:
    """
    æ™ºèƒ½åˆ†ç±»æ¨¡å‹

    Args:
        model_name: æ¨¡å‹åç§°
        publisher: å‘å¸ƒè€…
        base_model: åŸºç¡€æ¨¡å‹IDï¼ˆå¯é€‰ï¼Œç”¨äºè¡ç”Ÿæ¨¡å‹çš„åˆ†ç±»ï¼‰

    Returns:
        str: æ¨¡å‹ç±»åˆ« ('ernie-4.5', 'paddleocr-vl', 'other-ernie', 'other')
    """
    """
    ä»…è¿”å›ä¸¤ç±»ï¼šernie-4.5 æˆ– paddleocr-vlã€‚å…¶ä½™ä¸€å¾‹å½’å…¥ ernie-4.5ï¼ˆé¿å…å‡ºç° other/other-ernieï¼‰ã€‚
    """
    def _is_paddleocr(name: str) -> bool:
        n = name.lower()
        return 'paddleocr' in n and 'vl' in n

    base_lower = base_model.lower() if base_model else ''
    name_lower = model_name.lower()

    if _is_paddleocr(base_lower) or _is_paddleocr(name_lower):
        return 'paddleocr-vl'

    # é»˜è®¤å½’å…¥ ernie-4.5
    return 'ernie-4.5'


def classify_model_type(model_name: str, tags: list, pipeline_tag: str = None, card_data: dict = None) -> str:
    """
    è¯†åˆ«æ¨¡å‹ç±»å‹ï¼Œä¼˜å…ˆä½¿ç”¨ç»“æ„åŒ–ä¿¡æ¯ï¼ˆHF æ ‡ç­¾ / æ¨¡å‹å¡ï¼‰ï¼Œæœ€åå†åç§°å…œåº•

    Args:
        model_name: æ¨¡å‹åç§°
        tags: æ¨¡å‹æ ‡ç­¾åˆ—è¡¨ï¼ˆæ¥è‡ªHuggingFace APIï¼‰
        pipeline_tag: pipelineæ ‡ç­¾
        card_data: æ¨¡å‹å¡çš„å…ƒä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰

    Returns:
        str: æ¨¡å‹ç±»å‹
        - 'quantized': é‡åŒ–æ¨¡å‹
        - 'finetune': å¾®è°ƒæ¨¡å‹
        - 'adapter': Adapteræ¨¡å‹
        - 'lora': LoRAæ¨¡å‹
        - 'merge': åˆå¹¶æ¨¡å‹
        - 'original': å®˜æ–¹åŸå§‹æ¨¡å‹
        - 'other': å…¶ä»–
    """
    card_data_dict = card_data if isinstance(card_data, dict) else None

    # 1) æ ‡ç­¾ï¼šç»“æ„åŒ–ã€ä¼˜å…ˆçº§æœ€é«˜
    tags_lower = [tag.lower() for tag in tags] if tags else []
    for tag in tags_lower:
        if tag.startswith('base_model:quantized:'):
            return 'quantized'
        if tag.startswith('base_model:adapter:'):
            return 'adapter'
        if tag.startswith('base_model:lora:'):
            return 'lora'
        if tag.startswith('base_model:merge:'):
            return 'merge'
        if tag.startswith('base_model:finetune:'):
            return 'finetune'

    # 2) æ ‡ç­¾ï¼šPEFT ä¿¡å·
    peft_indicators = ['peft', 'prefix-tuning', 'prompt-tuning', 'adapter']
    if tags_lower and any(indicator in ' '.join(tags_lower) for indicator in peft_indicators):
        if any('lora' in tag for tag in tags_lower):
            return 'lora'
        return 'adapter'

    # 3) æ¨¡å‹å¡ï¼šä»…ä½¿ç”¨å¸¸è§ã€å›ºå®šå­—æ®µ
    if card_data_dict:
        card_type = _classify_by_card_data(card_data_dict)
        if card_type != 'other':
            return card_type

    # 4) å®˜æ–¹åŸå§‹æ¨¡å‹ï¼ˆæ—  base_model æ ‡ç­¾ï¼‰
    official_patterns = ['baidu/', 'paddlepaddle/']
    model_name_lower = model_name.lower()
    if any(pattern in model_name_lower for pattern in official_patterns):
        if not any(tag.startswith('base_model:') for tag in tags_lower):
            return 'original'

    # 5) åç§°å…œåº•ï¼ˆæœ€ä¸å¯é ï¼‰
    name_based_type = _classify_by_name_fallback(model_name)
    if name_based_type != 'other':
        return name_based_type

    return 'other'


def _classify_by_card_data(card_data: dict) -> str:
    """
    åŸºäºæ¨¡å‹å¡çš„å­—æ®µè¿›è¡Œåˆ†ç±»ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    """
    # é‡åŒ–ç›¸å…³å­—æ®µ
    quant_keys = [
        'quantization_config', 'quantization', 'quantization_bits',
        'load_in_4bit', 'load_in_8bit', 'bnb_4bit_quant_type', 'gguf'
    ]
    if any(key in card_data for key in quant_keys):
        return 'quantized'

    # PEFT / LoRA
    peft_type = str(card_data.get('peft_type', '') or '').lower()
    if 'lora' in peft_type:
        return 'lora'
    if peft_type:
        return 'adapter'

    if any(key in card_data for key in ['lora_alpha', 'lora_r', 'lora_dropout']):
        return 'lora'
    if any(key in card_data for key in ['adapters', 'adapter', 'adapter_config', 'adapter_name']):
        return 'adapter'

    # åˆå¹¶æ¨¡å‹
    if any(key in card_data for key in ['merge_method', 'merging_config', 'merge_config', 'merged_by']):
        return 'merge'

    # æ˜ç¡®çš„å¾®è°ƒé…ç½®å­—æ®µ
    finetune_keys = ['finetuning_type', 'finetuning_config', 'finetune_config']
    if any(key in card_data for key in finetune_keys):
        return 'finetune'

    return 'other'


def _classify_by_name_fallback(model_name: str) -> str:
    """
    å›é€€æ–¹æ¡ˆï¼šåŸºäºæ¨¡å‹åç§°è¿›è¡Œåˆ†ç±»ï¼ˆå½“æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯æ—¶ï¼‰

    Args:
        model_name: æ¨¡å‹åç§°

    Returns:
        str: æ¨¡å‹ç±»å‹
    """
    model_name_lower = model_name.lower()

    # Quantized ç›¸å…³å…³é”®è¯ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
    quantized_keywords = [
        # æ ¼å¼æ ‡è¯†
        '-gguf', '.gguf', 'gguf', '-gptq', '-awq', '-exl2',
        # é‡åŒ–ä½æ•° - é€šç”¨æ ¼å¼
        '-4bit', '-8bit', '-6bit', '-2bit',
        'int2', 'int4', 'int8',
        # Qç³»åˆ—é‡åŒ–
        '-q1_', '-q2_', '-q3_', '-q4_', '-q5_', '-q6_', '-q8_',
        'q1_', 'q2_', 'q3_', 'q4_', 'q5_', 'q6_', 'q8_',
        # ç²¾åº¦æ ¼å¼ï¼ˆä»…ä¿ç•™ fp8ï¼Œç§»é™¤ bf16/fp16 ä»¥å…è¯¯åˆ¤ï¼‰
        'fp8',
        # W/Aé‡åŒ–æ ¼å¼
        'w4a8', 'w4a16', 'w2a8', 'w8a8', 'w4a4',
        # MLXæ ¼å¼
        'mlx-4bit', 'mlx-8bit', 'mlx-6bit',
        # å…¶ä»–æ ‡è¯†
        '-quantized', '_quantized', 'quantized'
    ]
    if any(keyword in model_name_lower for keyword in quantized_keywords):
        return 'quantized'

    # LoRA ç›¸å…³å…³é”®è¯
    lora_keywords = ['lora', 'low-rank-adaptation', 'low-rank']
    if any(keyword in model_name_lower for keyword in lora_keywords):
        return 'lora'

    # Adapter ç›¸å…³å…³é”®è¯
    adapter_keywords = ['adapter', 'adapters', 'peft', 'prefix-tuning', 'prompt-tuning']
    if any(keyword in model_name_lower for keyword in adapter_keywords):
        return 'adapter'

    # Merge ç›¸å…³å…³é”®è¯
    merge_keywords = ['-merge', '_merge', '-merged', '_merged']
    if any(keyword in model_name_lower for keyword in merge_keywords):
        return 'merge'

    # Finetune ç›¸å…³å…³é”®è¯
    finetune_keywords = [
        'finetune', 'fine-tune', 'fine-tuned', 'finetuned',
        'custom-trained', 'custom-trained-model', 'trained-on'
    ]
    if any(keyword in model_name_lower for keyword in finetune_keywords):
        return 'finetune'

    # æ£€æŸ¥æ˜¯å¦ä¸ºå®˜æ–¹åŸå§‹æ¨¡å‹
    official_patterns = ['baidu/', 'paddlepaddle/']
    if any(pattern in model_name_lower for pattern in official_patterns):
        return 'original'

    return 'other'


def get_model_tree_children(base_model_id: str, max_depth: int = 1) -> List[Dict]:
    """
    è·å–æŒ‡å®šæ¨¡å‹çš„ç›´æ¥è¡ç”Ÿæ¨¡å‹ï¼ˆé€šè¿‡ HuggingFace API çš„ base_model filterï¼‰

    Args:
        base_model_id: åŸºç¡€æ¨¡å‹IDï¼ˆå¦‚ 'baidu/ERNIE-4.5-21B-A3B-PT'ï¼‰
        max_depth: æœç´¢æ·±åº¦ï¼Œé»˜è®¤ä¸º1ï¼ˆåªè·å–ç›´æ¥è¡ç”Ÿï¼‰

    Returns:
        List[Dict]: è¡ç”Ÿæ¨¡å‹ä¿¡æ¯åˆ—è¡¨
    """
    try:
        # éªŒè¯åŸºç¡€æ¨¡å‹å­˜åœ¨
        try:
            base_info = model_info(base_model_id)
            print(f"ğŸ“Š è·å– {base_model_id} çš„model tree...")
        except Exception as e:
            print(f"âš ï¸ åŸºç¡€æ¨¡å‹ {base_model_id} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {e}")
            return []

        # ä½¿ç”¨ HuggingFace å®˜æ–¹çš„ base_model filter åŠŸèƒ½
        # è¿™æ˜¯æ­£ç¡®çš„ Model Tree æŸ¥æ‰¾æ–¹æ³•
        try:
            derivatives = list(list_models(
                filter=f"base_model:{base_model_id}",
                full=True,
                limit=1000  # å¢åŠ é™åˆ¶ä»¥è·å–æ‰€æœ‰è¡ç”Ÿæ¨¡å‹
            ))

            if not derivatives:
                print(f"  âšª æ²¡æœ‰æ‰¾åˆ°è¡ç”Ÿæ¨¡å‹")
                return []

            print(f"  âœ… æ‰¾åˆ° {len(derivatives)} ä¸ªè¡ç”Ÿæ¨¡å‹")

            # è½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
            related_models = []
            for deriv in derivatives:
                try:
                    # è·å–è¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬ä¸‹è½½é‡ï¼‰ - å¿…é¡»ä½¿ç”¨ expand å‚æ•°
                    deriv_info = model_info(deriv.id, expand=["downloadsAllTime"])

                    # è·å–ä¸‹è½½é‡ - ä¼˜å…ˆä½¿ç”¨ downloads_all_timeï¼Œå›é€€åˆ° downloads
                    downloads = getattr(deriv_info, 'downloads_all_time', None) or getattr(deriv_info, 'downloads', 0) or 0

                    model_data = {
                        'id': deriv.id,
                        'author': deriv.author or 'Unknown',
                        'tags': getattr(deriv, 'tags', []),  # ğŸ”§ ä¿®å¤ï¼šä» deriv è·å– tagsï¼ˆderiv_info.tags ä¸º Noneï¼‰
                        'downloads': downloads,
                        'pipeline_tag': getattr(deriv, 'pipeline_tag', None),  # ğŸ”§ ä¿®å¤ï¼šä» deriv è·å–
                        'created_at': getattr(deriv, 'created_at', None),
                        'last_modified': getattr(deriv, 'last_modified', None),
                        'likes': getattr(deriv, 'likes', 0)
                    }
                    related_models.append(model_data)

                except Exception as e:
                    print(f"    âš ï¸ è·å– {deriv.id} è¯¦æƒ…å¤±è´¥: {e}")
                    continue

            print(f"  âœ… æˆåŠŸå¤„ç† {len(related_models)} ä¸ªè¡ç”Ÿæ¨¡å‹")
            return related_models

        except Exception as e:
            print(f"  âŒ é€šè¿‡ base_model filter æŸ¥æ‰¾å¤±è´¥: {e}")
            return []

    except Exception as e:
        print(f"âŒ è·å– {base_model_id} çš„model treeå¤±è´¥: {e}")
        return []


def extract_related_models_from_card(card_data: dict, base_model_id: str) -> List[str]:
    """
    ä»æ¨¡å‹cardä¸­æå–ç›¸å…³æ¨¡å‹ID
    """
    related_models = []

    if not card_data:
        return related_models

    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰æ–‡æœ¬å†…å®¹
    def extract_text(obj):
        texts = []
        if isinstance(obj, str):
            texts.append(obj)
        elif isinstance(obj, dict):
            for value in obj.values():
                texts.extend(extract_text(value))
        elif isinstance(obj, list):
            for item in obj:
                texts.extend(extract_text(item))
        return texts

    all_text = extract_text(card_data)
    combined_text = ' '.join(all_text).lower()

    # æŸ¥æ‰¾ç›¸å…³çš„æ¨¡å‹å¼•ç”¨
    base_name = base_model_id.split('/')[-1].lower()

    # æŸ¥æ‰¾æ¨¡å¼
    patterns = [
        rf'{base_model_id.lower()}',
        rf'{base_name}',
        'based on',
        'finetuned from',
        'adapter for',
        'lora for'
    ]

    # ä»æ–‡æœ¬ä¸­æå–æ¨¡å‹ID
    import re
    for text in all_text:
        # æŸ¥æ‰¾æ¨¡å‹IDæ¨¡å¼
        model_id_pattern = r'([a-zA-Z0-9_-]+/[a-zA-Z0-9_-]+)'
        matches = re.findall(model_id_pattern, text)

        for match in matches:
            if match != base_model_id and match not in related_models:
                # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„æ¨¡å‹
                try:
                    model_info(match)  # éªŒè¯æ¨¡å‹å­˜åœ¨
                    related_models.append(match)
                except:
                    continue

    return related_models


def is_genuine_derivative(model_info, base_model_id: str) -> bool:
    """
    éªŒè¯ä¸€ä¸ªæ¨¡å‹æ˜¯å¦çœŸçš„æ˜¯åŸºç¡€æ¨¡å‹çš„è¡ç”Ÿç‰ˆæœ¬

    Args:
        model_info: HuggingFaceæ¨¡å‹ä¿¡æ¯å¯¹è±¡
        base_model_id: åŸºç¡€æ¨¡å‹ID

    Returns:
        bool: æ˜¯å¦ä¸ºçœŸå®çš„è¡ç”Ÿæ¨¡å‹
    """
    try:
        # æ£€æŸ¥æ¨¡å‹cardå†…å®¹
        if hasattr(model_info, 'card_data') and model_info.card_data:
            card_content = str(model_info.card_data).lower()
            base_id_lower = base_model_id.lower()
            base_name = base_model_id.split('/')[-1].lower()

            # æ˜ç¡®çš„è¡ç”ŸæŒ‡æ ‡
            derivative_indicators = [
                f'based on {base_id_lower}',
                f'finetuned from {base_id_lower}',
                f'trained on {base_id_lower}',
                f'adapter for {base_id_lower}',
                f'lora adapter for {base_id_lower}',
                f'{base_name} finetune',
                f'{base_name} adapter',
                f'{base_name} lora'
            ]

            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡ç”ŸæŒ‡æ ‡
            if any(indicator in card_content for indicator in derivative_indicators):
                return True

        # æ£€æŸ¥æ¨¡å‹åç§°æ¨¡å¼
        model_name = model_info.modelId.lower()
        base_name = base_model_id.split('/')[-1].lower()

        # åç§°æ¨¡å¼æ£€æŸ¥
        derivative_patterns = [
            f'{base_name}-finetune',
            f'{base_name}-adapter',
            f'{base_name}-lora',
            f'{base_name}-fine-tuned',
            f'{base_name}-adapted',
            f'finetuned-{base_name}',
            f'adapter-{base_name}',
            f'lora-{base_name}'
        ]

        if any(pattern in model_name for pattern in derivative_patterns):
            return True

        return False

    except Exception:
        return False


def is_derivative_model(model, base_model_id: str) -> bool:
    """
    åˆ¤æ–­ä¸€ä¸ªæ¨¡å‹æ˜¯å¦æ˜¯åŸºç¡€æ¨¡å‹çš„è¡ç”Ÿæ¨¡å‹

    Args:
        model: HuggingFaceæ¨¡å‹å¯¹è±¡
        base_model_id: åŸºç¡€æ¨¡å‹ID

    Returns:
        bool: æ˜¯å¦ä¸ºè¡ç”Ÿæ¨¡å‹
    """
    model_id = model.id.lower()
    base_name = base_model_id.split('/')[-1].lower()

    # æ£€æŸ¥æ¨¡å‹åå…³ç³»
    derivative_patterns = [
        f"{base_name}-",
        f"-{base_name}",
        f"finetuned-{base_name}",
        f"{base_name}-finetune",
        f"adapter-{base_name}",
        f"{base_name}-adapter",
        f"lora-{base_name}",
        f"{base_name}-lora"
    ]

    # æ£€æŸ¥æ ‡ç­¾
    derivative_tags = ['fine-tuned', 'adapter', 'lora', 'peft']

    # åå­—åŒ¹é…æˆ–æ ‡ç­¾åŒ¹é…
    name_match = any(pattern in model_id for pattern in derivative_patterns)
    tag_match = (hasattr(model, 'tags') and
                any(tag in [t.lower() for t in model.tags] for tag in derivative_tags))

    return name_match or tag_match


def get_all_ernie_derivatives(include_paddleocr: bool = True) -> Tuple[pd.DataFrame, int]:
    """
    è·å–æ‰€æœ‰ ERNIE-4.5 å’Œ PaddleOCR-VL ç›¸å…³æ¨¡å‹ï¼Œç»“åˆï¼š
    - å…¨å±€æœç´¢ï¼ˆERNIE-4.5 / PaddleOCR-VLï¼‰
    - å®˜æ–¹è´¦å·æ¨¡å‹ï¼ˆbaidu / PaddlePaddleï¼‰
    - Model Tree è¡ç”Ÿ
    - ä»¥ base_model ä¸ºå…³é”®è¯çš„è¡¥å……æœç´¢

    ä¸è„šæœ¬ç‰ˆå¯¹é½ï¼šæ ‡è®° official ä¸º originalï¼ŒModel Tree å‘½ä¸­ä¸ search åˆå¹¶ä¸º bothï¼Œ
    ä¿ç•™ base_model_from_apiï¼Œå¹¶å¸¦å…¥æ›´å¤šå­—æ®µï¼ˆlikes/library/pipeline/æ—¶é—´æˆ³ï¼‰ã€‚
    """
    print("ğŸš€ å¼€å§‹è·å–ERNIE-4.5å’ŒPaddleOCR-VLæ¨¡å‹...")

    all_models: List[Dict] = []
    processed_ids: Set[str] = set()
    official_models: Dict[str, Dict] = {}

    search_terms = ['ERNIE-4.5', 'PaddleOCR-VL']

    # ---------- è¾…åŠ©å‡½æ•° ----------
    def normalize_tags(tags):
        return tags if isinstance(tags, list) else (tags if tags is not None else [])

    def parse_base_from_card(card_data):
        if not card_data:
            return None
        base_val = card_data.get('base_model') if isinstance(card_data, dict) else None
        if isinstance(base_val, list) and base_val:
            return base_val[0]
        if isinstance(base_val, str) and base_val:
            return base_val
        return None

    def _get_field(obj, name):
        """å…¼å®¹ dict å’Œ huggingface_hub è¿”å›å¯¹è±¡çš„å–å€¼"""
        if obj is None:
            return None
        if isinstance(obj, dict):
            return obj.get(name)
        return getattr(obj, name, None)

    def fetch_model_detail(model_id, model_obj=None):
        try:
            info = model_info(model_id, expand=["downloadsAllTime"])
        except Exception as e:
            print(f"  âš ï¸ è·å– {model_id} è¯¦æƒ…å¤±è´¥: {e}")
            return None

        card_data = None
        if hasattr(info, 'cardData') and info.cardData:
            if isinstance(info.cardData, dict):
                card_data = info.cardData
            elif hasattr(info.cardData, '__dict__'):
                card_data = info.cardData.__dict__

        tags = normalize_tags(_get_field(model_obj, 'tags') or getattr(info, 'tags', None))
        pipeline_tag = _get_field(model_obj, 'pipeline_tag') or getattr(info, 'pipeline_tag', None)
        # Hugging Face æŸäº›æ–°æ¨¡å‹çš„ author å­—æ®µå¯èƒ½ä¸ºç©ºï¼Œå›é€€åˆ° repo ownerï¼ˆID å‰ç¼€ï¼‰
        publisher = (
            getattr(info, 'author', None)
            or _get_field(model_obj, 'author')
            or (model_id.split('/')[0] if '/' in model_id else 'Unknown')
        )
        downloads = (
            getattr(info, 'downloads_all_time', None)
            or getattr(info, 'downloads', 0)
            or _get_field(model_obj, 'downloads')
            or 0
        )

        base_from_api = parse_base_from_card(card_data)

        # å¦‚æœ cardData ä¸­æ²¡æœ‰ base_modelï¼Œå°è¯•ä» tags ä¸­æå–
        if not base_from_api and tags:
            for tag in tags:
                if isinstance(tag, str) and tag.startswith('base_model:'):
                    # æå– base_modelï¼Œæ ¼å¼å¦‚: base_model:PaddlePaddle/PaddleOCR-VL
                    # æˆ– base_model:adapter:PaddlePaddle/PaddleOCR-VL
                    parts = tag.split(':', 2)  # æœ€å¤šåˆ†å‰²æˆ3éƒ¨åˆ†
                    if len(parts) >= 2:
                        # base_model:ModelID æˆ– base_model:type:ModelID
                        candidate = parts[-1]  # å–æœ€åä¸€éƒ¨åˆ†ä½œä¸º model ID
                        # éªŒè¯æ˜¯å¦æ˜¯æœ‰æ•ˆçš„ model ID æ ¼å¼ (åŒ…å« /)
                        if '/' in candidate and not candidate.startswith('license:'):
                            base_from_api = candidate
                            break

        model_category = classify_model(model_id, publisher, base_from_api)
        model_type = classify_model_type(model_id, tags, pipeline_tag, card_data)

        return {
            'model_id': model_id,
            'publisher': publisher,
            'downloads': downloads,
            'tags': tags,
            'pipeline_tag': pipeline_tag,
            'likes': getattr(info, 'likes', None),
            'library_name': getattr(info, 'library_name', None),
            'created_at': getattr(info, 'created_at', None),
            'last_modified': getattr(info, 'last_modified', None),
            'card_data': card_data,
            'model_category': model_category,
            'model_type': model_type,
            'base_model_from_api': base_from_api,
        }

    def search_models_with_keyword(keyword: str, exclude_ids: Set[str]) -> List:
        try:
            results = list(list_models(
                search=keyword,
                full=True,
                limit=600,
                sort="downloads",
                direction=-1
            ))
            filtered = [m for m in results if m.id not in exclude_ids]
            print(f"  ğŸ” æœç´¢ '{keyword}'ï¼š{len(results)} æ¡ï¼Œå»é‡å {len(filtered)} æ¡")
            return filtered
        except Exception as e:
            print(f"  âš ï¸ æœç´¢ '{keyword}' å¤±è´¥: {e}")
            return []

    allowed_categories = {'ernie-4.5', 'paddleocr-vl'}

    def add_record(detail: Dict, data_source: str, base_model: str = None, is_original: bool = False):
        if detail is None:
            return
        model_id = detail['model_id']
        model_name = model_id.split('/')[-1]
        publisher = detail['publisher']
        base_model_val = base_model or detail.get('base_model_from_api')
        model_category = detail['model_category']

        # ä»…ä¿ç•™ç›®æ ‡ç³»åˆ—
        if model_category not in allowed_categories:
            return
        if not include_paddleocr and model_category == 'paddleocr-vl':
            return

        record = {
            'date': date.today().isoformat(),
            'repo': 'Hugging Face',
            'model_name': model_name,
            'publisher': publisher,
            'download_count': detail['downloads'],
            'model_category': model_category,
            'model_type': detail['model_type'] if not is_original else 'original',
            'is_derivative': bool(base_model_val),
            'base_model': base_model_val,
            'data_source': data_source,
            'tags': detail['tags'],
            'likes': detail.get('likes'),
            'library_name': detail.get('library_name'),
            'pipeline_tag': detail.get('pipeline_tag'),
            'created_at': detail.get('created_at'),
            'last_modified': detail.get('last_modified'),
            'fetched_at': date.today().isoformat(),
            'base_model_from_api': detail.get('base_model_from_api')
        }
        all_models.append(record)
        processed_ids.add(model_id)

    # ---------- 1. å…¨å±€æœç´¢ ----------
    print(f"\nğŸ” å…¨å±€æœç´¢ï¼ˆ{', '.join(search_terms)}ï¼‰...")
    all_search_models = []
    for search_term in search_terms:
        all_search_models.extend(search_models_with_keyword(search_term, exclude_ids=set()))

    unique_search = {}
    for m in all_search_models:
        if m.id not in unique_search:
            unique_search[m.id] = m
    print(f"ğŸ” å»é‡åå…± {len(unique_search)} æ¡æœç´¢ç»“æœ")

    for model in unique_search.values():
        detail = fetch_model_detail(model.id, model)
        if detail is None:
            continue

        add_record(detail, data_source='search')

        if model.author in ['baidu', 'PaddlePaddle']:
            official_models[model.id] = {
                'id': model.id,
                'category': detail['model_category']
            }

    # ---------- 2. è¡¥å……å®˜æ–¹æ¨¡å‹åˆ—è¡¨ ----------
    print("\nğŸŒ³ æ‰©å……å®˜æ–¹æ¨¡å‹åˆ—è¡¨...")
    try:
        baidu_official = list(list_models(author="baidu", search="ERNIE-4.5", limit=150))
        paddle_official = list(list_models(author="PaddlePaddle", search="PaddleOCR-VL", limit=50))
        print(f"  baidu è´¦å·å®˜æ–¹æ¨¡å‹ {len(baidu_official)} ä¸ªï¼›PaddlePaddle {len(paddle_official)} ä¸ª")
        for m in baidu_official + paddle_official:
            cat = 'paddleocr-vl' if 'paddleocr-vl' in m.id.lower() else 'ernie-4.5'
            if not include_paddleocr and cat == 'paddleocr-vl':
                continue
            if cat not in allowed_categories:
                continue
            official_models.setdefault(m.id, {'id': m.id, 'category': cat})
            if m.id in processed_ids:
                # å·²åœ¨æœç´¢ç»“æœä¸­ï¼Œæ›´æ–°ä¸º official
                for rec in all_models:
                    if f"{rec['publisher']}/{rec['model_name']}" == m.id:
                        rec['data_source'] = 'original'
                        rec['base_model'] = None
                        rec['is_derivative'] = False
                        rec['model_type'] = 'original'
                        break
            else:
                detail = fetch_model_detail(m.id, m)
                if detail:
                    add_record(detail, data_source='original', base_model=None, is_original=True)
    except Exception as e:
        print(f"  âš ï¸ è·å–å®˜æ–¹æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

    official_list = list(official_models.values())
    print(f"ğŸŒ³ å®˜æ–¹åŸºåº§æ•°é‡: {len(official_list)}")

    # ---------- 3. ä¸ºæ¯ä¸ªå®˜æ–¹æ¨¡å‹æŸ¥ Model Tree + è¡¥å……å…³é”®è¯æœç´¢ ----------
    for official in official_list:
        model_id = official['id']
        model_category = official['category']
        print(f"\nğŸŒ³ å¤„ç†åŸºåº§: {model_id} ({model_category})")

        # Model Tree
        derivatives = get_model_tree_children(model_id, max_depth=1)
        if derivatives:
            for deriv in derivatives:
                deriv_detail = fetch_model_detail(deriv['id'], deriv)
                if deriv_detail is None:
                    continue

                if deriv['id'] not in processed_ids:
                    # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ Model Tree æä¾›çš„ base_model é‡æ–°åˆ†ç±»
                    # å› ä¸º fetch_model_detail ä¸­çš„åˆ†ç±»å¯èƒ½ä½¿ç”¨äº†é”™è¯¯çš„ base_from_apiï¼ˆå¯èƒ½ä¸ºç©ºï¼‰
                    deriv_detail['model_category'] = classify_model(
                        deriv['id'],
                        deriv_detail['publisher'],
                        model_id  # ä½¿ç”¨ Model Tree çš„ base_modelï¼Œè€Œä¸æ˜¯ base_from_api
                    )
                    add_record(deriv_detail, data_source='model_tree', base_model=model_id)
                else:
                    # æ›´æ–°å·²æœ‰è®°å½•ä¸º bothï¼Œè¡¥ base_model
                    for existing in all_models:
                        if f"{existing['publisher']}/{existing['model_name']}" == deriv['id']:
                            existing['data_source'] = 'both'
                            existing['base_model'] = existing.get('base_model') or model_id
                            existing['is_derivative'] = True
                            # ğŸ”§ ä¿®å¤ï¼šä¹Ÿè¦é‡æ–°åˆ†ç±»å·²æœ‰è®°å½•
                            existing['model_category'] = classify_model(
                                deriv['id'],
                                existing['publisher'],
                                model_id
                            )
                            break

        # å…³é”®è¯è¡¥å……æœç´¢ï¼ˆæŒ‰åŸºåº§åï¼‰
        base_keyword = model_id.split('/')[-1]
        extra_results = search_models_with_keyword(base_keyword, exclude_ids=processed_ids)
        for model in extra_results:
            detail = fetch_model_detail(model.id, model)
            if detail is None:
                continue
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨å½“å‰åŸºåº§çš„ model_id é‡æ–°åˆ†ç±»
            # å› ä¸ºè¿™æ˜¯é€šè¿‡åŸºåº§åç§°æœç´¢åˆ°çš„ï¼Œåº”è¯¥ä¸å½“å‰åŸºåº§ç›¸å…³
            detail['model_category'] = classify_model(
                model.id,
                detail['publisher'],
                model_id  # ä½¿ç”¨å½“å‰åŸºåº§çš„ model_id
            )
            if not include_paddleocr and detail['model_category'] == 'paddleocr-vl':
                continue
            # å¼ºåˆ¶è®¤ä¸ºä¸å½“å‰ base ç›¸å…³ï¼ˆå…œåº•è¡¥å……ï¼‰
            if model.id not in processed_ids:
                add_record(detail, data_source='search', base_model=model_id)
                # è‹¥å·²æœ‰ base_model_from_apiï¼Œä¿ç•™
                if detail.get('base_model_from_api') and not detail.get('base_model'):
                    for rec in all_models:
                        if rec['model_name'] == model.id.split('/')[-1] and rec['publisher'] == detail['publisher']:
                            rec['base_model'] = detail['base_model_from_api']
                            break

    # ---------- 4. è½¬ DataFrame ----------
    df = pd.DataFrame(all_models)
    if not df.empty:
        if 'tags' in df.columns:
            df['tags'] = df['tags'].apply(lambda x: str(x) if isinstance(x, list) else (x if pd.notna(x) else '[]'))
        # æŠŠæ—¶é—´å­—æ®µè½¬ä¸ºå­—ç¬¦ä¸²
        for col in ['created_at', 'last_modified', 'fetched_at']:
            if col in df.columns:
                df[col] = df[col].astype(str)

        print(f"\nğŸ“Š æ€»è®¡è·å– {len(df)} ä¸ªæ¨¡å‹ï¼Œå…¶ä¸­åŸºåº§ {len(official_list)} ä¸ª")

    return df, len(all_models)


def update_ernie_model_tree(save_to_db: bool = True) -> Tuple[pd.DataFrame, int]:
    """
    æ›´æ–°ERNIEæ¨¡å‹æ ‘æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼‰

    Args:
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        Tuple[DataFrame, int]: (æ›´æ–°çš„æ•°æ®, æ€»æ•°é‡)
    """
    print("ğŸ”„ å¼€å§‹æ›´æ–°ERNIEæ¨¡å‹æ ‘æ•°æ®...")

    # è·å–æ‰€æœ‰ERNIEç›¸å…³æ¨¡å‹
    df, total_count = get_all_ernie_derivatives(include_paddleocr=True)

    if df.empty:
        print("âš ï¸ æ²¡æœ‰è·å–åˆ°ä»»ä½•æ¨¡å‹æ•°æ®")
        return df, 0

    # å‡†å¤‡æ•°æ®åº“æ ¼å¼ï¼ˆåŒ…å«æ¨¡å‹ç±»å‹å’Œæ ‡ç­¾ä¿¡æ¯ï¼‰
    required_columns = ['date', 'repo', 'model_name', 'publisher', 'download_count']
    optional_columns = [
        'model_type',
        'model_category',
        'tags',
        'base_model',
        'data_source',
        'likes',
        'library_name',
        'pipeline_tag',
        'created_at',
        'last_modified',
        'fetched_at',
        'base_model_from_api',
    ]

    # ç¡®ä¿æ‰€æœ‰å¿…éœ€åˆ—éƒ½å­˜åœ¨
    available_columns = [col for col in required_columns if col in df.columns]
    db_df = df[available_columns].copy()

    # æ·»åŠ å¯é€‰åˆ—ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    for col in optional_columns:
        if col in df.columns:
            db_df[col] = df[col]
        else:
            db_df[col] = None  # ä¸ºç¼ºå¤±çš„åˆ—å¡«å……é»˜è®¤å€¼

    # å°†tagsåˆ—è¡¨è½¬æ¢ä¸ºå­—ç¬¦ä¸²å­˜å‚¨
    if 'tags' in db_df.columns:
        db_df['tags'] = db_df['tags'].apply(lambda x: str(x) if isinstance(x, list) else (x if pd.notna(x) else '[]'))

    # ä¿å­˜åˆ°æ•°æ®åº“
    if save_to_db:
        save_to_db(db_df, DB_PATH)
        print(f"ğŸ’¾ å·²ä¿å­˜ {len(db_df)} æ¡è®°å½•åˆ°æ•°æ®åº“")

    return df, total_count


def get_new_derivatives_since(last_date: str) -> pd.DataFrame:
    """
    è·å–è‡ªæŒ‡å®šæ—¥æœŸä»¥æ¥çš„æ–°å¢è¡ç”Ÿæ¨¡å‹

    Args:
        last_date: ä¸Šæ¬¡æ›´æ–°æ—¥æœŸ (YYYY-MM-DD)

    Returns:
        DataFrame: æ–°å¢çš„è¡ç”Ÿæ¨¡å‹
    """
    try:
        # ä»æ•°æ®åº“è·å–æŒ‡å®šæ—¥æœŸä»¥æ¥çš„æ•°æ®
        from ..db import load_data_from_db
        recent_data = load_data_from_db(date_filter=last_date)

        if recent_data.empty:
            return pd.DataFrame()

        # ç­›é€‰ERNIEç›¸å…³çš„è¡ç”Ÿæ¨¡å‹
        ernie_data = recent_data[
            recent_data['model_name'].str.contains('ernie|ERNIE|paddleocr|PaddleOCR', case=False, na=False)
        ].copy()

        return ernie_data

    except Exception as e:
        print(f"è·å–æ–°å¢è¡ç”Ÿæ¨¡å‹å¤±è´¥: {e}")
        return pd.DataFrame()


def get_weekly_new_finetune_adapters(current_date: str, previous_date: str, model_series: str = 'ERNIE-4.5') -> Dict:
    """
    è·å–æœ¬å‘¨æ–°å¢çš„Finetuneå’ŒAdapteræ¨¡å‹ï¼ˆç”¨äºå‘¨æŠ¥å±•ç¤ºï¼‰

    Args:
        current_date: å½“å‰æ—¥æœŸ (YYYY-MM-DD)
        previous_date: å¯¹æ¯”æ—¥æœŸ (YYYY-MM-DD)
        model_series: æ¨¡å‹ç³»åˆ— ('ERNIE-4.5' æˆ– 'PaddleOCR-VL')

    Returns:
        Dict: åŒ…å«æœ¬å‘¨æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹ä¿¡æ¯çš„å­—å…¸
    """
    try:
        from ..db import load_data_from_db

        # è·å–ä¸¤ä¸ªæ—¥æœŸçš„æ•°æ®
        current_data = load_data_from_db(date_filter=current_date)
        previous_data = load_data_from_db(date_filter=previous_date)

        if current_data.empty:
            return {
                'new_finetune_models': [],
                'new_adapter_models': [],
                'new_lora_models': [],
                'total_new': 0,
                'summary': 'æœ¬å‘¨æ²¡æœ‰æ–°å¢æ¨¡å‹æ•°æ®'
            }

        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ model_category å­—æ®µç²¾ç¡®ç­›é€‰ï¼Œè€Œä¸æ˜¯æœç´¢ model_name
        # æ ¹æ® model_series ç¡®å®šè¦ç­›é€‰çš„ model_category
        if model_series == 'ERNIE-4.5':
            target_category = 'ernie-4.5'
        elif model_series == 'PaddleOCR-VL':
            target_category = 'paddleocr-vl'
        else:
            # é»˜è®¤ä¸º ERNIE-4.5
            target_category = 'ernie-4.5'

        # ç­›é€‰Hugging Faceå¹³å°çš„æŒ‡å®šç³»åˆ—æ¨¡å‹ï¼ˆä½¿ç”¨ model_category å­—æ®µï¼‰
        hf_current = current_data[
            (current_data['repo'] == 'Hugging Face') &
            (current_data['model_category'] == target_category)
        ].copy()

        if previous_data.empty:
            # å¦‚æœæ²¡æœ‰å¯¹æ¯”æ•°æ®ï¼Œå‡è®¾æ‰€æœ‰éƒ½æ˜¯æ–°å¢çš„
            hf_previous = pd.DataFrame()
        else:
            hf_previous = previous_data[
                (previous_data['repo'] == 'Hugging Face') &
                (previous_data['model_category'] == target_category)
            ].copy()

        # æ‰¾å‡ºæ–°å¢çš„æ¨¡å‹ï¼ˆåœ¨å½“å‰æ•°æ®ä¸­ä½†ä¸åœ¨å¯¹æ¯”æ•°æ®ä¸­ï¼‰
        if hf_previous.empty:
            new_models = hf_current.copy()
        else:
            previous_model_names = set(hf_previous['model_name'].tolist())
            new_models = hf_current[~hf_current['model_name'].isin(previous_model_names)].copy()

        if new_models.empty:
            return {
                'new_finetune_models': [],
                'new_adapter_models': [],
                'new_lora_models': [],
                'total_new': 0,
                'summary': 'æœ¬å‘¨æ²¡æœ‰æ–°å¢Finetuneæˆ–Adapteræ¨¡å‹'
            }

        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨æ•°æ®åº“ä¸­å·²ç»å­˜å‚¨çš„ model_type å­—æ®µï¼Œè€Œä¸æ˜¯é‡æ–°åˆ†ç±»
        # æ•°æ®åœ¨å…¥åº“æ—¶å·²ç»é€šè¿‡ classify_model_type() æ­£ç¡®åˆ†ç±»äº†
        # å¦‚æœ model_type åˆ—ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ‰è¿›è¡Œåˆ†ç±»ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        if 'model_type' not in new_models.columns or new_models['model_type'].isna().all():
            print("âš ï¸ è­¦å‘Šï¼šmodel_type å­—æ®µä¸å­˜åœ¨æˆ–å…¨éƒ¨ä¸ºç©ºï¼Œå°è¯•é‡æ–°åˆ†ç±»")
            new_models['model_type'] = new_models.apply(
                lambda row: classify_model_type(
                    row['model_name'],
                    eval(row['tags']) if pd.notna(row.get('tags')) and row.get('tags') else [],
                    None
                ),
                axis=1
            )

        # æŒ‰ç±»å‹åˆ†ç±»
        new_finetune = new_models[new_models['model_type'] == 'finetune'].copy()
        new_adapter = new_models[new_models['model_type'] == 'adapter'].copy()
        new_lora = new_models[new_models['model_type'] == 'lora'].copy()

        # æ ¼å¼åŒ–è¾“å‡º
        def format_models(df):
            if df.empty:
                return []
            return df[['model_name', 'publisher', 'download_count']].to_dict('records')

        result = {
            'new_finetune_models': format_models(new_finetune),
            'new_adapter_models': format_models(new_adapter),
            'new_lora_models': format_models(new_lora),
            'total_new': len(new_models),
            'summary': f'æœ¬å‘¨å…±å‘ç° {len(new_models)} ä¸ªæ–°å¢æ¨¡å‹ï¼Œå…¶ä¸­ Finetune {len(new_finetune)} ä¸ªï¼ŒAdapter {len(new_adapter)} ä¸ªï¼ŒLoRA {len(new_lora)} ä¸ª'
        }

        return result

    except Exception as e:
        print(f"è·å–æœ¬å‘¨æ–°å¢Finetune/Adapteræ¨¡å‹å¤±è´¥: {e}")
        return {
            'new_finetune_models': [],
            'new_adapter_models': [],
            'new_lora_models': [],
            'total_new': 0,
            'summary': f'è·å–æ•°æ®æ—¶å‡ºé”™: {e}'
        }


def get_weekly_new_model_tree_derivatives(current_date: str, previous_date: str, model_series: str = 'ERNIE-4.5') -> Dict:
    """
    è·å–æœ¬å‘¨æ–°å¢çš„ Model Tree è¡ç”Ÿæ¨¡å‹ï¼ˆä¸“é—¨ç»Ÿè®¡ï¼‰

    æ³¨æ„ï¼šåªç»Ÿè®¡é€šè¿‡ Model Tree æ‰¾åˆ°çš„è¡ç”Ÿæ¨¡å‹ï¼ˆbase_model å­—æ®µä¸ä¸ºç©ºï¼‰

    Args:
        current_date: å½“å‰æ—¥æœŸ (YYYY-MM-DD)
        previous_date: å¯¹æ¯”æ—¥æœŸ (YYYY-MM-DD)
        model_series: æ¨¡å‹ç³»åˆ— ('ERNIE-4.5' æˆ– 'PaddleOCR-VL')

    Returns:
        Dict: åŒ…å«æœ¬å‘¨æ–°å¢Model Treeè¡ç”Ÿæ¨¡å‹ä¿¡æ¯çš„å­—å…¸
    """
    try:
        from ..db import load_data_from_db

        # è·å–ä¸¤ä¸ªæ—¥æœŸçš„æ•°æ®
        current_data = load_data_from_db(date_filter=current_date)
        previous_data = load_data_from_db(date_filter=previous_date)

        if current_data.empty:
            return {
                'new_model_tree_models': [],
                'total_new': 0,
                'summary': 'æœ¬å‘¨æ²¡æœ‰æ–°å¢æ¨¡å‹æ•°æ®'
            }

        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨ model_category å­—æ®µç²¾ç¡®ç­›é€‰ï¼Œè€Œä¸æ˜¯æœç´¢ model_name
        # æ ¹æ® model_series ç¡®å®šè¦ç­›é€‰çš„ model_category
        if model_series == 'ERNIE-4.5':
            target_category = 'ernie-4.5'
        elif model_series == 'PaddleOCR-VL':
            target_category = 'paddleocr-vl'
        else:
            # é»˜è®¤ä¸º ERNIE-4.5
            target_category = 'ernie-4.5'

        # åªç­›é€‰ Hugging Face å¹³å°çš„æŒ‡å®šç³»åˆ—æ¨¡å‹ï¼Œä¸” base_model ä¸ä¸ºç©ºï¼ˆModel Tree è¡ç”Ÿæ¨¡å‹ï¼‰
        hf_current = current_data[
            (current_data['repo'] == 'Hugging Face') &
            (current_data['model_category'] == target_category) &
            (current_data['base_model'].notna()) &  # åªè¦ Model Tree æ‰¾åˆ°çš„
            (current_data['base_model'] != '') &    # base_model ä¸ä¸ºç©º
            (current_data['base_model'] != 'None')  # æ’é™¤å­—ç¬¦ä¸² 'None'
        ].copy()

        if previous_data.empty:
            # å¦‚æœæ²¡æœ‰å¯¹æ¯”æ•°æ®ï¼Œå‡è®¾æ‰€æœ‰éƒ½æ˜¯æ–°å¢çš„
            hf_previous = pd.DataFrame()
        else:
            hf_previous = previous_data[
                (previous_data['repo'] == 'Hugging Face') &
                (previous_data['model_category'] == target_category) &
                (previous_data['base_model'].notna()) &
                (previous_data['base_model'] != '') &
                (previous_data['base_model'] != 'None')
            ].copy()

        # æ‰¾å‡ºæ–°å¢çš„æ¨¡å‹ï¼ˆåœ¨å½“å‰æ•°æ®ä¸­ä½†ä¸åœ¨å¯¹æ¯”æ•°æ®ä¸­ï¼‰
        if hf_previous.empty:
            new_models = hf_current.copy()
        else:
            previous_model_names = set(hf_previous['model_name'].tolist())
            new_models = hf_current[~hf_current['model_name'].isin(previous_model_names)].copy()

        if new_models.empty:
            return {
                'new_model_tree_models': [],
                'total_new': 0,
                'summary': 'æœ¬å‘¨æ²¡æœ‰æ–°å¢ Model Tree è¡ç”Ÿæ¨¡å‹'
            }

        # ğŸ”§ ä¿®å¤ï¼šç›´æ¥ä½¿ç”¨æ•°æ®åº“ä¸­å·²ç»å­˜å‚¨çš„ model_type å­—æ®µï¼Œè€Œä¸æ˜¯é‡æ–°åˆ†ç±»
        # æ•°æ®åœ¨å…¥åº“æ—¶å·²ç»é€šè¿‡ classify_model_type() æ­£ç¡®åˆ†ç±»äº†
        # å¦‚æœ model_type åˆ—ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œæ‰è¿›è¡Œåˆ†ç±»ï¼ˆå…¼å®¹æ—§æ•°æ®ï¼‰
        if 'model_type' not in new_models.columns or new_models['model_type'].isna().all():
            print("âš ï¸ è­¦å‘Šï¼šmodel_type å­—æ®µä¸å­˜åœ¨æˆ–å…¨éƒ¨ä¸ºç©ºï¼Œå°è¯•é‡æ–°åˆ†ç±»")
            new_models['model_type'] = new_models.apply(
                lambda row: classify_model_type(
                    row['model_name'],
                    eval(row['tags']) if pd.notna(row.get('tags')) and row.get('tags') else [],
                    None
                ),
                axis=1
            )

        # æ ¼å¼åŒ–è¾“å‡ºï¼ˆå¢åŠ  base_model å’Œ model_type ä¿¡æ¯ï¼‰
        def format_models(df):
            if df.empty:
                return []
            # å¢åŠ  base_model å’Œ model_type åˆ—ï¼Œæ–¹ä¾¿åœ¨å‘¨æŠ¥ä¸­æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            if 'base_model' in df.columns and 'model_type' in df.columns:
                return df[['model_name', 'publisher', 'download_count', 'base_model', 'model_type']].to_dict('records')
            else:
                return df[['model_name', 'publisher', 'download_count']].to_dict('records')

        result = {
            'new_model_tree_models': format_models(new_models),
            'total_new': len(new_models),
            'summary': f'æœ¬å‘¨ Model Tree æ–°å¢ {len(new_models)} ä¸ªè¡ç”Ÿæ¨¡å‹'
        }

        return result

    except Exception as e:
        print(f"è·å–æœ¬å‘¨æ–°å¢ Model Tree è¡ç”Ÿæ¨¡å‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            'new_model_tree_models': [],
            'total_new': 0,
            'summary': f'è·å–æ•°æ®æ—¶å‡ºé”™: {e}'
        }


if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    print("=== æµ‹è¯•ERNIEæ¨¡å‹æ ‘è·å–åŠŸèƒ½ ===")

    # æµ‹è¯•åˆ†ç±»åŠŸèƒ½
    test_cases = [
        ("ernie-4.5-8b", "baidu"),
        ("ernie-4.5-8b-finetuned", "user123"),
        ("paddleocr-vl", "PaddlePaddle"),
        ("ernie-3.0", "baidu"),
        ("some-other-model", "user")
    ]

    print("\nğŸ§ª æµ‹è¯•æ¨¡å‹åˆ†ç±»:")
    for model_name, publisher in test_cases:
        category = classify_model(model_name, publisher)
        print(f"  {model_name} -> {category}")

    # æµ‹è¯•è·å–æ¨¡å‹æ ‘
    print("\nğŸŒ³ æµ‹è¯•è·å–æ¨¡å‹æ ‘:")
    df, count = get_all_ernie_derivatives(include_paddleocr=True)
    print(f"æ€»å…±è·å–åˆ° {count} ä¸ªæ¨¡å‹")

    if not df.empty:
        print("\nå‰5ä¸ªæ¨¡å‹:")
        print(df[['model_name', 'publisher', 'download_count', 'model_category']].head())
