"""
å•ä¸ªæ¨¡å‹é‡æ–°è·å–æ¨¡å—
å¤ç”¨ç°æœ‰fetcherçš„create_recordæ–¹æ³•å’Œé€»è¾‘
"""
from datetime import date, datetime
import sqlite3
import pandas as pd
from huggingface_hub import model_info
from modelscope.hub.api import HubApi
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

from ..config import DB_PATH
from ..utils import create_chrome_driver, extract_numbers


class SingleModelFetcher:
    """å•æ¨¡å‹é‡æ–°è·å–å™¨ - å¤ç”¨BaseFetcherçš„create_recordé€»è¾‘"""

    def __init__(self, platform_name, target_date=None):
        self.platform_name = platform_name
        self.target_date = target_date if target_date else date.today().isoformat()
        self.fetched_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S')

    def create_record(self, model_name, publisher, download_count, search_keyword=None,
                     created_at=None, last_modified=None, url=None):
        """
        åˆ›å»ºä¸€æ¡è®°å½•ï¼ˆä¸BaseFetcherå®Œå…¨ä¸€è‡´ï¼‰
        """
        record = {
            "date": self.target_date,  # ä½¿ç”¨target_dateè€Œä¸æ˜¯today
            "repo": self.platform_name,
            "model_name": model_name,
            "publisher": publisher,
            "download_count": download_count,
            "fetched_at": self.fetched_at  # å…¥åº“æ—¶é—´æˆ³
        }
        if search_keyword:
            record["search_keyword"] = search_keyword
        if created_at:
            record["created_at"] = created_at
        if last_modified:
            record["last_modified"] = last_modified
        if url:
            record["url"] = url
        return record

    def get_url_from_db(self, model_name, publisher):
        """ä»æ•°æ®åº“è·å–æ¨¡å‹URLï¼ˆå¿½ç•¥publisherå¤§å°å†™ï¼‰"""
        import sqlite3
        try:
            conn = sqlite3.connect(DB_PATH)
            # ä½¿ç”¨LOWER()å¿½ç•¥publisherå¤§å°å†™åŒ¹é…
            query = """
                SELECT url FROM model_downloads
                WHERE repo = ? AND model_name = ? AND LOWER(publisher) = LOWER(?)
                AND url IS NOT NULL AND url != ''
                ORDER BY date DESC
                LIMIT 1
            """
            cursor = conn.execute(query, (self.platform_name, model_name, publisher))
            result = cursor.fetchone()
            conn.close()
            return result[0] if result else None
        except Exception as e:
            print(f"  [{self.platform_name}] ä»æ•°æ®åº“è·å–URLå¤±è´¥: {e}")
            return None

    def refetch(self, model_name, publisher):
        """
        é‡æ–°è·å–å•ä¸ªæ¨¡å‹çš„ä¸‹è½½é‡

        Returns:
            dict: recordå­—å…¸ï¼Œå¤±è´¥è¿”å›None
        """
        raise NotImplementedError("å­ç±»å¿…é¡»å®ç°refetchæ–¹æ³•")


class HuggingFaceSingleFetcher(SingleModelFetcher):
    """Hugging Faceå•æ¨¡å‹è·å–å™¨"""

    def __init__(self, target_date=None):
        super().__init__("Hugging Face", target_date)

    def refetch(self, model_name, publisher):
        """ä»Hugging Face APIé‡æ–°è·å–å•ä¸ªæ¨¡å‹"""
        try:
            model_id = f"{publisher}/{model_name}"
            info = model_info(model_id, expand=["downloadsAllTime"])
            downloads = getattr(info, 'downloads_all_time', 0)
            url = f"https://huggingface.co/{model_id}"

            print(f"  [HF] {model_name}: {downloads:,}")
            return self.create_record(
                model_name=model_name,
                publisher=publisher,
                download_count=downloads,
                url=url
            )
        except Exception as e:
            print(f"  [HF] è·å–å¤±è´¥: {e}")
            return None


class ModelScopeSingleFetcher(SingleModelFetcher):
    """ModelScopeå•æ¨¡å‹è·å–å™¨"""

    def __init__(self, target_date=None):
        super().__init__("ModelScope", target_date)

    def refetch(self, model_name, publisher):
        """ä»ModelScope APIé‡æ–°è·å–å•ä¸ªæ¨¡å‹"""
        try:
            model_id = f"{publisher}/{model_name}"
            api = HubApi()
            info = api.get_model(model_id, revision="master")
            downloads = info.get("Downloads", 0)
            url = f"https://modelscope.cn/models/{model_id}"

            print(f"  [ModelScope] {model_name}: {downloads:,}")
            return self.create_record(
                model_name=model_name,
                publisher=publisher,
                download_count=downloads,
                url=url
            )
        except Exception as e:
            print(f"  [ModelScope] è·å–å¤±è´¥: {e}")
            return None


class AIStudioSingleFetcher(SingleModelFetcher):
    """AI Studioå•æ¨¡å‹è·å–å™¨ - ä½¿ç”¨Seleniumè®¿é—®è¯¦æƒ…é¡µ"""

    def __init__(self, target_date=None):
        super().__init__("AI Studio", target_date)

    def refetch(self, model_name, publisher):
        """ä»AI Studioè¯¦æƒ…é¡µé‡æ–°è·å–å•ä¸ªæ¨¡å‹"""
        url = self.get_url_from_db(model_name, publisher)
        if not url:
            print(f"  [AI Studio] æ²¡æœ‰URLï¼Œè·³è¿‡")
            return None

        driver = None
        try:
            driver = create_chrome_driver()
            wait = WebDriverWait(driver, 40)

            print(f"  [AI Studio] è®¿é—®: {url}")
            driver.get(url)
            time.sleep(8)  # å¢åŠ ç­‰å¾…æ—¶é—´ï¼Œç¡®ä¿JavaScriptåŠ è½½å®Œæˆ

            # ä½¿ç”¨æ­£ç¡®çš„XPathï¼šæŸ¥æ‰¾åŒ…å«"ä½¿ç”¨é‡"çš„å…ƒç´ 
            downloads_xpath = "//*[contains(text(), 'ä½¿ç”¨é‡')]"

            try:
                element = driver.find_element(By.XPATH, downloads_xpath)
                downloads_text = element.text.strip()  # ä¾‹å¦‚ï¼š"ä½¿ç”¨é‡ 72458"

                # æå–æ•°å­—ï¼ˆ"ä½¿ç”¨é‡ 72458" â†’ 72458ï¼‰
                number = extract_numbers(downloads_text)
                if number is not None:
                    downloads = str(number)
                    print(f"  [AI Studio] æ‰¾åˆ°ä½¿ç”¨é‡: {downloads}")
                else:
                    downloads = "0"
                    print(f"  [AI Studio] æ— æ³•æå–æ•°å­—ï¼ŒåŸå§‹æ–‡æœ¬: {downloads_text}")
            except Exception as e:
                print(f"  [AI Studio] è·å–ä½¿ç”¨é‡å…ƒç´ å¤±è´¥: {e}")
                downloads = "0"

            return self.create_record(
                model_name=model_name,
                publisher=publisher,
                download_count=downloads,
                url=url
            )
        except Exception as e:
            print(f"  [AI Studio] è·å–å¤±è´¥: {e}")
            return None
        finally:
            if driver:
                driver.quit()


class GitCodeSingleFetcher(SingleModelFetcher):
    """GitCodeå•æ¨¡å‹è·å–å™¨ - ä½¿ç”¨Seleniumè®¿é—®è¯¦æƒ…é¡µ"""

    def __init__(self, target_date=None):
        super().__init__("GitCode", target_date)

    def refetch(self, model_name, publisher):
        """ä»GitCodeè¯¦æƒ…é¡µé‡æ–°è·å–å•ä¸ªæ¨¡å‹"""
        url = self.get_url_from_db(model_name, publisher)
        if not url:
            print(f"  [GitCode] æ²¡æœ‰URLï¼Œè·³è¿‡")
            return None

        driver = None
        try:
            driver = create_chrome_driver()
            wait = WebDriverWait(driver, 40)

            print(f"  [GitCode] è®¿é—®: {url}")
            driver.get(url)
            time.sleep(3)

            # ä½¿ç”¨ä¸ç°æœ‰fetcherä¸€è‡´çš„XPath
            downloads_xpath = '//*[@id="app"]/div/div[2]/div[2]/div/div/div/div/div/div[2]/div[1]/div[1]/div/div[2]'
            downloads = "0"

            try:
                downloads_element = wait.until(EC.presence_of_element_located((By.XPATH, downloads_xpath)))
                # ç­‰å¾…æ•°å€¼ç¨³å®š
                last_val = ""
                for _ in range(5):
                    downloads_element = wait.until(EC.presence_of_element_located((By.XPATH, downloads_xpath)))
                    val = downloads_element.text.strip().replace(',', '')
                    if val and val != last_val:
                        last_val = val
                        time.sleep(1)
                    else:
                        break
                downloads = last_val
            except Exception as e:
                print(f"  [GitCode] è·å–ä¸‹è½½é‡å…ƒç´ å¤±è´¥: {e}")

            print(f"  [GitCode] {model_name}: {downloads}")
            return self.create_record(
                model_name=model_name,
                publisher=publisher,
                download_count=downloads,
                url=url
            )
        except Exception as e:
            print(f"  [GitCode] è·å–å¤±è´¥: {e}")
            return None
        finally:
            if driver:
                driver.quit()


# å•æ¨¡å‹fetcherå·¥å‚
SINGLE_MODEL_FETCHERS = {
    "Hugging Face": HuggingFaceSingleFetcher,
    "ModelScope": ModelScopeSingleFetcher,
    "AI Studio": AIStudioSingleFetcher,
    "GitCode": GitCodeSingleFetcher,
}


def refetch_single_model(repo, model_name, publisher, target_date=None):
    """
    é‡æ–°è·å–å•ä¸ªæ¨¡å‹çš„ä¸‹è½½é‡

    Args:
        repo: å¹³å°åç§°
        model_name: æ¨¡å‹åç§°
        publisher: å‘å¸ƒè€…
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆä¿å­˜åˆ°æ•°æ®åº“çš„æ—¥æœŸï¼‰

    Returns:
        dict: recordå­—å…¸ï¼Œå¤±è´¥è¿”å›None
    """
    fetcher_class = SINGLE_MODEL_FETCHERS.get(repo)
    if not fetcher_class:
        print(f"  âš ï¸ å¹³å° {repo} æš‚ä¸æ”¯æŒé‡æ–°è·å–")
        return None

    fetcher = fetcher_class(target_date=target_date)
    return fetcher.refetch(model_name, publisher)


def refetch_models_batch(negative_growth_list, target_date=None):
    """
    æ‰¹é‡é‡æ–°è·å–è´Ÿå¢é•¿æ¨¡å‹çš„ä¸‹è½½é‡

    Args:
        negative_growth_list: è´Ÿå¢é•¿æ¨¡å‹åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ ä¸ºå­—å…¸ï¼ŒåŒ…å«:
            - platform: å¹³å°
            - model_name: æ¨¡å‹åç§°
            - publisher: å‘å¸ƒè€…
            - current: å½“å‰ä¸‹è½½é‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        target_date: ç›®æ ‡æ—¥æœŸï¼ˆä¿å­˜åˆ°æ•°æ®åº“çš„æ—¥æœŸï¼‰

    Returns:
        tuple: (æˆåŠŸæ›´æ–°çš„åˆ—è¡¨, å¤±è´¥çš„åˆ—è¡¨)
    """
    success_list = []
    failed_list = []

    for item in negative_growth_list:
        repo = item['platform']
        model_name = item['model_name']
        publisher = item['publisher']
        old_count = item['current']

        record = refetch_single_model(repo, model_name, publisher, target_date=target_date)

        if record:
            try:
                # æ­£ç¡®å¤„ç†download_countï¼ˆè½¬æ¢ä¸ºæ•´æ•°ï¼‰
                raw_count = record['download_count']
                try:
                    new_count = int(raw_count)
                except (ValueError, TypeError):
                    new_count = 0

                change = new_count - old_count

                result = {
                    'platform': repo,
                    'model_name': model_name,
                    'publisher': publisher,
                    'old_count': old_count,
                    'new_count': new_count,
                    'change': change,
                    'record': record
                }

                success_list.append(result)
            except Exception as e:
                print(f"  âŒ å¤„ç†ç»“æœå¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                failed_list.append(item)
        else:
            failed_list.append(item)

    return success_list, failed_list


# ========== è‡ªå®šä¹‰æ¨¡å‹æ‰¹é‡è·å– ==========

def fetch_custom_models(target_date=None, progress_callback=None):
    """
    è·å–æ‰€æœ‰è‡ªå®šä¹‰æ¨¡å‹çš„æ•°æ®

    Args:
        target_date: ä¿å­˜åˆ°æ•°æ®åº“çš„æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
        progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

    Returns:
        tuple: (DataFrame, count) æˆåŠŸè·å–çš„æ¨¡å‹æ•°æ®
    """
    from ..db import init_database, CUSTOM_MODELS_TABLE

    init_database()
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    cursor.execute(f"SELECT platform, model_id, url, model_category FROM {CUSTOM_MODELS_TABLE}")
    custom_models = cursor.fetchall()
    conn.close()

    if not custom_models:
        return pd.DataFrame(), 0

    records = []
    total = len(custom_models)

    for i, (platform, model_id, url, model_category) in enumerate(custom_models, 1):
        try:
            print(f"  [{i}/{total}] è·å–è‡ªå®šä¹‰æ¨¡å‹: {platform} - {model_id}")

            if platform == 'Hugging Face':
                fetcher = HuggingFaceSingleFetcher(target_date=target_date)
                # model_id æ ¼å¼: publisher/model_name
                parts = model_id.split('/', 1)
                if len(parts) == 2:
                    publisher, model_name = parts
                    record = fetcher.refetch(model_name, publisher)
                    if record:
                        record['data_source'] = 'custom'
                        record['model_category'] = model_category  # ğŸ”§ ä½¿ç”¨ç™½åå•ä¸­ä¿å­˜çš„åˆ†ç±»
                        records.append(record)

            elif platform == 'ModelScope':
                fetcher = ModelScopeSingleFetcher(target_date=target_date)
                # model_id æ ¼å¼: publisher/model_name
                parts = model_id.split('/', 1)
                if len(parts) == 2:
                    publisher, model_name = parts
                    record = fetcher.refetch(model_name, publisher)
                    if record:
                        record['data_source'] = 'custom'
                        record['model_category'] = model_category  # ğŸ”§ ä½¿ç”¨ç™½åå•ä¸­ä¿å­˜çš„åˆ†ç±»
                        records.append(record)

            elif platform == 'AI Studio':
                fetcher = AIStudioSingleFetcher(target_date=target_date)
                # å¯¹äº AI Studioï¼Œmodel_id æ˜¯å®Œæ•´çš„ URL
                # éœ€è¦ä»æ•°æ®åº“ä¸­å·²æœ‰çš„è®°å½•è·å– publisher å’Œ model_name
                # æˆ–è€…é€šè¿‡ URL è§£æ
                record = _fetch_aistudio_custom(fetcher, url)
                if record:
                    record['data_source'] = 'custom'
                    record['model_category'] = model_category  # ğŸ”§ ä½¿ç”¨ç™½åå•ä¸­ä¿å­˜çš„åˆ†ç±»
                    records.append(record)

            if progress_callback:
                progress_callback(i, total)

        except Exception as e:
            print(f"  âŒ è·å– {platform}/{model_id} å¤±è´¥: {e}")

    if records:
        df = pd.DataFrame(records)
        print(f"  âœ… è‡ªå®šä¹‰æ¨¡å‹è·å–å®Œæˆ: {len(df)} ä¸ªæ¨¡å‹")
        return df, len(df)
    else:
        print(f"  âš ï¸  æ²¡æœ‰è·å–åˆ°ä»»ä½•è‡ªå®šä¹‰æ¨¡å‹æ•°æ®")
        return pd.DataFrame(), 0


def _fetch_aistudio_custom(fetcher, url):
    """
    è·å– AI Studio è‡ªå®šä¹‰æ¨¡å‹çš„æ•°æ®

    å¯¹äº AI Studioï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†ï¼š
    1. å…ˆå°è¯•ä» custom_models è¡¨ä¸­æ‰¾åˆ°è¯¥ URL å¯¹åº”çš„ publisher å’Œ model_nameï¼ˆç™½åå•ï¼‰
    2. å¦‚æœæ‰¾ä¸åˆ°ï¼Œå†ä» model_downloads è¡¨ä¸­æŸ¥æ‰¾å†å²è®°å½•
    3. å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œåˆ™è·³è¿‡
    """
    import sqlite3
    from ..config import DB_PATH
    from ..db import DATA_TABLE, CUSTOM_MODELS_TABLE

    try:
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()

        # ä¼˜å…ˆä» custom_models è¡¨æŸ¥æ‰¾ï¼ˆç™½åå•ä¿¡æ¯ï¼‰
        cursor.execute(f"""
            SELECT publisher, model_name
            FROM {CUSTOM_MODELS_TABLE}
            WHERE url = ? AND platform = 'AI Studio'
            LIMIT 1
        """, (url,))
        result = cursor.fetchone()

        # å¦‚æœç™½åå•ä¸­æ²¡æœ‰ï¼Œå†ä»å†å²æ•°æ®ä¸­æŸ¥æ‰¾
        if not result:
            cursor.execute(f"""
                SELECT publisher, model_name
                FROM {DATA_TABLE}
                WHERE url = ? AND repo = 'AI Studio'
                LIMIT 1
            """, (url,))
            result = cursor.fetchone()

        conn.close()

        if result:
            publisher, model_name = result
            return fetcher.refetch(model_name, publisher)
        else:
            # æ²¡æœ‰æ‰¾åˆ°ä»»ä½•è®°å½•
            print(f"  âš ï¸  AI Studio æ¨¡å‹éœ€è¦å…ˆåœ¨ç™½åå•æˆ–æ•°æ®åº“ä¸­æœ‰è®°å½•: {url}")
            return None

    except Exception as e:
        print(f"  âŒ AI Studio è‡ªå®šä¹‰æ¨¡å‹è·å–å¤±è´¥: {e}")
        return None
