"""
ERNIE æ¨¡å‹ä¸‹è½½é‡ç»Ÿè®¡ç³»ç»Ÿ
ä¸»ç•Œé¢ - ä½¿ç”¨ Streamlit æ„å»º
"""
import streamlit as st
import pandas as pd
import time
from datetime import date
import concurrent.futures
import threading

from ernie_tracker.config import DB_PATH, PLATFORM_NAMES
from ernie_tracker.db import (
    save_to_db,
    get_last_model_count,
    update_last_model_count,
    load_data_from_db,
    init_database,
)
from ernie_tracker.fetchers.fetchers_unified import (
    UNIFIED_PLATFORM_FETCHERS,
    fetch_all_paddlepaddle_data,
    fetch_hugging_face_data_unified,
)


# é¡µé¢é…ç½®
st.set_page_config(page_title="ERNIEæ¨¡å‹ä¸‹è½½æ•°æ®ç»Ÿè®¡", layout="wide")
st.title("ğŸ“Š ERNIEæ¨¡å‹ä¸‹è½½æ•°æ®ç»Ÿè®¡")


def fetch_platform_data_only(platform_name, fetch_func, save_to_database=True):
    """
    ä»…æ‰§è¡Œæ•°æ®æŠ“å–ï¼ˆä¸åŒ…å«UIæ“ä½œï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰

    Args:
        platform_name: å¹³å°åç§°
        fetch_func: æŠ“å–å‡½æ•°
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        tuple: (platform_name, DataFrame, success, elapsed_time, error_message, progress_updates)
    """
    # è·å–ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡
    last_count = get_last_model_count(platform_name)

    # è¿›åº¦æ›´æ–°ä¿¡æ¯åˆ—è¡¨
    progress_updates = []

    # ä¿å­˜å½“å‰å‚è€ƒæ€»æ•°ï¼ˆä½¿ç”¨å­—å…¸é¿å…é—­åŒ…é—®é¢˜ï¼‰
    ref = {"denom": last_count}

    def progress_callback(processed, discovered_total=None):
        """è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆä»…æ”¶é›†è¿›åº¦ä¿¡æ¯ï¼Œä¸æ›´æ–°UIï¼‰"""
        if ref["denom"]:  # æœ‰å‚è€ƒæ€»æ•°
            denom = ref["denom"]
            if processed > denom:
                if save_to_database:
                    update_last_model_count(platform_name, processed)
                ref["denom"] = processed
                denom = processed

            progress = min(processed / denom, 1.0)
            progress_updates.append({
                'processed': processed,
                'total': denom,
                'progress': progress,
                'message': f"å·²å¤„ç† {processed} / å‚è€ƒæ€»æ•° {denom}"
            })
        else:  # é¦–æ¬¡è¿è¡Œ
            if discovered_total:
                progress = processed / discovered_total
                progress_updates.append({
                    'processed': processed,
                    'total': discovered_total,
                    'progress': progress,
                    'message': f"å·²å¤„ç† {processed} / å®é™…æ€»æ•° {discovered_total}"
                })
            else:
                progress_updates.append({
                    'processed': processed,
                    'total': None,
                    'progress': None,
                    'message': f"å·²å¤„ç† {processed} ï¼ˆæ€»æ•°æœªçŸ¥ï¼‰"
                })

    # æ‰§è¡Œæ•°æ®è·å–
    start_time = time.time()
    try:
        df, total_count = fetch_func(progress_callback=progress_callback, progress_total=ref["denom"])
        elapsed_time = time.time() - start_time

        # ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_database:
            if total_count is not None and total_count != ref["denom"]:
                update_last_model_count(platform_name, total_count)
            save_to_db(df, DB_PATH)
            status_message = f"âœ… å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚"
        else:
            status_message = f"âœ… å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œä»…è·å–æ•°æ®ã€‚"

        progress_updates.append({
            'status': 'completed',
            'message': status_message
        })

        return platform_name, df, True, elapsed_time, None, progress_updates

    except Exception as e:
        error_message = f"âŒ çˆ¬å–å¤±è´¥: {e}"
        progress_updates.append({
            'status': 'error',
            'message': error_message
        })
        return platform_name, None, False, time.time() - start_time, error_message, progress_updates


def run_platform_fetcher(platform_name, fetch_func, save_to_database=True, ui_container=None):
    """
    è¿è¡Œå•ä¸ªå¹³å°çš„æ•°æ®æŠ“å–ï¼ˆåŒ…å«UIæ›´æ–°ï¼Œç”¨äºä¸²è¡Œæ¨¡å¼ï¼‰

    Args:
        platform_name: å¹³å°åç§°
        fetch_func: æŠ“å–å‡½æ•°
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        ui_container: UIå®¹å™¨ï¼ˆå…¼å®¹å‚æ•°ï¼‰

    Returns:
        DataFrame: æŠ“å–çš„æ•°æ®
    """
    if ui_container is None:
        # å…¼å®¹åŸæœ‰çš„ç‹¬ç«‹UIæ¨¡å¼
        st.subheader(platform_name)

    # è·å–ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡
    last_count = get_last_model_count(platform_name)

    # ä¸²è¡Œæ¨¡å¼ - åŸæœ‰UIæ˜¾ç¤ºæ–¹å¼
    st.write(
        f"ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡ï¼š{last_count if last_count is not None else 'æš‚æ— è®°å½•ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰'}"
    )
    status_placeholder = st.empty()
    progress_bar = st.progress(0)

    # ä¿å­˜å½“å‰å‚è€ƒæ€»æ•°
    ref = {"denom": last_count}

    def progress_callback(processed, discovered_total=None):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        if ref["denom"]:  # æœ‰å‚è€ƒæ€»æ•°
            denom = ref["denom"]
            if processed > denom:
                if save_to_database:
                    update_last_model_count(platform_name, processed)
                ref["denom"] = processed
                denom = processed

            progress = min(processed / denom, 1.0)
            progress_bar.progress(progress)
            status_placeholder.text(
                f"å·²å¤„ç† {processed} / å‚è€ƒæ€»æ•° {denom}"
            )
        else:  # é¦–æ¬¡è¿è¡Œ
            if discovered_total:
                progress_bar.progress(processed / discovered_total)
                status_placeholder.text(
                    f"å·²å¤„ç† {processed} / å®é™…æ€»æ•° {discovered_total}"
                )
            else:
                status_placeholder.text(f"å·²å¤„ç† {processed} ï¼ˆæ€»æ•°æœªçŸ¥ï¼‰")

    # æ‰§è¡Œæ•°æ®è·å–
    start_time = time.time()
    try:
        df, total_count = fetch_func(progress_callback=progress_callback, progress_total=last_count)
        elapsed_time = time.time() - start_time

        # ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_database:
            if total_count is not None and total_count != last_count:
                update_last_model_count(platform_name, total_count)
            save_to_db(df, DB_PATH)
            status_message = f"å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚"
        else:
            status_message = f"å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œä»…è·å–æ•°æ®ã€‚"

        status_placeholder.text(status_message)
        progress_bar.progress(1.0)
        return df

    except Exception as e:
        st.error(f"{platform_name} çˆ¬å–å¤±è´¥: {e}")
        return None


def run_platforms_parallel(platforms, fetchers_to_use, save_to_database=True):
    """
    å¹¶è¡Œè¿è¡Œå¤šä¸ªå¹³å°çš„æ•°æ®æŠ“å–ï¼ˆä¿®å¤ç‰ˆï¼šé¿å…åœ¨çº¿ç¨‹ä¸­è°ƒç”¨Streamlit APIï¼‰

    Args:
        platforms: å¹³å°åç§°åˆ—è¡¨
        fetchers_to_use: å¹³å°æŠ“å–å‡½æ•°å­—å…¸
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        tuple: (DataFrameåˆ—è¡¨, æ€»ç”¨æ—¶)
    """
    all_dfs = []
    total_start_time = time.time()

    # åˆ›å»ºUIå®¹å™¨
    st.markdown("### â³ å¹¶è¡Œæ›´æ–°è¿›åº¦")
    overall_progress = st.empty()

    # ä¸ºæ¯ä¸ªå¹³å°åˆ›å»ºçŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
    platform_status = {}
    for platform in platforms:
        with st.expander(f"ğŸ”„ {platform}", expanded=True):
            platform_status[platform] = {
                'status': st.empty(),
                'progress': st.progress(0),
                'details': st.empty(),
                'time': st.empty()
            }
            platform_status[platform]['status'].info(f"ğŸ”„ {platform} ç­‰å¾…ä¸­...")

    def fetch_platform_task(platform_name):
        """å•ä¸ªå¹³å°æŠ“å–ä»»åŠ¡ï¼ˆçº¯æ•°æ®å¤„ç†ï¼Œä¸åŒ…å«UIæ“ä½œï¼‰"""
        fetch_func = fetchers_to_use.get(platform_name)
        if fetch_func:
            return fetch_platform_data_only(platform_name, fetch_func, save_to_database)
        return platform_name, None, False, 0, "æŠ“å–å‡½æ•°æœªæ‰¾åˆ°", []

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œ
    with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(platforms), 4)) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_platform = {
            executor.submit(fetch_platform_task, platform): platform
            for platform in platforms
        }

        completed_count = 0
        total_count = len(platforms)

        # å®æ—¶æ›´æ–°å„å¹³å°çŠ¶æ€
        while completed_count < total_count:
            # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
            for future in list(future_to_platform.keys()):
                if future.done():
                    platform_name = future_to_platform.pop(future)
                    completed_count += 1

                    try:
                        # è·å–ç»“æœ
                        _, df, success, elapsed_time, error_message, progress_updates = future.result()

                        # æ›´æ–°è¯¥å¹³å°çš„æœ€ç»ˆçŠ¶æ€
                        if success:
                            platform_status[platform_name]['status'].success(f"âœ… {platform_name} å®Œæˆ")
                            platform_status[platform_name]['details'].success(progress_updates[-1]['message'] if progress_updates else "å®Œæˆ")
                            platform_status[platform_name]['time'].success(f"â±ï¸ ç”¨æ—¶: {elapsed_time:.2f} ç§’")
                            platform_status[platform_name]['progress'].progress(1.0)

                            if df is not None:
                                all_dfs.append(df)
                        else:
                            platform_status[platform_name]['status'].error(f"âŒ {platform_name} å¤±è´¥")
                            platform_status[platform_name]['details'].error(error_message)
                            platform_status[platform_name]['time'].error(f"â±ï¸ ç”¨æ—¶: {elapsed_time:.2f} ç§’")

                    except Exception as e:
                        platform_status[platform_name]['status'].error(f"âŒ {platform_name} å¼‚å¸¸")
                        platform_status[platform_name]['details'].error(f"æ‰§è¡Œå¼‚å¸¸: {e}")

                    # æ›´æ–°æ€»ä½“è¿›åº¦
                    overall_progress.info(f"ğŸ¯ æ€»ä½“è¿›åº¦ï¼š{completed_count}/{total_count} ä¸ªå¹³å°å®Œæˆ")

            # çŸ­æš‚ä¼‘çœ é¿å…è¿‡åº¦å ç”¨CPU
            time.sleep(0.5)

    total_elapsed_time = time.time() - total_start_time
    overall_progress.success(f"ğŸ¯ å¹¶è¡ŒæŠ“å–å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{total_elapsed_time:.2f} ç§’")

    return all_dfs, total_elapsed_time


# åˆå§‹åŒ–æ•°æ®åº“
init_database()

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("ğŸ”§ åŠŸèƒ½é€‰æ‹©")
page = st.sidebar.radio(
    " ",
    [
        "ğŸ“¥ æ•°æ®æ›´æ–°",
        "ğŸ“Š ERNIE-4.5 åˆ†æ",
        "ğŸ“Š PaddleOCR-VL åˆ†æ",
        "ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€",
        "ğŸŒ² Model Tree ç»Ÿè®¡",
        "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†",
    ],
    index=0,
)


# ================= æ•°æ®æ›´æ–°æ¨¡å— =================
if page == "ğŸ“¥ æ•°æ®æ›´æ–°":
    from ernie_tracker.analysis import get_available_dates
    import os
    st.markdown("## ğŸ“¥ æ•°æ®æ›´æ–°")
    st.info("ğŸš€ **ä¼˜åŒ–æ›´æ–°æ¨¡å¼**ï¼šç°åœ¨ä¸€æ¬¡æ›´æ–°å³å¯è·å–æ‰€æœ‰PaddlePaddleæ¨¡å‹æ•°æ®ï¼ˆåŒ…å«ERNIE-4.5å’ŒPaddleOCR-VLï¼‰ï¼Œæ— éœ€åˆ†åˆ«é€‰æ‹©ï¼")

    # Model Tree é€‰é¡¹
    use_model_tree = st.checkbox(
        "ğŸŒ³ ä½¿ç”¨ Model Tree åŠŸèƒ½ï¼ˆè·å–è¡ç”Ÿæ¨¡å‹ï¼‰",
        value=True,
        help="å¯ç”¨åä¼šè·å–ERNIE-4.5å’ŒPaddleOCR-VLçš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼ŒåŒ…æ‹¬Finetuneã€Adapterç­‰"
    )

    if use_model_tree:
        st.info("ğŸ” **Model Treeæ¨¡å¼**ï¼šå°†è·å–ERNIE-4.5å’ŒPaddleOCR-VLçš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨åˆ†ç±»è¯†åˆ«Finetuneã€Adapterã€LoRAç­‰ç±»å‹")

    # ä½¿ç”¨ç»Ÿä¸€çš„å¹³å°æŠ“å–å™¨
    fetchers_to_use = UNIFIED_PLATFORM_FETCHERS.copy()

    # æ ¹æ®Model Treeé€‰é¡¹æ›´æ–°Hugging Faceè·å–å™¨
    fetchers_to_use["Hugging Face"] = lambda **kwargs: fetch_hugging_face_data_unified(
        progress_callback=kwargs.get('progress_callback'),
        progress_total=kwargs.get('progress_total'),
        use_model_tree=use_model_tree  # ä¼ é€’ç”¨æˆ·çš„é€‰æ‹©
    )

    platform_options = list(fetchers_to_use.keys())

    # åˆå§‹åŒ– session_state
    if "select_all" not in st.session_state:
        st.session_state.select_all = False

    # å¹³å°é€‰æ‹©
    with st.container():
        toolbar_col1, toolbar_col2, toolbar_col3 = st.columns([1, 5, 1])

        with toolbar_col1:
            if st.button("âœ… å…¨é€‰ / å–æ¶ˆ"):
                st.session_state.select_all = not st.session_state.select_all

        with toolbar_col2:
            platforms = st.multiselect(
                "é€‰æ‹©éœ€è¦æ›´æ–°çš„å¹³å°",
                platform_options,
                default=platform_options if st.session_state.select_all else [],
                label_visibility="collapsed"
            )

        with toolbar_col3:
            run_all = st.button("ğŸš€ æ›´æ–°æ•°æ®", use_container_width=True)

    # æ•°æ®ä¿å­˜é€‰é¡¹
    st.markdown("### âš™ï¸ æ•°æ®ä¿å­˜è®¾ç½®")
    save_to_db_option = st.radio(
        "é€‰æ‹©æ•°æ®å¤„ç†æ–¹å¼ï¼š",
        options=["ä¿å­˜åˆ°æ•°æ®åº“", "ä»…è·å–æ•°æ®ï¼ˆä¸ä¿å­˜ï¼‰"],
        index=0,
        horizontal=True,
        help="é€‰æ‹©æ˜¯å¦å°†çˆ¬å–çš„æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ä¸­"
    )

    save_to_database = (save_to_db_option == "ä¿å­˜åˆ°æ•°æ®åº“")

    if save_to_database:
        st.info("ğŸ’¾ æ•°æ®å°†ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå¹¶æ›´æ–°å¹³å°ç»Ÿè®¡ä¿¡æ¯")
    else:
        st.warning("âš ï¸ æ•°æ®ä»…ç”¨äºé¢„è§ˆï¼Œä¸ä¼šä¿å­˜åˆ°æ•°æ®åº“")

    # æ‰§è¡Œæ¨¡å¼é€‰æ‹©
    st.markdown("### ğŸš€ æ‰§è¡Œæ¨¡å¼")
    execution_mode = st.radio(
        "é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š",
        options=["ğŸš€ å¹¶è¡Œæ‰§è¡Œï¼ˆæ¨èï¼‰", "ğŸ”„ ä¸²è¡Œæ‰§è¡Œ"],
        index=0,
        horizontal=True,
        help="å¹¶è¡Œæ‰§è¡Œå¯ä»¥å¤§å¹…æå‡å¤šå¹³å°æŠ“å–æ•ˆç‡"
    )

    use_parallel = (execution_mode == "ğŸš€ å¹¶è¡Œæ‰§è¡Œï¼ˆæ¨èï¼‰")

    if use_parallel:
        st.info("âš¡ å„å¹³å°å°†åŒæ—¶è¿›è¡Œæ•°æ®æŠ“å–ï¼Œå¤§å¹…æå‡æ•ˆç‡")
    else:
        st.warning("ğŸŒ å„å¹³å°å°†ä¾æ¬¡è¿›è¡Œæ•°æ®æŠ“å–ï¼Œè€—æ—¶è¾ƒé•¿")

    st.markdown("---")

    # æ‰§è¡Œæ›´æ–°
    if run_all:
        if not platforms:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå¹³å°å†æ›´æ–°ã€‚")
        else:
            all_dfs = []
            total_elapsed_time = 0

            if use_parallel:
                # å¹¶è¡Œæ‰§è¡Œæ¨¡å¼
                all_dfs, total_elapsed_time = run_platforms_parallel(
                    platforms, fetchers_to_use, save_to_database
                )
            else:
                # ä¸²è¡Œæ‰§è¡Œæ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
                total_start_time = time.time()
                st.markdown("### â³ ä¸²è¡Œæ›´æ–°è¿›åº¦")
                progress_placeholder = st.empty()

                for idx, platform in enumerate(platforms, start=1):
                    progress_placeholder.info(f"æ­£åœ¨æ›´æ–°ï¼š**{platform}** ({idx}/{len(platforms)})")

                    # è°ƒç”¨å¹³å°æŠ“å–å‡½æ•°
                    fetch_func = fetchers_to_use.get(platform)
                    if fetch_func:
                        df = run_platform_fetcher(platform, fetch_func, save_to_database)
                        if df is not None:
                            all_dfs.append(df)

                        elapsed = time.time() - total_start_time
                        status_msg = "æ•°æ®å·²ä¿å­˜" if save_to_database else "ä»…é¢„è§ˆ"
                        st.success(f"âœ… {platform} å®Œæˆï¼Œç”¨æ—¶ {elapsed:.2f} ç§’ï¼Œ{status_msg}")

                total_elapsed_time = time.time() - total_start_time
                st.info(f"ğŸ¯ ä¸²è¡ŒæŠ“å–å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{total_elapsed_time:.2f} ç§’")

            # æ•°æ®é¢„è§ˆ
            st.markdown("### ğŸ“„ æœ¬æ¬¡æ›´æ–°æ•°æ®é¢„è§ˆ")
            if all_dfs:
                final_df = pd.concat(all_dfs, ignore_index=True)
                st.dataframe(final_df, use_container_width=True)

                # ä¸‹è½½æŒ‰é’®
                csv_data = final_df.to_csv(index=False).encode("utf-8-sig")
                download_label = "â¬‡ï¸ ä¸‹è½½æœ¬æ¬¡æ›´æ–°æ•°æ® (CSV)" if save_to_database else "â¬‡ï¸ ä¸‹è½½è·å–çš„æ•°æ® (CSV)"

                st.download_button(
                    label=download_label,
                    data=csv_data,
                    file_name=f"paddlepaddle_models_downloads_{date.today().isoformat()}.csv",
                    mime="text/csv",
                    use_container_width=False
                )

    # å¯¼å‡ºæŒ‡å®šæ—¥æœŸæ•°æ®
    st.markdown("### ğŸ“ å¯¼å‡ºæŒ‡å®šæ—¥æœŸæ•°æ®åˆ°æœ¬åœ°")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates_export = get_available_dates()

    if not available_dates_export:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®å¯ä¾›å¯¼å‡ºã€‚")
    else:
        selected_date = st.selectbox(
            "é€‰æ‹©è¦å¯¼å‡ºçš„æ—¥æœŸ",
            options=available_dates_export,
            index=0,
            key="export_date_selector",
            help="é€‰æ‹©ä¸€ä¸ªæ—¥æœŸï¼Œå°†å…¶æ•°æ®å¯¼å‡ºä¸º Excel æ–‡ä»¶åˆ° Data æ–‡ä»¶å¤¹"
        )

        if st.button("ğŸ’¾ å¯¼å‡ºåˆ° Data æ–‡ä»¶å¤¹"):
            with st.spinner(f"æ­£åœ¨å¯¼å‡º {selected_date} çš„æ•°æ®..."):
                df_export = load_data_from_db(date_filter=selected_date)
                
                if df_export.empty:
                    st.error(f"âŒ æœªæ‰¾åˆ° {selected_date} çš„æ•°æ®ã€‚")
                else:
                    output_dir = "Data"
                    os.makedirs(output_dir, exist_ok=True)
                    output_path = os.path.join(output_dir, f"data_{selected_date}.xlsx")
                    
                    try:
                        # ä¿å­˜åˆ° Excel
                        df_export.to_excel(output_path, index=False, engine='openpyxl')
                        st.success(f"âœ… æ•°æ®æˆåŠŸå¯¼å‡ºåˆ°: `{output_path}`")
                        st.info(f"å…±å¯¼å‡º {len(df_export)} æ¡è®°å½•ã€‚")
                    except Exception as e:
                        st.error(f"å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")


# ================= ERNIE-4.5 æ•°æ®åˆ†ææ¨¡å— =================
elif page == "ğŸ“Š ERNIE-4.5 åˆ†æ":
    from ernie_tracker.analysis import calculate_weekly_report, format_report_tables, get_available_dates, get_last_friday
    from datetime import datetime

    st.markdown("## ğŸ“ˆ å‘¨æŠ¥åˆ†æ")
    st.markdown("åˆ†æå½“å‰æ—¥æœŸä¸å¯¹æ¯”æ—¥æœŸä¹‹é—´çš„ä¸‹è½½é‡å¢é•¿æƒ…å†µ")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # æ—¥æœŸé€‰æ‹©
        col1, col2 = st.columns(2)

        with col1:
            current_date = st.selectbox(
                "ğŸ“… å½“å‰æ—¥æœŸ",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„å½“å‰æ—¥æœŸ"
            )

        with col2:
            # é»˜è®¤ä¸ºä¸Šå‘¨äº”
            default_previous = get_last_friday(current_date)
            if default_previous in available_dates:
                default_index = available_dates.index(default_previous)
            else:
                default_index = min(1, len(available_dates) - 1)

            previous_date = st.selectbox(
                "ğŸ“… å¯¹æ¯”æ—¥æœŸ",
                options=available_dates,
                index=default_index,
                help="é€‰æ‹©è¦å¯¹æ¯”çš„æ—¥æœŸï¼ˆé€šå¸¸ä¸ºä¸Šå‘¨äº”ï¼‰"
            )

        if st.button("ğŸ” ç”Ÿæˆå‘¨æŠ¥", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                report_data = calculate_weekly_report(current_date, previous_date, model_series='ERNIE-4.5')

            if report_data is None:
                st.error("âŒ æ— æ³•ç”Ÿæˆå‘¨æŠ¥ï¼Œè¯·æ£€æŸ¥é€‰æ‹©çš„æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®ã€‚")
            else:
                tables = format_report_tables(report_data)

                st.success(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å¯¹æ¯”æ—¶é—´æ®µï¼š{previous_date} â†’ {current_date}")

                # æ£€æŸ¥å¹¶æ˜¾ç¤ºè´Ÿå¢é•¿è­¦å‘Š
                warnings_df = tables.get('negative_growth_warnings')
                if warnings_df is not None and not warnings_df.empty:
                    st.markdown("### âš ï¸ è´Ÿå¢é•¿è­¦å‘Š")
                    st.error(f"æ£€æµ‹åˆ° {len(warnings_df)} ä¸ªæ¨¡å‹å‡ºç°è´Ÿå¢é•¿ï¼è¿™å¯èƒ½è¡¨ç¤ºæ•°æ®é‡‡é›†é—®é¢˜æˆ–æ¨¡å‹è¢«ä¸‹æ¶ã€‚")
                    st.dataframe(warnings_df, use_container_width=True)
                    st.markdown("---")

                # æ˜¾ç¤ºæ€»ä½“æƒ…å†µæ‘˜è¦
                st.markdown("### ğŸ“ æ€»ä½“æƒ…å†µæ‘˜è¦")
                stats = report_data['summary_stats']
                
                # æ ¼å¼åŒ–æ•°å­—
                def format_num(n):
                    return f"{n/10000:.2f}ä¸‡"

                def format_percent(p):
                    return f"{p:.2%}"

                # è®¡ç®—ç™¾åˆ†æ¯”
                official_total_percent = stats['official_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                derivative_total_percent = stats['derivative_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                official_growth_percent = stats['official_growth'] / stats['all_growth'] if stats['all_growth'] else 0
                derivative_growth_percent = stats['derivative_growth'] / stats['all_growth'] if stats['all_growth'] else 0

                summary_text = f"""
                æˆªè‡³ **{current_date}**ï¼Œæ¨¡å‹ç´¯è®¡ä¸‹è½½ **{format_num(stats['all_current_total'])}** æ¬¡
                ï¼ˆå«å®˜æ–¹æ¨¡å‹ **{format_num(stats['official_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_total_percent)}**ï¼Œ
                è¡ç”Ÿ **{format_num(stats['derivative_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_total_percent)}**ï¼‰ï¼Œ
                è¾ƒä¸Šå‘¨å¢é•¿ **{format_num(stats['all_growth'])}** æ¬¡
                ï¼ˆå®˜æ–¹æ¨¡å‹ **{format_num(stats['official_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_growth_percent)}**ï¼Œ
                è¡ç”Ÿæ¨¡å‹å¢é•¿ **{format_num(stats['derivative_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_growth_percent)}**ï¼‰ã€‚
                """
                st.markdown(summary_text)

                # ç´¯è®¡/æœ¬å‘¨æ–°å¢è¡ç”Ÿæ¨¡å‹æ•°é‡
                new_models_list_count = len(tables.get('all_new_models', pd.DataFrame()))
                st.info(
                    f"ç´¯è®¡è¡ç”Ÿæ¨¡å‹ï¼š{int(stats.get('derivative_current_total_models', 0) or 0)} ä¸ªï½œ"
                    f"æœ¬å‘¨æ–°å¢è¡ç”Ÿï¼ˆHFéå®˜æ–¹å·®é›†ï¼‰ï¼š{int(stats.get('derivative_new_models', 0) or 0)} ä¸ªï½œ"
                    f"æ–°å¢åˆ—è¡¨å±•ç¤ºï¼š{new_models_list_count} ä¸ª"
                )

                # ç¤¾åŒºå’Œæ¨¡å‹ç»´åº¦æ‘˜è¦
                st.markdown("### ğŸ“ˆ ç¤¾åŒºä¸æ¨¡å‹ç»´åº¦æ‘˜è¦")
                community_summary = report_data['community_summary']
                
                # ç¤¾åŒºç»´åº¦
                community_text = f"""
                - **ç¤¾åŒºç»´åº¦**ï¼šHugging Faceä¸‹è½½é‡æœ€é«˜ï¼Œ**{community_summary['hf_top_model_name']}** ä¸ºæœ¬å‘¨HFå¹³å°ä¸‹è½½æœ€é«˜æ¨¡å‹ï¼Œå¢é•¿ **{community_summary['hf_top_model_growth']/10000:.2f}ä¸‡** æ¬¡ã€‚
                """
                st.markdown(community_text)

                # æ¨¡å‹ç»´åº¦
                top3_downloads_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_downloads_details'].items()])
                top3_growth_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_growth_details'].items()])
                
                model_text = f"""
                - **æ¨¡å‹ç»´åº¦**ï¼š
                    - æ¨¡å‹ï¼ˆå®˜æ–¹ï¼‰ä¸‹è½½æ€»é‡å‰ä¸‰ä½ï¼š{top3_downloads_str}
                    - æœ¬å‘¨ï¼ˆå®˜æ–¹ï¼‰å¢é•¿æœ€å¿«å‰ä¸‰ä½ï¼š{top3_growth_str}
                """
                st.markdown(model_text)

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                st.markdown("### ğŸ“Š å¹³å°æ±‡æ€»")
                st.dataframe(tables['platform_summary'], use_container_width=True)

                # Topæ¦œå•
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### ğŸ† Top 5 å¢é•¿æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top5_growth'], use_container_width=True)

                with col2:
                    st.markdown("### ğŸ¥‡ Top 3 æ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top3_downloads'], use_container_width=True)

                # å„å¹³å°æ¦œé¦–
                st.markdown("### ğŸ¯ å„å¹³å°æ¦œé¦–æ¨¡å‹")
                st.dataframe(
                    tables['platform_top_models'],
                    use_container_width=True,
                    column_config={
                        "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                        "å¢é•¿æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "å¢é•¿æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæœ¬å‘¨å¢é•¿é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                    }
                )

                # è¯¦ç»†æ•°æ®è¡¨æ ¼
                st.markdown("### ğŸ“‹ å„å¹³å°æ¨¡å‹ä¸‹è½½é‡è¯¦æƒ… (æ€»/å‘¨å¢)")
                st.dataframe(tables['combined_downloads_growth'], use_container_width=True)

                # æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹å±•ç¤º
                st.markdown("### ğŸŒŸ æœ¬å‘¨æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                summary = tables.get('new_models_summary', 'æ— æ–°å¢æ¨¡å‹ä¿¡æ¯')
                st.info(f"ğŸ“Š {summary}")

                # åˆ†åˆ—æ˜¾ç¤ºä¸åŒç±»å‹çš„æ–°å¢æ¨¡å‹
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown("#### ğŸ”§ æ–°å¢Finetuneæ¨¡å‹")
                    finetune_df = tables.get('new_finetune_models')
                    if finetune_df is not None and not finetune_df.empty:
                        st.dataframe(finetune_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Finetuneæ¨¡å‹")

                with col2:
                    st.markdown("#### ğŸ”Œ æ–°å¢Adapteræ¨¡å‹")
                    adapter_df = tables.get('new_adapter_models')
                    if adapter_df is not None and not adapter_df.empty:
                        st.dataframe(adapter_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Adapteræ¨¡å‹")

                with col3:
                    st.markdown("#### ğŸ¯ æ–°å¢LoRAæ¨¡å‹")
                    lora_df = tables.get('new_lora_models')
                    if lora_df is not None and not lora_df.empty:
                        st.dataframe(lora_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢LoRAæ¨¡å‹")

                # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                st.markdown("### ğŸ“‹ æœ¬å‘¨æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                all_new_summary = tables.get('all_new_models_summary', 'æ— æ–°å¢æ¨¡å‹')
                st.info(f"ğŸ“Š {all_new_summary}")

                # æ˜¾ç¤ºæ‰€æœ‰æ–°å¢æ¨¡å‹è¡¨æ ¼
                all_new_df = tables.get('all_new_models')
                if all_new_df is not None and not all_new_df.empty:
                    st.dataframe(all_new_df, use_container_width=True, height=400)
                else:
                    st.info("æœ¬å‘¨æ²¡æœ‰æ–°å¢ERNIE-4.5æ¨¡å‹")

                # ğŸ†• å·²åˆ é™¤/éšè—çš„æ¨¡å‹åˆ—è¡¨
                st.markdown("### ğŸ—‘ï¸ å·²åˆ é™¤/éšè—çš„è¡ç”Ÿæ¨¡å‹")
                st.info("ğŸ“Œ è¿™äº›æ¨¡å‹åœ¨å†å²è®°å½•ä¸­å­˜åœ¨ï¼Œä½†åœ¨å½“å‰æ—¥æœŸå·²ä¸å¯è§ï¼ˆå¯èƒ½è¢«åˆ é™¤æˆ–éšè—ï¼‰")

                from ernie_tracker.analysis import get_deleted_or_hidden_models
                deleted_models = get_deleted_or_hidden_models(current_date, model_series='ERNIE-4.5')

                if deleted_models:
                    deleted_df = pd.DataFrame(deleted_models)
                    deleted_df.index = deleted_df.index + 1

                    # é‡å‘½ååˆ—
                    column_mapping = {
                        'model_name': 'æ¨¡å‹åç§°',
                        'publisher': 'å‘å¸ƒè€…',
                        'repo': 'å¹³å°',
                        'model_type': 'æ¨¡å‹ç±»å‹',
                        'base_model': 'åŸºç¡€æ¨¡å‹',
                        'last_seen_date': 'æœ€åå‡ºç°æ—¥æœŸ',
                        'last_download_count': 'æœ€åä¸‹è½½é‡'
                    }
                    deleted_df = deleted_df.rename(columns={k: v for k, v in column_mapping.items() if k in deleted_df.columns})

                    st.warning(f"âš ï¸ å‘ç° {len(deleted_models)} ä¸ªæ¨¡å‹å·²è¢«åˆ é™¤æˆ–éšè—")
                    st.dataframe(deleted_df, use_container_width=True, height=400)
                else:
                    st.success("âœ… æ‰€æœ‰å†å²æ¨¡å‹åœ¨å½“å‰æ—¥æœŸä»ç„¶å¯è§")

                # å¯¼å‡ºåŠŸèƒ½
                st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥è¡¨")

                # åˆå¹¶æ‰€æœ‰è¡¨æ ¼ä¸ºä¸€ä¸ªExcel
                from io import BytesIO

                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    tables['platform_summary'].to_excel(writer, sheet_name='å¹³å°æ±‡æ€»')
                    tables['top5_growth'].to_excel(writer, sheet_name='Top5å¢é•¿')
                    tables['top3_downloads'].to_excel(writer, sheet_name='Top3ä¸‹è½½é‡')
                    tables['platform_top_models'].to_excel(writer, sheet_name='å„å¹³å°æ¦œé¦–', index=False)
                    tables['combined_downloads_growth'].to_excel(writer, sheet_name='ä¸‹è½½é‡è¯¦æƒ…')
                    # æ–°å¢æ¨¡å‹è¡¨æ ¼
                    if not tables.get('new_finetune_models', pd.DataFrame()).empty:
                        tables['new_finetune_models'].to_excel(writer, sheet_name='æ–°å¢Finetuneæ¨¡å‹')
                    if not tables.get('new_adapter_models', pd.DataFrame()).empty:
                        tables['new_adapter_models'].to_excel(writer, sheet_name='æ–°å¢Adapteræ¨¡å‹')
                    if not tables.get('new_lora_models', pd.DataFrame()).empty:
                        tables['new_lora_models'].to_excel(writer, sheet_name='æ–°å¢LoRAæ¨¡å‹')
                    # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                    if not tables.get('all_new_models', pd.DataFrame()).empty:
                        tables['all_new_models'].to_excel(writer, sheet_name='æ‰€æœ‰æ–°å¢æ¨¡å‹')

                excel_data = output.getvalue()

                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½å®Œæ•´å‘¨æŠ¥ (Excel)",
                    data=excel_data,
                    file_name=f"ERNIE-4.5_å‘¨æŠ¥_{previous_date}_to_{current_date}.xlsx",
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )

# ================= PaddleOCR-VL æ•°æ®åˆ†ææ¨¡å— =================
elif page == "ğŸ“Š PaddleOCR-VL åˆ†æ":
    from ernie_tracker.analysis import calculate_paddleocr_vl_weekly_report, format_report_tables, get_available_dates, get_last_friday
    from datetime import datetime

    st.markdown("## ğŸ“ˆ PaddleOCR-VL å‘¨æŠ¥åˆ†æ")
    st.markdown("åˆ†æå½“å‰æ—¥æœŸä¸å¯¹æ¯”æ—¥æœŸä¹‹é—´çš„ä¸‹è½½é‡å¢é•¿æƒ…å†µ")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # æ—¥æœŸé€‰æ‹©
        col1, col2 = st.columns(2)

        with col1:
            current_date = st.selectbox(
                "ğŸ“… å½“å‰æ—¥æœŸ (PaddleOCR-VL)",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„å½“å‰æ—¥æœŸ"
            )

        with col2:
            # é»˜è®¤ä¸ºä¸Šå‘¨äº”
            default_previous = get_last_friday(current_date)
            if default_previous in available_dates:
                default_index = available_dates.index(default_previous)
            else:
                default_index = min(1, len(available_dates) - 1)

            previous_date = st.selectbox(
                "ğŸ“… å¯¹æ¯”æ—¥æœŸ (PaddleOCR-VL)",
                options=available_dates,
                index=default_index,
                help="é€‰æ‹©è¦å¯¹æ¯”çš„æ—¥æœŸï¼ˆé€šå¸¸ä¸ºä¸Šå‘¨äº”ï¼‰"
            )

        if st.button("ğŸ” ç”Ÿæˆ PaddleOCR-VL å‘¨æŠ¥", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                report_data = calculate_paddleocr_vl_weekly_report(current_date, previous_date)

            if report_data is None:
                st.error("âŒ æ— æ³•ç”Ÿæˆå‘¨æŠ¥ï¼Œè¯·æ£€æŸ¥é€‰æ‹©çš„æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®ã€‚")
            else:
                tables = format_report_tables(report_data)

                st.success(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å¯¹æ¯”æ—¶é—´æ®µï¼š{previous_date} â†’ {current_date}")

                # æ£€æŸ¥å¹¶æ˜¾ç¤ºè´Ÿå¢é•¿è­¦å‘Š
                warnings_df = tables.get('negative_growth_warnings')
                if warnings_df is not None and not warnings_df.empty:
                    st.markdown("### âš ï¸ è´Ÿå¢é•¿è­¦å‘Š")
                    st.error(f"æ£€æµ‹åˆ° {len(warnings_df)} ä¸ªæ¨¡å‹å‡ºç°è´Ÿå¢é•¿ï¼è¿™å¯èƒ½è¡¨ç¤ºæ•°æ®é‡‡é›†é—®é¢˜æˆ–æ¨¡å‹è¢«ä¸‹æ¶ã€‚")
                    st.dataframe(warnings_df, use_container_width=True)
                    st.markdown("---")

                # æ˜¾ç¤ºæ€»ä½“æƒ…å†µæ‘˜è¦
                st.markdown("### ğŸ“ æ€»ä½“æƒ…å†µæ‘˜è¦")
                stats = report_data['summary_stats']
                
                # æ ¼å¼åŒ–æ•°å­—
                def format_num(n):
                    return f"{n/10000:.2f}ä¸‡"

                def format_percent(p):
                    return f"{p:.2%}"

                # è®¡ç®—ç™¾åˆ†æ¯”
                official_total_percent = stats['official_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                derivative_total_percent = stats['derivative_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                official_growth_percent = stats['official_growth'] / stats['all_growth'] if stats['all_growth'] else 0
                derivative_growth_percent = stats['derivative_growth'] / stats['all_growth'] if stats['all_growth'] else 0

                summary_text = f"""
                æˆªè‡³ **{current_date}**ï¼Œæ¨¡å‹ç´¯è®¡ä¸‹è½½ **{format_num(stats['all_current_total'])}** æ¬¡
                ï¼ˆå«å®˜æ–¹æ¨¡å‹ **{format_num(stats['official_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_total_percent)}**ï¼Œ
                è¡ç”Ÿ **{format_num(stats['derivative_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_total_percent)}**ï¼‰ï¼Œ
                è¾ƒä¸Šå‘¨å¢é•¿ **{format_num(stats['all_growth'])}** æ¬¡
                ï¼ˆå®˜æ–¹æ¨¡å‹ **{format_num(stats['official_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_growth_percent)}**ï¼Œ
                è¡ç”Ÿæ¨¡å‹å¢é•¿ **{format_num(stats['derivative_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_growth_percent)}**ï¼‰ã€‚
                """
                st.markdown(summary_text)

                # ç´¯è®¡/æœ¬å‘¨æ–°å¢è¡ç”Ÿæ¨¡å‹æ•°é‡
                new_models_list_count = len(tables.get('all_new_models', pd.DataFrame()))
                st.info(
                    f"ç´¯è®¡è¡ç”Ÿæ¨¡å‹ï¼š{int(stats.get('derivative_current_total_models', 0) or 0)} ä¸ªï½œ"
                    f"æœ¬å‘¨æ–°å¢è¡ç”Ÿï¼ˆHFéå®˜æ–¹å·®é›†ï¼‰ï¼š{int(stats.get('derivative_new_models', 0) or 0)} ä¸ªï½œ"
                    f"æ–°å¢åˆ—è¡¨å±•ç¤ºï¼š{new_models_list_count} ä¸ª"
                )

                # ç¤¾åŒºå’Œæ¨¡å‹ç»´åº¦æ‘˜è¦
                st.markdown("### ğŸ“ˆ ç¤¾åŒºä¸æ¨¡å‹ç»´åº¦æ‘˜è¦")
                community_summary = report_data['community_summary']
                
                # ç¤¾åŒºç»´åº¦
                community_text = f"""
                - **ç¤¾åŒºç»´åº¦**ï¼šHugging Faceä¸‹è½½é‡æœ€é«˜ï¼Œ**{community_summary['hf_top_model_name']}** ä¸ºæœ¬å‘¨HFå¹³å°ä¸‹è½½æœ€é«˜æ¨¡å‹ï¼Œå¢é•¿ **{community_summary['hf_top_model_growth']/10000:.2f}ä¸‡** æ¬¡ã€‚
                """
                st.markdown(community_text)

                # æ¨¡å‹ç»´åº¦
                top3_downloads_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_downloads_details'].items()])
                top3_growth_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_growth_details'].items()])
                
                model_text = f"""
                - **æ¨¡å‹ç»´åº¦**ï¼š
                    - æ¨¡å‹ï¼ˆå®˜æ–¹ï¼‰ä¸‹è½½æ€»é‡å‰ä¸‰ä½ï¼š{top3_downloads_str}
                    - æœ¬å‘¨ï¼ˆå®˜æ–¹ï¼‰å¢é•¿æœ€å¿«å‰ä¸‰ä½ï¼š{top3_growth_str}
                """
                st.markdown(model_text)

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                st.markdown("### ğŸ“Š å¹³å°æ±‡æ€»")
                st.dataframe(tables['platform_summary'], use_container_width=True)

                # Topæ¦œå•
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### ğŸ† Top 5 å¢é•¿æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top5_growth'], use_container_width=True)

                with col2:
                    st.markdown("### ğŸ¥‡ Top 3 æ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top3_downloads'], use_container_width=True)

                # å„å¹³å°æ¦œé¦–
                st.markdown("### ğŸ¯ å„å¹³å°æ¦œé¦–æ¨¡å‹")
                st.dataframe(
                    tables['platform_top_models'],
                    use_container_width=True,
                    column_config={
                        "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                        "å¢é•¿æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "å¢é•¿æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæœ¬å‘¨å¢é•¿é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                    }
                )

                # è¯¦ç»†æ•°æ®è¡¨æ ¼
                st.markdown("### ğŸ“‹ å„å¹³å°æ¨¡å‹ä¸‹è½½é‡è¯¦æƒ… (æ€»/å‘¨å¢)")
                st.dataframe(tables['combined_downloads_growth'], use_container_width=True)

                # ğŸ”§ æ–°å¢ï¼šPaddleOCR-VL çš„ Finetune å’Œ Adapter æ¨¡å‹å±•ç¤º
                st.markdown("### ğŸŒŸ æœ¬å‘¨æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                summary = tables.get('new_models_summary', 'æ— æ–°å¢æ¨¡å‹ä¿¡æ¯')
                st.info(f"ğŸ“Š {summary}")

                # åˆ†åˆ—æ˜¾ç¤ºä¸åŒç±»å‹çš„æ–°å¢æ¨¡å‹
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown("#### ğŸ”§ æ–°å¢Finetuneæ¨¡å‹")
                    finetune_df = tables.get('new_finetune_models')
                    if finetune_df is not None and not finetune_df.empty:
                        st.dataframe(finetune_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Finetuneæ¨¡å‹")

                with col2:
                    st.markdown("#### ğŸ”Œ æ–°å¢Adapteræ¨¡å‹")
                    adapter_df = tables.get('new_adapter_models')
                    if adapter_df is not None and not adapter_df.empty:
                        st.dataframe(adapter_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Adapteræ¨¡å‹")

                with col3:
                    st.markdown("#### ğŸ¯ æ–°å¢LoRAæ¨¡å‹")
                    lora_df = tables.get('new_lora_models')
                    if lora_df is not None and not lora_df.empty:
                        st.dataframe(lora_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢LoRAæ¨¡å‹")

                # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                st.markdown("### ğŸ“‹ æœ¬å‘¨æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                all_new_summary = tables.get('all_new_models_summary', 'æ— æ–°å¢æ¨¡å‹')
                st.info(f"ğŸ“Š {all_new_summary}")

                # æ˜¾ç¤ºæ‰€æœ‰æ–°å¢æ¨¡å‹è¡¨æ ¼
                all_new_df = tables.get('all_new_models')
                if all_new_df is not None and not all_new_df.empty:
                    st.dataframe(all_new_df, use_container_width=True, height=400)
                else:
                    st.info("æœ¬å‘¨æ²¡æœ‰æ–°å¢PaddleOCR-VLæ¨¡å‹")

                # ğŸ†• å·²åˆ é™¤/éšè—çš„æ¨¡å‹åˆ—è¡¨
                st.markdown("### ğŸ—‘ï¸ å·²åˆ é™¤/éšè—çš„è¡ç”Ÿæ¨¡å‹")
                st.info("ğŸ“Œ è¿™äº›æ¨¡å‹åœ¨å†å²è®°å½•ä¸­å­˜åœ¨ï¼Œä½†åœ¨å½“å‰æ—¥æœŸå·²ä¸å¯è§ï¼ˆå¯èƒ½è¢«åˆ é™¤æˆ–éšè—ï¼‰")

                from ernie_tracker.analysis import get_deleted_or_hidden_models
                deleted_models = get_deleted_or_hidden_models(current_date, model_series='PaddleOCR-VL')

                if deleted_models:
                    deleted_df = pd.DataFrame(deleted_models)
                    deleted_df.index = deleted_df.index + 1

                    # é‡å‘½ååˆ—
                    column_mapping = {
                        'model_name': 'æ¨¡å‹åç§°',
                        'publisher': 'å‘å¸ƒè€…',
                        'repo': 'å¹³å°',
                        'model_type': 'æ¨¡å‹ç±»å‹',
                        'base_model': 'åŸºç¡€æ¨¡å‹',
                        'last_seen_date': 'æœ€åå‡ºç°æ—¥æœŸ',
                        'last_download_count': 'æœ€åä¸‹è½½é‡'
                    }
                    deleted_df = deleted_df.rename(columns={k: v for k, v in column_mapping.items() if k in deleted_df.columns})

                    st.warning(f"âš ï¸ å‘ç° {len(deleted_models)} ä¸ªæ¨¡å‹å·²è¢«åˆ é™¤æˆ–éšè—")
                    st.dataframe(deleted_df, use_container_width=True, height=400)
                else:
                    st.success("âœ… æ‰€æœ‰å†å²æ¨¡å‹åœ¨å½“å‰æ—¥æœŸä»ç„¶å¯è§")

                # å¯¼å‡ºåŠŸèƒ½
                st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥è¡¨")

                # åˆå¹¶æ‰€æœ‰è¡¨æ ¼ä¸ºä¸€ä¸ªExcel
                from io import BytesIO

                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    tables['platform_summary'].to_excel(writer, sheet_name='å¹³å°æ±‡æ€»')
                    tables['top5_growth'].to_excel(writer, sheet_name='Top5å¢é•¿')
                    tables['top3_downloads'].to_excel(writer, sheet_name='Top3ä¸‹è½½é‡')
                    tables['platform_top_models'].to_excel(writer, sheet_name='å„å¹³å°æ¦œé¦–', index=False)
                    tables['combined_downloads_growth'].to_excel(writer, sheet_name='ä¸‹è½½é‡è¯¦æƒ…')
                    # ğŸ”§ æ–°å¢ï¼šå¯¼å‡ºæ–°å¢æ¨¡å‹è¡¨æ ¼
                    if not tables.get('new_finetune_models', pd.DataFrame()).empty:
                        tables['new_finetune_models'].to_excel(writer, sheet_name='æ–°å¢Finetuneæ¨¡å‹')
                    if not tables.get('new_adapter_models', pd.DataFrame()).empty:
                        tables['new_adapter_models'].to_excel(writer, sheet_name='æ–°å¢Adapteræ¨¡å‹')
                    if not tables.get('new_lora_models', pd.DataFrame()).empty:
                        tables['new_lora_models'].to_excel(writer, sheet_name='æ–°å¢LoRAæ¨¡å‹')
                    if not tables.get('new_model_tree_models', pd.DataFrame()).empty:
                        tables['new_model_tree_models'].to_excel(writer, sheet_name='ModelTreeæ–°å¢æ¨¡å‹')
                    # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                    if not tables.get('all_new_models', pd.DataFrame()).empty:
                        tables['all_new_models'].to_excel(writer, sheet_name='æ‰€æœ‰æ–°å¢æ¨¡å‹')

                excel_data = output.getvalue()

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ PaddleOCR-VL å®Œæ•´å‘¨æŠ¥ (Excel)",
            data=excel_data,
            file_name=f"PaddleOCR-VL_å‘¨æŠ¥_{previous_date}_to_{current_date}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ================= Model Tree ç»Ÿè®¡ =================
elif page == "ğŸŒ² Model Tree ç»Ÿè®¡":
    st.markdown("## ğŸŒ² Model Tree ç»Ÿè®¡")
    from ernie_tracker.analysis import get_available_dates

    available_dates = get_available_dates()
    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ›´æ–°æˆ–å¯¼å…¥æ•°æ®ã€‚")
    else:
        date_options = ["å…¨éƒ¨"] + available_dates
        selected_date = st.selectbox("ğŸ“… é€‰æ‹©æ—¥æœŸ", options=date_options, index=1 if len(date_options) > 1 else 0)
        date_filter = None if selected_date == "å…¨éƒ¨" else selected_date

        df = load_data_from_db(date_filter=date_filter)

        if df.empty:
            st.warning(f"âš ï¸ {selected_date} æ²¡æœ‰æ•°æ®")
            st.stop()

        # æ¸…æ´— base_model ä¸­çš„ç©ºå€¼å­—ç¬¦ä¸²
        if 'base_model' in df.columns:
            df['base_model'] = df['base_model'].apply(
                lambda v: None if str(v).strip().lower() in ['', 'none', 'nan'] else v
            )

        # ä»…ä¿ç•™ ERNIE ç›¸å…³ï¼Œæ’é™¤ PaddleOCR-VL
        df = df[df['model_category'] != 'paddleocr-vl']

        total = len(df)
        original_count = len(df[df['model_type'] == 'original']) if 'model_type' in df.columns else 0
        derivative_count = total - original_count

        col_total1, col_total2, col_total3 = st.columns(3)
        with col_total1:
            st.metric("æ€»æ¨¡å‹æ•°", total)

        st.markdown("### ğŸ“Š æ•°æ®æ¥æºåˆ†å¸ƒ")
        source_counts = df['data_source'].fillna('unknown').value_counts().reset_index()
        source_counts.columns = ['data_source', 'count']
        st.dataframe(source_counts, use_container_width=True)

        st.markdown("### ğŸ§­ åˆ†ç±»ç»Ÿè®¡")
        col_stats1, col_stats2 = st.columns(2)
        with col_stats1:
            cat_counts = df['model_category'].fillna('unknown').value_counts().reset_index()
            cat_counts.columns = ['model_category', 'count']
            st.dataframe(cat_counts, use_container_width=True)
        with col_stats2:
            type_counts = df['model_type'].fillna('unknown').value_counts().reset_index()
            type_counts.columns = ['model_type', 'count']
            st.dataframe(type_counts, use_container_width=True)

        class_total = cat_counts['count'].sum() if not cat_counts.empty else 0
        with col_total2:
            st.metric("åˆ†ç±»åˆè®¡", class_total)
        with col_total3:
            st.metric("è¡ç”Ÿæ¨¡å‹æ•°", derivative_count)
        if class_total != total:
            st.warning(f"åˆ†ç±»è®¡æ•°({class_total})ä¸æ€»æ¨¡å‹æ•°({total})ä¸ä¸€è‡´ï¼Œè¯·åˆ·æ–°æˆ–æ£€æŸ¥æ•°æ®ã€‚")

        derivative_df = df[df['base_model'].notna() & (df['base_model'] != '') & (df['model_type'] != 'original')]

        if not derivative_df.empty:
            st.markdown("### ğŸŒ³ æŒ‰åŸºåº§æ±‡æ€»")
            base_summary = (
                derivative_df.groupby('base_model')
                .agg(
                    derivative_count=('model_name', 'count'),
                    downloads=('download_count', lambda x: pd.to_numeric(x, errors='coerce').fillna(0).sum()),
                )
                .reset_index()
                .sort_values('derivative_count', ascending=False)
            )
            st.dataframe(base_summary, use_container_width=True)

            st.markdown("### ğŸ† ä¸‹è½½é‡ Top è¡ç”Ÿæ¨¡å‹")
            top_derivatives = derivative_df.copy()
            top_derivatives['download_count'] = pd.to_numeric(top_derivatives['download_count'], errors='coerce').fillna(0)
            top_derivatives = top_derivatives.sort_values('download_count', ascending=False).head(30)
            display_cols = [
                'model_name',
                'publisher',
                'base_model',
                'download_count',
                'model_type',
                'model_category',
                'data_source',
            ]
            top_derivatives = top_derivatives[[c for c in display_cols if c in top_derivatives.columns]]
            st.dataframe(top_derivatives, use_container_width=True)

# ================= æ•°æ®åº“ç®¡ç†æ¨¡å— =================
elif page == "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†":
    from ernie_tracker.db_manager import (
        backup_database, restore_database, delete_data_by_date,
        delete_data_by_platform, get_database_stats, get_available_backups,
        delete_backup, vacuum_database, export_database_to_excel,
        get_duplicate_records, remove_duplicate_records, insert_single_record,
        import_from_excel
    )
    from ernie_tracker.analysis import get_available_dates
    from io import BytesIO
    import os

    st.markdown("## ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†")
    st.info("ğŸ’¡ æä¾›æ•°æ®åº“å¤‡ä»½ã€æ¢å¤ã€åˆ é™¤ã€ä¼˜åŒ–ç­‰ç®¡ç†åŠŸèƒ½")

    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š æ•°æ®åº“æ¦‚è§ˆ",
        "ğŸ’¾ å¤‡ä»½ä¸æ¢å¤",
        "ğŸ—‘ï¸ æ•°æ®åˆ é™¤",
        "ğŸ”§ æ•°æ®ç»´æŠ¤",
        "ğŸ“¤ æ•°æ®å¯¼å‡º",
        "ğŸ“ æ•°æ®å½•å…¥",
        "âœï¸ æ•°æ®ç¼–è¾‘"
    ])
    
    # ========== Tab 1: æ•°æ®åº“æ¦‚è§ˆ ==========
    with tab1:
        st.markdown("### ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
        
        if st.button("ğŸ”„ åˆ·æ–°ç»Ÿè®¡", key="refresh_stats"):
            st.rerun()
        
        stats = get_database_stats()
        
        if 'error' in stats:
            st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {stats['error']}")
        else:
            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»è®°å½•æ•°", f"{stats['total_records']:,}")
            
            with col2:
                st.metric("æ•°æ®åº“å¤§å°", f"{stats['db_size_mb']} MB")
            
            with col3:
                st.metric("æœ€æ—©æ—¥æœŸ", stats['min_date'] or "æ— æ•°æ®")
            
            with col4:
                st.metric("æœ€æ–°æ—¥æœŸ", stats['max_date'] or "æ— æ•°æ®")
            
            st.markdown("---")
            
            # æŒ‰æ—¥æœŸç»Ÿè®¡
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸ“… æŒ‰æ—¥æœŸç»Ÿè®¡")
                if not stats['date_stats'].empty:
                    st.dataframe(
                        stats['date_stats'].rename(columns={'date': 'æ—¥æœŸ', 'count': 'è®°å½•æ•°'}),
                        use_container_width=True,
                        height=300
                    )
                else:
                    st.info("æš‚æ— æ•°æ®")
            
            with col2:
                st.markdown("#### ğŸŒ æŒ‰å¹³å°ç»Ÿè®¡")
                if not stats['platform_stats'].empty:
                    st.dataframe(
                        stats['platform_stats'].rename(columns={'repo': 'å¹³å°', 'count': 'è®°å½•æ•°'}),
                        use_container_width=True,
                        height=300
                    )
                else:
                    st.info("æš‚æ— æ•°æ®")
    
    # ========== Tab 2: å¤‡ä»½ä¸æ¢å¤ ==========
    with tab2:
        st.markdown("### ğŸ’¾ æ•°æ®åº“å¤‡ä»½")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            backup_dir = st.text_input(
                "å¤‡ä»½ç›®å½•",
                value="backups",
                help="æ•°æ®åº“å¤‡ä»½æ–‡ä»¶å°†ä¿å­˜åˆ°è¿™ä¸ªç›®å½•"
            )
        
        with col2:
            st.write("")
            st.write("")
            if st.button("ğŸ“¦ ç«‹å³å¤‡ä»½", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨å¤‡ä»½æ•°æ®åº“..."):
                    success, result = backup_database(backup_dir)
                
                if success:
                    st.success(f"âœ… å¤‡ä»½æˆåŠŸï¼\næ–‡ä»¶è·¯å¾„: `{result}`")
                else:
                    st.error(f"âŒ å¤‡ä»½å¤±è´¥: {result}")
        
        st.markdown("---")
        st.markdown("### ğŸ“‚ å·²æœ‰å¤‡ä»½")
        
        backups = get_available_backups(backup_dir)
        
        if not backups:
            st.info("æš‚æ— å¤‡ä»½æ–‡ä»¶")
        else:
            st.write(f"å…±æ‰¾åˆ° **{len(backups)}** ä¸ªå¤‡ä»½æ–‡ä»¶:")
            
            for backup in backups:
                with st.expander(f"ğŸ“ {backup['filename']}", expanded=False):
                    col1, col2, col3 = st.columns([2, 1, 1])
                    
                    with col1:
                        st.write(f"**åˆ›å»ºæ—¶é—´**: {backup['created_time']}")
                        st.write(f"**æ–‡ä»¶å¤§å°**: {backup['size_mb']} MB")
                        st.write(f"**æ–‡ä»¶è·¯å¾„**: `{backup['filepath']}`")
                    
                    with col2:
                        if st.button("ğŸ”„ æ¢å¤æ­¤å¤‡ä»½", key=f"restore_{backup['filename']}"):
                            if st.session_state.get(f"confirm_restore_{backup['filename']}", False):
                                with st.spinner("æ­£åœ¨æ¢å¤æ•°æ®åº“..."):
                                    success, message = restore_database(backup['filepath'])
                                
                                if success:
                                    st.success(f"âœ… {message}")
                                    st.rerun()
                                else:
                                    st.error(f"âŒ æ¢å¤å¤±è´¥: {message}")
                                
                                st.session_state[f"confirm_restore_{backup['filename']}"] = False
                            else:
                                st.warning("âš ï¸ è¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤æ¢å¤")
                                st.session_state[f"confirm_restore_{backup['filename']}"] = True
                    
                    with col3:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤å¤‡ä»½", key=f"delete_{backup['filename']}"):
                            success, message = delete_backup(backup['filepath'])
                            if success:
                                st.success(message)
                                st.rerun()
                            else:
                                st.error(f"åˆ é™¤å¤±è´¥: {message}")
    
    # ========== Tab 3: æ•°æ®åˆ é™¤ ==========
    with tab3:
        st.markdown("### ğŸ—‘ï¸ æ•°æ®åˆ é™¤")
        st.warning("âš ï¸ **è­¦å‘Š**: åˆ é™¤æ“ä½œä¸å¯é€†ï¼Œå»ºè®®å…ˆå¤‡ä»½æ•°æ®åº“ï¼")
        
        # åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        st.markdown("#### ğŸ—“ï¸ æŒ‰æ—¥æœŸåˆ é™¤")
        
        available_dates = get_available_dates()
        
        if not available_dates:
            st.info("æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")
        else:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                delete_date = st.selectbox(
                    "é€‰æ‹©è¦åˆ é™¤çš„æ—¥æœŸ",
                    options=available_dates,
                    key="delete_date_selector"
                )
            
            with col2:
                st.write("")
                st.write("")
                if st.button("ğŸ—‘ï¸ åˆ é™¤è¯¥æ—¥æœŸæ•°æ®", key="delete_by_date", use_container_width=True):
                    if st.session_state.get("confirm_delete_date", False):
                        with st.spinner(f"æ­£åœ¨åˆ é™¤ {delete_date} çš„æ•°æ®..."):
                            success, message, count = delete_data_by_date(delete_date)
                        
                        if success:
                            st.success(f"âœ… {message}")
                            st.rerun()
                        else:
                            st.error(f"âŒ åˆ é™¤å¤±è´¥: {message}")
                        
                        st.session_state["confirm_delete_date"] = False
                    else:
                        st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤ {delete_date} çš„æ‰€æœ‰æ•°æ®ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                        st.session_state["confirm_delete_date"] = True
        
        st.markdown("---")
        
        # åˆ é™¤æŒ‡å®šå¹³å°çš„æ•°æ®
        st.markdown("#### ğŸŒ æŒ‰å¹³å°åˆ é™¤")
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            delete_platform = st.selectbox(
                "é€‰æ‹©å¹³å°",
                options=list(PLATFORM_NAMES.values()),
                key="delete_platform_selector"
            )
        
        with col2:
            delete_platform_date = st.selectbox(
                "é€‰æ‹©æ—¥æœŸï¼ˆå¯é€‰ï¼‰",
                options=["å…¨éƒ¨æ—¥æœŸ"] + (available_dates if available_dates else []),
                key="delete_platform_date_selector"
            )
        
        with col3:
            st.write("")
            st.write("")
            if st.button("ğŸ—‘ï¸ åˆ é™¤å¹³å°æ•°æ®", key="delete_by_platform", use_container_width=True):
                if st.session_state.get("confirm_delete_platform", False):
                    target_date = None if delete_platform_date == "å…¨éƒ¨æ—¥æœŸ" else delete_platform_date
                    
                    with st.spinner(f"æ­£åœ¨åˆ é™¤ {delete_platform} çš„æ•°æ®..."):
                        success, message, count = delete_data_by_platform(delete_platform, target_date)
                    
                    if success:
                        st.success(f"âœ… {message}")
                        st.rerun()
                    else:
                        st.error(f"âŒ åˆ é™¤å¤±è´¥: {message}")
                    
                    st.session_state["confirm_delete_platform"] = False
                else:
                    date_info = f" ({delete_platform_date})" if delete_platform_date != "å…¨éƒ¨æ—¥æœŸ" else ""
                    st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤ {delete_platform}{date_info} çš„æ•°æ®ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                    st.session_state["confirm_delete_platform"] = True
    
    # ========== Tab 4: æ•°æ®ç»´æŠ¤ ==========
    with tab4:
        st.markdown("### ğŸ”§ æ•°æ®ç»´æŠ¤")
        
        # æ£€æŸ¥é‡å¤è®°å½•
        st.markdown("#### ğŸ” é‡å¤è®°å½•æ£€æµ‹")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("æ£€æŸ¥å¹¶æ¸…ç†æ•°æ®åº“ä¸­çš„é‡å¤è®°å½•ï¼ˆç›¸åŒçš„æ—¥æœŸã€å¹³å°ã€å‘å¸ƒè€…ã€æ¨¡å‹åç§°ï¼‰")

        with col2:
            if st.button("ğŸ” æ£€æŸ¥é‡å¤è®°å½•", key="check_duplicates", use_container_width=True):
                with st.spinner("æ­£åœ¨æ£€æŸ¥é‡å¤è®°å½•..."):
                    duplicates = get_duplicate_records()

                if duplicates.empty:
                    st.success("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•")
                else:
                    total_duplicates = duplicates['count'].sum() - len(duplicates)
                    st.session_state['duplicates_found'] = duplicates
                    st.session_state['duplicate_count'] = total_duplicates
                    st.rerun()

        # æ˜¾ç¤ºæ£€æŸ¥ç»“æœ
        if 'duplicates_found' in st.session_state and not st.session_state['duplicates_found'].empty:
            duplicates = st.session_state['duplicates_found']
            total_duplicates = st.session_state['duplicate_count']

            st.warning(f"âš ï¸ å‘ç° {len(duplicates)} ç»„é‡å¤è®°å½•ï¼Œå…± {total_duplicates} æ¡é‡å¤æ•°æ®éœ€è¦æ¸…ç†")
            st.dataframe(
                duplicates.rename(columns={
                    'date': 'æ—¥æœŸ',
                    'repo': 'å¹³å°',
                    'publisher': 'å‘å¸ƒè€…',
                    'model_name': 'æ¨¡å‹åç§°',
                    'count': 'é‡å¤æ¬¡æ•°'
                }),
                use_container_width=True
            )

            col1, col2 = st.columns([3, 1])
            with col2:
                if st.button("ğŸ§¹ æ¸…é™¤é‡å¤è®°å½•", key="remove_duplicates", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨æ¸…é™¤é‡å¤è®°å½•..."):
                        success, message, count = remove_duplicate_records()

                    if success:
                        st.success(f"âœ… {message}")
                        # æ¸…é™¤session state
                        if 'duplicates_found' in st.session_state:
                            del st.session_state['duplicates_found']
                        if 'duplicate_count' in st.session_state:
                            del st.session_state['duplicate_count']
                        st.rerun()
                    else:
                        st.error(f"âŒ æ¸…é™¤å¤±è´¥: {message}")
        
        st.markdown("---")
        
        # æ•°æ®åº“ä¼˜åŒ–
        st.markdown("#### âš¡ æ•°æ®åº“ä¼˜åŒ–")
        st.info("æ•°æ®åº“ä¼˜åŒ–ï¼ˆVACUUMï¼‰å¯ä»¥å›æ”¶åˆ é™¤æ•°æ®åçš„ç©ºé—´ï¼Œå‡å°æ•°æ®åº“æ–‡ä»¶å¤§å°")
        
        if st.button("âš¡ ä¼˜åŒ–æ•°æ®åº“", key="vacuum_db"):
            with st.spinner("æ­£åœ¨ä¼˜åŒ–æ•°æ®åº“..."):
                success, message = vacuum_database()
            
            if success:
                st.success(f"âœ… {message}")
                st.rerun()
            else:
                st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {message}")
    
    # ========== Tab 5: æ•°æ®å¯¼å‡º ==========
    with tab5:
        st.markdown("### ğŸ“¤ æ•°æ®å¯¼å‡º")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            export_date = st.selectbox(
                "é€‰æ‹©å¯¼å‡ºæ—¥æœŸ",
                options=["å…¨éƒ¨æ—¥æœŸ"] + (available_dates if available_dates else []),
                key="export_date_selector"
            )
        
        with col2:
            export_filename = st.text_input(
                "æ–‡ä»¶å",
                value=f"database_export_{date.today().isoformat()}.xlsx",
                key="export_filename"
            )
        
        if st.button("ğŸ“¥ å¯¼å‡ºåˆ° Excel", type="primary", key="export_excel"):
            output_path = os.path.join("exports", export_filename)
            os.makedirs("exports", exist_ok=True)
            
            target_date = None if export_date == "å…¨éƒ¨æ—¥æœŸ" else export_date
            
            with st.spinner("æ­£åœ¨å¯¼å‡ºæ•°æ®..."):
                success, message = export_database_to_excel(output_path, target_date)
            
            if success:
                st.success(f"âœ… {message}")
                
                # æä¾›ä¸‹è½½
                with open(output_path, 'rb') as f:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½å¯¼å‡ºæ–‡ä»¶",
                        data=f.read(),
                        file_name=export_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            else:
                st.error(f"âŒ {message}")

    
    # ========== Tab 6: æ•°æ®å½•å…¥ ==========
    with tab6:
        st.markdown("### ğŸ“ æ•°æ®å½•å…¥")
        st.info("ğŸ’¡ æ”¯æŒå•æ¡æ•°æ®å½•å…¥å’Œ Excel æ‰¹é‡å¯¼å…¥")
        
        # åˆ›å»ºå­æ ‡ç­¾
        subtab1, subtab2 = st.tabs(["â• å•æ¡å½•å…¥", "ğŸ“„ æ‰¹é‡å¯¼å…¥"])
        
        # ========== å­Tab 1: å•æ¡å½•å…¥ ==========
        with subtab1:
            st.markdown("#### â• å•æ¡æ•°æ®å½•å…¥")
            st.markdown("---")
            
            # å¿…å¡«å­—æ®µ
            col1, col2 = st.columns(2)
            
            with col1:
                input_date = st.date_input(
                    "æ—¥æœŸ *",
                    value=date.today(),
                    help="æ•°æ®é‡‡é›†çš„æ—¥æœŸ"
                )
                input_date_str = input_date.strftime('%Y-%m-%d')
                
                input_repo = st.selectbox(
                    "å¹³å° *",
                    options=list(PLATFORM_NAMES.values()),
                    help="æ¨¡å‹æ‰€åœ¨çš„å¹³å°"
                )
            
            with col2:
                input_model_name = st.text_input(
                    "æ¨¡å‹åç§° *",
                    help="æ¨¡å‹çš„å®Œæ•´åç§°"
                )
                
                input_publisher = st.text_input(
                    "å‘å¸ƒè€… *",
                    help="æ¨¡å‹çš„å‘å¸ƒè€…/ä½œè€…"
                )
            
            input_download_count = st.number_input(
                "ä¸‹è½½é‡ *",
                min_value=0,
                value=0,
                step=1,
                help="æ¨¡å‹çš„ä¸‹è½½æ¬¡æ•°"
            )
            
            st.markdown("---")
            st.markdown("#### å¯é€‰å­—æ®µï¼ˆModel Tree ç›¸å…³ï¼‰")
            
            col3, col4, col5 = st.columns(3)
            
            with col3:
                input_base_model = st.text_input(
                    "åŸºç¡€æ¨¡å‹",
                    help="è¡ç”Ÿæ¨¡å‹çš„åŸºç¡€æ¨¡å‹åç§°"
                )
            
            with col4:
                input_model_type = st.selectbox(
                    "æ¨¡å‹ç±»å‹",
                    options=["", "original", "finetune", "adapter", "lora", "other"],
                    help="æ¨¡å‹çš„ç±»å‹åˆ†ç±»"
                )
            
            with col5:
                input_model_category = st.selectbox(
                    "æ¨¡å‹åˆ†ç±»",
                    options=["", "ernie-4.5", "paddleocr-vl", "other-ernie", "other"],
                    help="æ¨¡å‹çš„ç³»åˆ—åˆ†ç±»"
                )
            
            st.markdown("---")
            
            col_btn1, col_btn2 = st.columns([3, 1])
            
            with col_btn2:
                if st.button("ğŸ’¾ ä¿å­˜æ•°æ®", type="primary", use_container_width=True, key="insert_single"):
                    # è½¬æ¢ç©ºå­—ç¬¦ä¸²ä¸º None
                    base_model = input_base_model if input_base_model else None
                    model_type = input_model_type if input_model_type else None
                    model_category = input_model_category if input_model_category else None
                    
                    with st.spinner("æ­£åœ¨ä¿å­˜æ•°æ®..."):
                        success, message = insert_single_record(
                            date=input_date_str,
                            repo=input_repo,
                            model_name=input_model_name,
                            publisher=input_publisher,
                            download_count=input_download_count,
                            base_model=base_model,
                            model_type=model_type,
                            model_category=model_category
                        )
                    
                    if success:
                        st.success(f"âœ… {message}")
                        st.balloons()
                    else:
                        st.error(f"âŒ {message}")
        
        # ========== å­Tab 2: æ‰¹é‡å¯¼å…¥ ==========
        with subtab2:
            st.markdown("#### ğŸ“„ Excel æ‰¹é‡å¯¼å…¥")
            st.markdown("---")
            
            # è¯´æ˜ä¿¡æ¯
            st.info("""
            ğŸ“‹ **Excel æ–‡ä»¶æ ¼å¼è¦æ±‚ï¼š**
            
            **å¿…éœ€åˆ—**ï¼ˆç¼ºä¸€ä¸å¯ï¼‰ï¼š
            - `date`: æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            - `repo`: å¹³å°åç§°
            - `model_name`: æ¨¡å‹åç§°
            - `publisher`: å‘å¸ƒè€…
            - `download_count`: ä¸‹è½½é‡ï¼ˆæ•°å­—ï¼‰
            
            **å¯é€‰åˆ—**ï¼š
            - `base_model`: åŸºç¡€æ¨¡å‹ï¼ˆç”¨äºè¡ç”Ÿæ¨¡å‹ï¼‰
            - `model_type`: æ¨¡å‹ç±»å‹ï¼ˆoriginal, finetune, adapter, lora, otherï¼‰
            - `model_category`: æ¨¡å‹åˆ†ç±»ï¼ˆernie-4.5, paddleocr-vl, other-ernie, otherï¼‰
            """)
            
            # ä¸‹è½½æ¨¡æ¿
            template_data = {
                'date': ['2025-01-01', '2025-01-01'],
                'repo': ['Hugging Face', 'ModelScope'],
                'model_name': ['ç¤ºä¾‹æ¨¡å‹1', 'ç¤ºä¾‹æ¨¡å‹2'],
                'publisher': ['ç¤ºä¾‹å‘å¸ƒè€…1', 'ç¤ºä¾‹å‘å¸ƒè€…2'],
                'download_count': [1000, 2000],
                'base_model': ['', ''],
                'model_type': ['', ''],
                'model_category': ['', '']
            }
            template_df = pd.DataFrame(template_data)
            
            template_buffer = BytesIO()
            with pd.ExcelWriter(template_buffer, engine='openpyxl') as writer:
                template_df.to_excel(writer, index=False, sheet_name='æ¨¡å‹æ•°æ®')
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel æ¨¡æ¿",
                data=template_buffer.getvalue(),
                file_name="å¯¼å…¥æ¨¡æ¿.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="ä¸‹è½½åŒ…å«ç¤ºä¾‹æ•°æ®çš„ Excel æ¨¡æ¿"
            )
            
            st.markdown("---")
            
            # æ–‡ä»¶ä¸Šä¼ 
            uploaded_file = st.file_uploader(
                "é€‰æ‹© Excel æ–‡ä»¶",
                type=['xlsx', 'xls'],
                help="ä¸Šä¼ åŒ…å«æ¨¡å‹æ•°æ®çš„ Excel æ–‡ä»¶"
            )
            
            if uploaded_file is not None:
                # é¢„è§ˆä¸Šä¼ çš„æ–‡ä»¶
                st.markdown("##### ğŸ“Š æ–‡ä»¶é¢„è§ˆ")
                try:
                    preview_df = pd.read_excel(uploaded_file, engine='openpyxl')
                    st.dataframe(preview_df.head(10), use_container_width=True)
                    st.info(f"æ–‡ä»¶åŒ…å« {len(preview_df)} è¡Œæ•°æ®")
                    
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    uploaded_file.seek(0)
                except Exception as e:
                    st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
                    uploaded_file = None
            
            if uploaded_file is not None:
                st.markdown("---")
                
                # å¯¼å…¥é€‰é¡¹
                col_opt1, col_opt2 = st.columns(2)
                
                with col_opt1:
                    skip_duplicates = st.radio(
                        "é‡åˆ°é‡å¤è®°å½•æ—¶",
                        options=[True, False],
                        format_func=lambda x: "è·³è¿‡ï¼ˆæ¨èï¼‰" if x else "è¦†ç›–",
                        help="é€‰æ‹©å¦‚ä½•å¤„ç†ä¸æ•°æ®åº“ä¸­å·²å­˜åœ¨è®°å½•ç›¸åŒçš„æ•°æ®"
                    )
                
                col_import1, col_import2 = st.columns([3, 1])
                
                with col_import2:
                    if st.button("ğŸ“¤ å¼€å§‹å¯¼å…¥", type="primary", use_container_width=True, key="import_excel"):
                        with st.spinner("æ­£åœ¨å¯¼å…¥æ•°æ®..."):
                            # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                            uploaded_file.seek(0)
                            success, message, stats = import_from_excel(uploaded_file, skip_duplicates)
                        
                        if success:
                            st.success("âœ… å¯¼å…¥å®Œæˆï¼")

                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

                            with col_stat1:
                                st.metric("æ€»è®°å½•æ•°", stats['total'])

                            with col_stat2:
                                st.metric("æˆåŠŸæ’å…¥", stats['inserted'], delta=stats['inserted'])

                            with col_stat3:
                                st.metric("è·³è¿‡é‡å¤", stats['skipped'])

                            with col_stat4:
                                st.metric("é”™è¯¯è®°å½•", stats['errors'], delta=-stats['errors'] if stats['errors'] > 0 else 0)

                            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                            with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯"):
                                st.text(message)

                            if stats['inserted'] > 0:
                                st.balloons()
                        else:
                            st.error(f"âŒ å¯¼å…¥å¤±è´¥")
                            st.error(message)

    # ========== Tab 7: æ•°æ®ç¼–è¾‘ ==========
    with tab7:
        from ernie_tracker.db_manager import search_records, get_record_by_rowid, update_record, delete_record_by_rowid

        st.markdown("### âœï¸ æ•°æ®ç¼–è¾‘")
        st.info("ğŸ’¡ æœç´¢å¹¶ç¼–è¾‘æ•°æ®åº“ä¸­çš„è®°å½•")

        # æœç´¢åŒºåŸŸ
        st.markdown("#### ğŸ” æœç´¢è®°å½•")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            search_date = st.selectbox(
                "æ—¥æœŸ",
                options=["å…¨éƒ¨"] + (available_dates if available_dates else []),
                key="search_date"
            )

        with col2:
            search_repo = st.selectbox(
                "å¹³å°",
                options=["å…¨éƒ¨"] + list(PLATFORM_NAMES.values()),
                key="search_repo"
            )

        with col3:
            search_model_name = st.text_input(
                "æ¨¡å‹åç§°ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰",
                key="search_model_name"
            )

        with col4:
            search_publisher = st.text_input(
                "å‘å¸ƒè€…ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰",
                key="search_publisher"
            )

        # æœç´¢æŒ‰é’®
        col_search1, col_search2 = st.columns([3, 1])
        with col_search2:
            search_button = st.button("ğŸ” æœç´¢", type="primary", use_container_width=True, key="search_btn")

        # æ‰§è¡Œæœç´¢
        if search_button or 'search_results' in st.session_state:
            # æ„å»ºæœç´¢å‚æ•°
            search_params = {}

            if search_date != "å…¨éƒ¨":
                search_params['date_filter'] = search_date

            if search_repo != "å…¨éƒ¨":
                search_params['repo_filter'] = search_repo

            if search_model_name:
                search_params['model_name_filter'] = search_model_name

            if search_publisher:
                search_params['publisher_filter'] = search_publisher

            # æ‰§è¡Œæœç´¢
            if search_button:
                with st.spinner("æ­£åœ¨æœç´¢..."):
                    results = search_records(**search_params)
                    st.session_state['search_results'] = results
            else:
                results = st.session_state.get('search_results', pd.DataFrame())

            # æ˜¾ç¤ºæœç´¢ç»“æœ
            st.markdown("---")
            st.markdown("#### ğŸ“‹ æœç´¢ç»“æœ")

            if results.empty:
                st.info("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å½•")
            else:
                st.success(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•")

                # æ˜¾ç¤ºæœç´¢ç»“æœè¡¨æ ¼ï¼ˆå¯é€‰æ‹©ï¼‰
                # é€‰æ‹©è¦ç¼–è¾‘çš„è®°å½•
                st.markdown("##### é€‰æ‹©è¦ç¼–è¾‘çš„è®°å½•ï¼š")

                # åˆ›å»ºä¸€ä¸ªæ›´å‹å¥½çš„æ˜¾ç¤ºæ ¼å¼
                display_df = results.copy()
                display_df['é€‰æ‹©'] = False

                # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼ŒæŠŠ rowid æ”¾åœ¨å‰é¢
                cols = ['rowid', 'date', 'repo', 'model_name', 'publisher', 'download_count']
                optional_cols = ['base_model', 'model_type', 'model_category', 'tags']

                for col in optional_cols:
                    if col in display_df.columns:
                        cols.append(col)

                display_df = display_df[cols]

                # ä½¿ç”¨ data_editor æ˜¾ç¤ºå¯é€‰æ‹©çš„è¡¨æ ¼
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    height=300
                )

                # è¾“å…¥è¦ç¼–è¾‘çš„è®°å½• rowid
                st.markdown("---")
                st.markdown("#### âœï¸ ç¼–è¾‘è®°å½•")

                col_edit1, col_edit2 = st.columns([2, 2])

                with col_edit1:
                    edit_rowid = st.number_input(
                        "è¾“å…¥è¦ç¼–è¾‘çš„è®°å½• rowid",
                        min_value=1,
                        value=int(results.iloc[0]['rowid']) if not results.empty else 1,
                        step=1,
                        key="edit_rowid"
                    )

                with col_edit2:
                    st.write("")
                    st.write("")
                    load_button = st.button("ğŸ“¥ åŠ è½½è®°å½•", use_container_width=True, key="load_record")

                # åŠ è½½è®°å½•è¿›è¡Œç¼–è¾‘
                if load_button or 'editing_record' in st.session_state:
                    if load_button:
                        record = get_record_by_rowid(edit_rowid)
                        if record:
                            st.session_state['editing_record'] = record
                            st.session_state['editing_rowid'] = edit_rowid
                        else:
                            st.error(f"æœªæ‰¾åˆ° rowid={edit_rowid} çš„è®°å½•")
                            if 'editing_record' in st.session_state:
                                del st.session_state['editing_record']

                    if 'editing_record' in st.session_state:
                        record = st.session_state['editing_record']

                        st.markdown(f"##### æ­£åœ¨ç¼–è¾‘ rowid={st.session_state['editing_rowid']} çš„è®°å½•")
                        st.markdown("---")

                        # ç¼–è¾‘è¡¨å•
                        col_form1, col_form2 = st.columns(2)

                        with col_form1:
                            edit_date = st.date_input(
                                "æ—¥æœŸ *",
                                value=pd.to_datetime(record['date']).date() if record['date'] else date.today(),
                                key="edit_date_input"
                            )
                            edit_date_str = edit_date.strftime('%Y-%m-%d')

                            edit_repo = st.selectbox(
                                "å¹³å° *",
                                options=list(PLATFORM_NAMES.values()),
                                index=list(PLATFORM_NAMES.values()).index(record['repo']) if record['repo'] in list(PLATFORM_NAMES.values()) else 0,
                                key="edit_repo_input"
                            )

                            edit_model_name = st.text_input(
                                "æ¨¡å‹åç§° *",
                                value=record['model_name'] or "",
                                key="edit_model_name_input"
                            )

                        with col_form2:
                            edit_publisher = st.text_input(
                                "å‘å¸ƒè€… *",
                                value=record['publisher'] or "",
                                key="edit_publisher_input"
                            )

                            edit_download_count = st.number_input(
                                "ä¸‹è½½é‡ *",
                                min_value=0,
                                value=int(record['download_count']) if record['download_count'] else 0,
                                step=1,
                                key="edit_download_count_input"
                            )

                        st.markdown("##### Model Tree ç›¸å…³å­—æ®µï¼ˆå¯é€‰ï¼‰")

                        col_form3, col_form4, col_form5 = st.columns(3)

                        with col_form3:
                            edit_base_model = st.text_input(
                                "åŸºç¡€æ¨¡å‹",
                                value=record['base_model'] or "",
                                key="edit_base_model_input"
                            )

                        with col_form4:
                            model_type_options = ["", "original", "finetune", "adapter", "lora", "other"]
                            current_type = record['model_type'] or ""
                            edit_model_type = st.selectbox(
                                "æ¨¡å‹ç±»å‹",
                                options=model_type_options,
                                index=model_type_options.index(current_type) if current_type in model_type_options else 0,
                                key="edit_model_type_input"
                            )

                        with col_form5:
                            category_options = ["", "ernie-4.5", "paddleocr-vl", "other-ernie", "other"]
                            current_category = record['model_category'] or ""
                            edit_model_category = st.selectbox(
                                "æ¨¡å‹åˆ†ç±»",
                                options=category_options,
                                index=category_options.index(current_category) if current_category in category_options else 0,
                                key="edit_model_category_input"
                            )

                        edit_tags = st.text_input(
                            "æ ‡ç­¾",
                            value=record['tags'] or "",
                            key="edit_tags_input"
                        )

                        st.markdown("---")

                        # æ“ä½œæŒ‰é’®
                        col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])

                        with col_btn2:
                            if st.button("ğŸ’¾ ä¿å­˜æ›´æ”¹", type="primary", use_container_width=True, key="save_edit"):
                                # è½¬æ¢ç©ºå­—ç¬¦ä¸²ä¸º None
                                base_model_value = edit_base_model if edit_base_model else None
                                model_type_value = edit_model_type if edit_model_type else None
                                model_category_value = edit_model_category if edit_model_category else None
                                tags_value = edit_tags if edit_tags else None

                                with st.spinner("æ­£åœ¨ä¿å­˜..."):
                                    success, message = update_record(
                                        rowid=st.session_state['editing_rowid'],
                                        date=edit_date_str,
                                        repo=edit_repo,
                                        model_name=edit_model_name,
                                        publisher=edit_publisher,
                                        download_count=edit_download_count,
                                        base_model=base_model_value,
                                        model_type=model_type_value,
                                        model_category=model_category_value,
                                        tags=tags_value
                                    )

                                if success:
                                    st.success(f"âœ… {message}")
                                    # æ¸…é™¤ç¼–è¾‘çŠ¶æ€
                                    if 'editing_record' in st.session_state:
                                        del st.session_state['editing_record']
                                    if 'editing_rowid' in st.session_state:
                                        del st.session_state['editing_rowid']
                                    # é‡æ–°æœç´¢
                                    results = search_records(**search_params)
                                    st.session_state['search_results'] = results
                                    st.rerun()
                                else:
                                    st.error(f"âŒ {message}")

                        with col_btn3:
                            if st.button("ğŸ—‘ï¸ åˆ é™¤è®°å½•", use_container_width=True, key="delete_edit"):
                                if st.session_state.get("confirm_delete_edit", False):
                                    with st.spinner("æ­£åœ¨åˆ é™¤..."):
                                        success, message = delete_record_by_rowid(st.session_state['editing_rowid'])

                                    if success:
                                        st.success(f"âœ… {message}")
                                        # æ¸…é™¤ç¼–è¾‘çŠ¶æ€
                                        if 'editing_record' in st.session_state:
                                            del st.session_state['editing_record']
                                        if 'editing_rowid' in st.session_state:
                                            del st.session_state['editing_rowid']
                                        st.session_state["confirm_delete_edit"] = False
                                        # é‡æ–°æœç´¢
                                        results = search_records(**search_params)
                                        st.session_state['search_results'] = results
                                        st.rerun()
                                    else:
                                        st.error(f"âŒ {message}")
                                        st.session_state["confirm_delete_edit"] = False
                                else:
                                    st.warning("âš ï¸ ç¡®è®¤åˆ é™¤ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                                    st.session_state["confirm_delete_edit"] = True

# ================= è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†ææ¨¡å— =================
elif page == "ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€":
    from ernie_tracker.analysis import get_available_dates
    from ernie_tracker.model_analysis import analyze_derivative_ecosystem, OFFICIAL_MODEL_GROUPS
    import plotly.express as px
    import plotly.graph_objects as go
    from io import BytesIO

    st.markdown("## ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†æ")
    st.info("ğŸ“Š åˆ†æ ERNIE-4.5 å’Œ PaddleOCR-VL çš„è¡ç”Ÿæ¨¡å‹ç”Ÿæ€ï¼ŒåŒ…æ‹¬ Finetuneã€Adapterã€é‡åŒ–æ¨¡å‹ç­‰ã€‚æ”¯æŒæŒ‰æ¨¡å‹ç³»åˆ—ç­›é€‰ï¼Œå¯å•ç‹¬åˆ†æ ERNIE-4.5 æˆ– PaddleOCR-VLã€‚")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # é…ç½®é€‰é¡¹
        col_config1, col_config2 = st.columns([2, 2])

        with col_config1:
            # æ—¥æœŸé€‰æ‹©
            selected_date = st.selectbox(
                "ğŸ“… é€‰æ‹©åˆ†ææ—¥æœŸ",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ—¥æœŸ"
            )

        with col_config2:
            # æ•°æ®æºç­›é€‰
            data_source_filter = st.radio(
                "ğŸ“‚ æ•°æ®æ¥æºç­›é€‰",
                options=["å…¨éƒ¨æ¨¡å‹", "ä»… Model Tree"],
                index=0,
                horizontal=True,
                help="é€‰æ‹©è¦åˆ†æçš„æ¨¡å‹èŒƒå›´"
            )

        # æ¨¡å‹ç³»åˆ—ç­›é€‰
        st.markdown("#### ğŸ¯ æ¨¡å‹ç³»åˆ—ç­›é€‰")
        selected_series = st.multiselect(
            "é€‰æ‹©è¦åˆ†æçš„æ¨¡å‹ç³»åˆ—",
            options=["ERNIE-4.5", "PaddleOCR-VL", "å…¶ä»–ERNIE"],
            default=["ERNIE-4.5", "PaddleOCR-VL"],
            help="å¯ä»¥é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹ç³»åˆ—è¿›è¡Œåˆ†æ"
        )

        if not selected_series:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ç³»åˆ—")
            st.stop()

        # æ˜¾ç¤ºç­›é€‰è¯´æ˜
        series_info = "ã€".join(selected_series)
        if data_source_filter == "ä»… Model Tree":
            st.info(f"ğŸŒ³ **Model Tree æ¨¡å¼** | ğŸ“Š **åˆ†æç³»åˆ—**: {series_info} | ä»…åˆ†æé€šè¿‡ Model Tree æ‰¾åˆ°çš„è¡ç”Ÿæ¨¡å‹ï¼ˆæœ‰æ˜ç¡®çš„ base_model å…³ç³»ï¼‰")
        else:
            st.info(f"ğŸ” **å…¨éƒ¨æ¨¡å‹æ¨¡å¼** | ğŸ“Š **åˆ†æç³»åˆ—**: {series_info} | åˆ†ææ‰€æœ‰ç›¸å…³æ¨¡å‹ï¼ˆåŒ…æ‹¬é€šè¿‡æœç´¢å’Œ Model Tree å‘ç°çš„ï¼‰")

        if st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†æè¡ç”Ÿæ¨¡å‹ç”Ÿæ€..."):
                # åŠ è½½æ•°æ®
                df = load_data_from_db(date_filter=selected_date)

                if df.empty:
                    st.error(f"âŒ {selected_date} æ²¡æœ‰æ•°æ®")
                else:
                    # ç­›é€‰ HuggingFace å¹³å°çš„ ERNIE å’Œ PaddleOCR ç›¸å…³æ•°æ®
                    hf_df = df[df['repo'] == 'Hugging Face'].copy()

                    if hf_df.empty:
                        st.warning("âš ï¸ è¯¥æ—¥æœŸæ²¡æœ‰ Hugging Face å¹³å°çš„æ•°æ®")
                    else:
                        # æ ¹æ®æ•°æ®æºç­›é€‰é€‰é¡¹è¿‡æ»¤æ•°æ®
                        if data_source_filter == "ä»… Model Tree":
                            # åªä¿ç•™é€šè¿‡ Model Tree æ‰¾åˆ°çš„æ¨¡å‹ï¼ˆdata_source = 'model_tree' æˆ– 'both'ï¼‰
                            # æˆ–è€…è‡³å°‘è¦æœ‰ base_model çš„è®°å½•
                            if 'data_source' in hf_df.columns:
                                hf_df = hf_df[
                                    (hf_df['data_source'].isin(['model_tree', 'both'])) |
                                    (hf_df['base_model'].notna() & (hf_df['base_model'] != '') & (hf_df['base_model'] != 'None'))
                                ].copy()
                            else:
                                # å¦‚æœæ²¡æœ‰ data_source åˆ—ï¼Œä½¿ç”¨ base_model åˆ¤æ–­
                                hf_df = hf_df[
                                    hf_df['base_model'].notna() &
                                    (hf_df['base_model'] != '') &
                                    (hf_df['base_model'] != 'None')
                                ].copy()

                            if hf_df.empty:
                                st.warning("âš ï¸ è¯¥æ—¥æœŸæ²¡æœ‰ Model Tree è¡ç”Ÿæ¨¡å‹æ•°æ®")
                                st.stop()

                            st.success(f"âœ… ç­›é€‰åå…± {len(hf_df)} ä¸ª Model Tree è¡ç”Ÿæ¨¡å‹")
                        else:
                            st.success(f"âœ… å…± {len(hf_df)} ä¸ª HuggingFace æ¨¡å‹")

                        # æ ¹æ®æ¨¡å‹ç³»åˆ—ç­›é€‰
                        if 'model_category' in hf_df.columns:
                            # æ˜ å°„ç”¨æˆ·é€‰æ‹©åˆ° model_category å€¼
                            series_mapping = {
                                "ERNIE-4.5": "ernie-4.5",
                                "PaddleOCR-VL": "paddleocr-vl",
                                "å…¶ä»–ERNIE": "other-ernie"
                            }
                            selected_categories = [series_mapping[s] for s in selected_series if s in series_mapping]

                            if selected_categories:
                                hf_df = hf_df[hf_df['model_category'].isin(selected_categories)].copy()

                                if hf_df.empty:
                                    st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆé€‰æ‹©çš„æ¨¡å‹ç³»åˆ—ï¼ˆ{series_info}ï¼‰çš„æ•°æ®")
                                    st.stop()

                                st.info(f"ğŸ¯ æ¨¡å‹ç³»åˆ—ç­›é€‰å: {len(hf_df)} ä¸ªæ¨¡å‹")

                        # è¿›è¡Œè¡ç”Ÿç”Ÿæ€åˆ†æ
                        analysis_result = analyze_derivative_ecosystem(hf_df, infer_missing=True)

                        st.success(f"âœ… åˆ†æå®Œæˆï¼åˆ†ææ—¥æœŸï¼š{selected_date}")

                        # ========== 1. æ€»ä½“æ¦‚è§ˆ ==========
                        st.markdown("### ğŸ“Š æ€»ä½“æ¦‚è§ˆ")

                        col1, col2, col3, col4 = st.columns(4)

                        total_models = len(hf_df)
                        derivative_models = analysis_result['total_derivatives']
                        inferred_models = analysis_result['total_inferred']
                        official_models = len(hf_df[hf_df.get('model_type') == 'original']) if 'model_type' in hf_df.columns else 0

                        with col1:
                            st.metric("æ€»æ¨¡å‹æ•°", f"{total_models:,}")

                        with col2:
                            st.metric("è¡ç”Ÿæ¨¡å‹æ•°", f"{derivative_models:,}")

                        with col3:
                            derivative_rate = (derivative_models / total_models * 100) if total_models > 0 else 0
                            st.metric("è¡ç”Ÿç‡", f"{derivative_rate:.1f}%")

                        with col4:
                            st.metric("æ¨æ–­çš„ base_model", f"{inferred_models:,}")

                        st.markdown("---")

                        # ========== 2. æŒ‰ model_category ç»Ÿè®¡ ==========
                        st.markdown("### ğŸ“ˆ æŒ‰æ¨¡å‹ç³»åˆ—åˆ†ç±»")

                        if 'model_category' in hf_df.columns:
                            category_counts = hf_df[hf_df['model_category'].notna()]['model_category'].value_counts()

                            if not category_counts.empty:
                                col_chart1, col_chart2 = st.columns([1, 1])

                                with col_chart1:
                                    # é¥¼å›¾
                                    fig_pie = px.pie(
                                        values=category_counts.values,
                                        names=category_counts.index,
                                        title="æ¨¡å‹ç³»åˆ—åˆ†å¸ƒ",
                                        hole=0.3
                                    )
                                    fig_pie.update_traces(textposition='inside', textinfo='percent+label')
                                    st.plotly_chart(fig_pie, use_container_width=True)

                                with col_chart2:
                                    # è¡¨æ ¼
                                    category_df = pd.DataFrame({
                                        'æ¨¡å‹ç³»åˆ—': category_counts.index,
                                        'æ•°é‡': category_counts.values,
                                        'å æ¯”': [f"{v/category_counts.sum()*100:.1f}%" for v in category_counts.values]
                                    })
                                    st.dataframe(category_df, use_container_width=True, height=250)

                        st.markdown("---")

                        # ========== 3. æŒ‰ model_type ç»Ÿè®¡ ==========
                        st.markdown("### ğŸ”§ æŒ‰æ¨¡å‹ç±»å‹åˆ†ç±»")
                        st.info("ğŸ“Œ ç»Ÿè®¡è¡ç”Ÿæ¨¡å‹ç±»å‹ï¼Œä¸åŒ…æ‹¬å®˜æ–¹åŸå§‹æ¨¡å‹ï¼ˆoriginalï¼‰")

                        if 'model_type' in hf_df.columns:
                            # è¿‡æ»¤æ‰ 'original' ç±»å‹ï¼ˆå®˜æ–¹åŸå§‹æ¨¡å‹ï¼‰
                            type_df_filtered = hf_df[
                                hf_df['model_type'].notna() &
                                (hf_df['model_type'] != 'original')
                            ]
                            type_counts = type_df_filtered['model_type'].value_counts()

                            if not type_counts.empty:
                                col_chart3, col_chart4 = st.columns([1, 1])

                                with col_chart3:
                                    # æŸ±çŠ¶å›¾
                                    fig_bar = px.bar(
                                        x=type_counts.index,
                                        y=type_counts.values,
                                        title="æ¨¡å‹ç±»å‹åˆ†å¸ƒ",
                                        labels={'x': 'æ¨¡å‹ç±»å‹', 'y': 'æ•°é‡'},
                                        text=type_counts.values
                                    )
                                    fig_bar.update_traces(texttemplate='%{text}', textposition='outside')
                                    fig_bar.update_layout(showlegend=False)
                                    st.plotly_chart(fig_bar, use_container_width=True)

                                with col_chart4:
                                    # è¡¨æ ¼
                                    type_df = pd.DataFrame({
                                        'æ¨¡å‹ç±»å‹': type_counts.index,
                                        'æ•°é‡': type_counts.values,
                                        'å æ¯”': [f"{v/type_counts.sum()*100:.1f}%" for v in type_counts.values]
                                    })

                                    # æ·»åŠ ç±»å‹è¯´æ˜
                                    type_labels = {
                                        'quantized': 'é‡åŒ–æ¨¡å‹',
                                        'finetune': 'å¾®è°ƒæ¨¡å‹',
                                        'adapter': 'Adapteræ¨¡å‹',
                                        'lora': 'LoRAæ¨¡å‹',
                                        'merge': 'åˆå¹¶æ¨¡å‹',
                                        'original': 'å®˜æ–¹åŸå§‹',
                                        'other': 'å…¶ä»–'
                                    }
                                    type_df['è¯´æ˜'] = type_df['æ¨¡å‹ç±»å‹'].map(type_labels).fillna('æœªçŸ¥')

                                    st.dataframe(type_df, use_container_width=True, height=250)

                        st.markdown("---")

                        # ========== 4. æŒ‰å®˜æ–¹æ¨¡å‹åˆ†ç»„ç»Ÿè®¡ ==========
                        st.markdown("### ğŸ·ï¸ æŒ‰å®˜æ–¹æ¨¡å‹åˆ†ç»„ç»Ÿè®¡")
                        st.info("ğŸ“Œ ç»Ÿè®¡æ¯ä¸ªå®˜æ–¹æ¨¡å‹çš„è¡ç”Ÿç”Ÿæ€æƒ…å†µ")

                        # æ˜¾ç¤ºæ±‡æ€»è¡¨æ ¼
                        group_summary_data = []
                        for group_name, group_data in analysis_result['by_group'].items():
                            if group_data['total'] > 0:
                                group_summary_data.append({
                                    'æ¨¡å‹åˆ†ç»„': group_name,
                                    'è¡ç”Ÿæ¨¡å‹æ€»æ•°': group_data['total'],
                                    'Quantized': group_data['by_type'].get('quantized', 0),
                                    'Finetune': group_data['by_type'].get('finetune', 0),
                                    'Adapter': group_data['by_type'].get('adapter', 0),
                                    'Merge': group_data['by_type'].get('merge', 0),
                                    'Other': group_data['by_type'].get('other', 0)
                                })

                        if group_summary_data:
                            summary_df = pd.DataFrame(group_summary_data)
                            st.dataframe(summary_df, use_container_width=True)

                            # å¯è§†åŒ–ï¼šå„åˆ†ç»„çš„è¡ç”Ÿæ¨¡å‹æ•°é‡å¯¹æ¯”
                            fig_group = px.bar(
                                summary_df,
                                x='æ¨¡å‹åˆ†ç»„',
                                y='è¡ç”Ÿæ¨¡å‹æ€»æ•°',
                                title="å„å®˜æ–¹æ¨¡å‹åˆ†ç»„çš„è¡ç”Ÿæ¨¡å‹æ•°é‡",
                                text='è¡ç”Ÿæ¨¡å‹æ€»æ•°'
                            )
                            fig_group.update_traces(texttemplate='%{text}', textposition='outside')
                            fig_group.update_layout(showlegend=False)
                            st.plotly_chart(fig_group, use_container_width=True)

                            # è¯¦ç»†å±•å¼€
                            st.markdown("#### ğŸ“‹ å„åˆ†ç»„è¯¦ç»†ä¿¡æ¯")

                            for group_name, group_data in analysis_result['by_group'].items():
                                if group_data['total'] > 0:
                                    with st.expander(f"ğŸ” {group_name} ({group_data['total']} ä¸ªè¡ç”Ÿæ¨¡å‹)", expanded=False):
                                        st.markdown(f"**åŒ…å«çš„å®˜æ–¹æ¨¡å‹ï¼š**")
                                        for base_model in group_data['base_models']:
                                            st.markdown(f"- `{base_model}`")

                                        st.markdown(f"\n**ç±»å‹åˆ†å¸ƒï¼š**")
                                        type_dist_data = []
                                        for model_type, count in sorted(group_data['by_type'].items(), key=lambda x: x[1], reverse=True):
                                            percentage = (count / group_data['total']) * 100
                                            type_dist_data.append({
                                                'ç±»å‹': model_type,
                                                'æ•°é‡': count,
                                                'å æ¯”': f"{percentage:.1f}%"
                                            })

                                        st.dataframe(pd.DataFrame(type_dist_data), use_container_width=True)

                                        if group_data['by_data_source']:
                                            st.markdown(f"\n**æ•°æ®æ¥æºï¼š**")
                                            source_labels = {
                                                'search': 'æœç´¢å‘ç°',
                                                'model_tree': 'Model Tree',
                                                'both': 'æœç´¢+Model Tree'
                                            }
                                            for source, count in group_data['by_data_source'].items():
                                                label = source_labels.get(source, source)
                                                st.markdown(f"- {label}: {count} ä¸ª")

                                        st.markdown(f"\n**æ ·æœ¬æ¨¡å‹ï¼ˆå‰10ä¸ªï¼‰ï¼š**")
                                        if group_data['models']:
                                            samples = group_data['models'][:10]
                                            sample_df = pd.DataFrame(samples)
                                            sample_df['download_count'] = sample_df['download_count'].apply(lambda x: int(x) if pd.notna(x) else 0)
                                            st.dataframe(sample_df, use_container_width=True)
                        else:
                            st.info("æš‚æ— è¡ç”Ÿæ¨¡å‹æ•°æ®")

                        st.markdown("---")

                        # ========== 5. è¡ç”Ÿæ¨¡å‹è¯¦ç»†åˆ—è¡¨ ==========
                        st.markdown("### ğŸ“‹ è¡ç”Ÿæ¨¡å‹è¯¦ç»†åˆ—è¡¨")

                        # è·å–æ‰€æœ‰è¡ç”Ÿæ¨¡å‹
                        derivatives = hf_df[
                            hf_df['base_model'].notna() &
                            (hf_df['base_model'] != '') &
                            (hf_df['base_model'] != 'None')
                        ].copy()

                        if not derivatives.empty:
                            # ç­›é€‰å™¨
                            col_filter1, col_filter2, col_filter3 = st.columns(3)

                            with col_filter1:
                                category_options = ['å…¨éƒ¨'] + sorted(derivatives['model_category'].dropna().unique().tolist())
                                selected_category = st.selectbox("ç­›é€‰æ¨¡å‹ç³»åˆ—", category_options, key="filter_category")

                            with col_filter2:
                                type_options = ['å…¨éƒ¨'] + sorted(derivatives['model_type'].dropna().unique().tolist())
                                selected_type = st.selectbox("ç­›é€‰æ¨¡å‹ç±»å‹", type_options, key="filter_type")

                            with col_filter3:
                                base_options = ['å…¨éƒ¨'] + sorted(derivatives['base_model'].dropna().unique().tolist())
                                selected_base = st.selectbox("ç­›é€‰åŸºç¡€æ¨¡å‹", base_options, key="filter_base")

                            # åº”ç”¨ç­›é€‰
                            filtered_derivatives = derivatives.copy()

                            if selected_category != 'å…¨éƒ¨':
                                filtered_derivatives = filtered_derivatives[filtered_derivatives['model_category'] == selected_category]

                            if selected_type != 'å…¨éƒ¨':
                                filtered_derivatives = filtered_derivatives[filtered_derivatives['model_type'] == selected_type]

                            if selected_base != 'å…¨éƒ¨':
                                filtered_derivatives = filtered_derivatives[filtered_derivatives['base_model'] == selected_base]

                            st.info(f"ğŸ“Š å…± {len(filtered_derivatives)} ä¸ªè¡ç”Ÿæ¨¡å‹ç¬¦åˆç­›é€‰æ¡ä»¶")

                            # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                            display_cols = ['model_name', 'publisher', 'download_count', 'model_type',
                                          'model_category', 'base_model', 'data_source']
                            available_cols = [col for col in display_cols if col in filtered_derivatives.columns]

                            display_df = filtered_derivatives[available_cols].copy()
                            display_df['download_count'] = display_df['download_count'].apply(lambda x: int(x) if pd.notna(x) else 0)
                            display_df = display_df.sort_values('download_count', ascending=False)

                            # æ˜¾ç¤ºåˆ—åä¸­æ–‡åŒ–
                            display_df = display_df.rename(columns={
                                'model_name': 'æ¨¡å‹åç§°',
                                'publisher': 'å‘å¸ƒè€…',
                                'download_count': 'ä¸‹è½½é‡',
                                'model_type': 'æ¨¡å‹ç±»å‹',
                                'model_category': 'æ¨¡å‹ç³»åˆ—',
                                'base_model': 'åŸºç¡€æ¨¡å‹',
                                'data_source': 'æ•°æ®æ¥æº'
                            })

                            st.dataframe(display_df, use_container_width=True, height=400)

                            # ========== 6. å¯¼å‡ºåŠŸèƒ½ ==========
                            st.markdown("### ğŸ’¾ å¯¼å‡ºåˆ†æç»“æœ")

                            col_export1, col_export2 = st.columns([3, 1])

                            with col_export2:
                                # å¯¼å‡ºåˆ° Excel
                                output = BytesIO()
                                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                    # Sheet 1: æ€»ä½“æ¦‚è§ˆ
                                    overview_data = {
                                        'æŒ‡æ ‡': ['æ€»æ¨¡å‹æ•°', 'è¡ç”Ÿæ¨¡å‹æ•°', 'è¡ç”Ÿç‡', 'æ¨æ–­çš„base_modelæ•°'],
                                        'æ•°å€¼': [total_models, derivative_models, f"{derivative_rate:.1f}%", inferred_models]
                                    }
                                    pd.DataFrame(overview_data).to_excel(writer, sheet_name='æ€»ä½“æ¦‚è§ˆ', index=False)

                                    # Sheet 2: æ¨¡å‹ç³»åˆ—åˆ†å¸ƒ
                                    if 'model_category' in hf_df.columns:
                                        category_df.to_excel(writer, sheet_name='æ¨¡å‹ç³»åˆ—åˆ†å¸ƒ', index=False)

                                    # Sheet 3: æ¨¡å‹ç±»å‹åˆ†å¸ƒ
                                    if 'model_type' in hf_df.columns:
                                        type_df.to_excel(writer, sheet_name='æ¨¡å‹ç±»å‹åˆ†å¸ƒ', index=False)

                                    # Sheet 4: åˆ†ç»„æ±‡æ€»
                                    if group_summary_data:
                                        summary_df.to_excel(writer, sheet_name='åˆ†ç»„æ±‡æ€»', index=False)

                                    # Sheet 5: è¡ç”Ÿæ¨¡å‹è¯¦ç»†åˆ—è¡¨
                                    display_df.to_excel(writer, sheet_name='è¡ç”Ÿæ¨¡å‹åˆ—è¡¨', index=False)

                                excel_data = output.getvalue()

                                st.download_button(
                                    label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š",
                                    data=excel_data,
                                    file_name=f"è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†æ_{selected_date}.xlsx",
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    use_container_width=True
                                )
                        else:
                            st.info("è¯¥æ—¥æœŸæ²¡æœ‰è¡ç”Ÿæ¨¡å‹æ•°æ®")
