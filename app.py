"""
ERNIE æ¨¡å‹ä¸‹è½½é‡ç»Ÿè®¡ç³»ç»Ÿ
ä¸»ç•Œé¢ - ä½¿ç”¨ Streamlit æ„å»º
"""
import streamlit as st
import pandas as pd
import time
from datetime import date
import concurrent.futures
import threading
from enum import Enum
import re

from ernie_tracker.config import DB_PATH, PLATFORM_NAMES
from ernie_tracker.db import (
    save_to_db,
    get_last_model_count,
    update_last_model_count,
    load_data_from_db,
    init_database,
)
from ernie_tracker.fetchers.fetchers_unified import (
    UNIFIED_PLATFORM_FETCHERS,
    fetch_all_paddlepaddle_data,
    fetch_hugging_face_data_unified,
)
import sqlite3


# =============================================================================
# æ—¥å¿—ç³»ç»Ÿï¼ˆç¾åŒ–ç‰ˆï¼‰
# =============================================================================

class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""
    INFO = "INFO"
    SUCCESS = "SUCCESS"
    WARNING = "WARNING"
    ERROR = "ERROR"
    DEBUG = "DEBUG"


class LogEntry:
    """æ—¥å¿—æ¡ç›®ç±»"""
    def __init__(self, level: LogLevel, message: str, platform: str = None, timestamp: str = None):
        self.level = level
        self.message = message
        self.platform = platform
        self.timestamp = timestamp or time.strftime('%H:%M:%S')

    def to_html(self) -> str:
        """è½¬æ¢ä¸ºHTMLæ ¼å¼ï¼ˆå¸¦æ ·å¼ï¼‰"""
        # æ ¹æ®çº§åˆ«é€‰æ‹©é¢œè‰²å’Œå›¾æ ‡
        level_styles = {
            LogLevel.INFO: {
                'icon': 'â„¹ï¸',
                'color': '#3498db',
                'bg_color': '#ebf5fb'
            },
            LogLevel.SUCCESS: {
                'icon': 'âœ…',
                'color': '#27ae60',
                'bg_color': '#e8f8f5'
            },
            LogLevel.WARNING: {
                'icon': 'âš ï¸',
                'color': '#f39c12',
                'bg_color': '#fef5e7'
            },
            LogLevel.ERROR: {
                'icon': 'âŒ',
                'color': '#e74c3c',
                'bg_color': '#fdedec'
            },
            LogLevel.DEBUG: {
                'icon': 'ğŸ”',
                'color': '#95a5a6',
                'bg_color': '#f4f6f7'
            }
        }

        style = level_styles[self.level]

        # å¹³å°æ ‡ç­¾
        platform_tag = f'<span style="background: #667eea; color: white; padding: 2px 8px; border-radius: 4px; font-size: 0.85em; margin-left: 8px;">{self.platform}</span>' if self.platform else ''

        # æ„å»ºHTML
        html = f'''
        <div style="
            padding: 8px 12px;
            margin: 4px 0;
            background: {style['bg_color']};
            border-left: 4px solid {style['color']};
            border-radius: 4px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
        ">
            <span style="color: #7f8c8d; margin-right: 8px;">[{self.timestamp}]</span>
            <span style="color: {style['color']}; font-weight: bold; margin-right: 8px;">{style['icon']}</span>
            <span style="color: #2c3e50;">{self.message}</span>
            {platform_tag}
        </div>
        '''
        return html

    def to_text(self) -> str:
        """è½¬æ¢ä¸ºçº¯æ–‡æœ¬æ ¼å¼"""
        platform_str = f"[{self.platform}] " if self.platform else ""
        return f"[{self.timestamp}] {self.level.value} {platform_str}{self.message}"


class Logger:
    """æ—¥å¿—ç®¡ç†å™¨ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    def __init__(self, max_logs: int = 100):
        self.logs = []
        self.max_logs = max_logs
        self.lock = threading.Lock()

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            LogLevel.INFO: 0,
            LogLevel.SUCCESS: 0,
            LogLevel.WARNING: 0,
            LogLevel.ERROR: 0,
            LogLevel.DEBUG: 0
        }

    def log(self, level: LogLevel, message: str, platform: str = None):
        """æ·»åŠ æ—¥å¿—"""
        with self.lock:
            entry = LogEntry(level, message, platform)
            self.logs.append(entry)
            self.stats[level] += 1

            # ä¿ç•™æœ€è¿‘çš„æ—¥å¿—
            if len(self.logs) > self.max_logs:
                removed = self.logs.pop(0)
                self.stats[removed.level] -= 1

    def info(self, message: str, platform: str = None):
        """è®°å½•ä¿¡æ¯æ—¥å¿—"""
        self.log(LogLevel.INFO, message, platform)

    def success(self, message: str, platform: str = None):
        """è®°å½•æˆåŠŸæ—¥å¿—"""
        self.log(LogLevel.SUCCESS, message, platform)

    def warning(self, message: str, platform: str = None):
        """è®°å½•è­¦å‘Šæ—¥å¿—"""
        self.log(LogLevel.WARNING, message, platform)

    def error(self, message: str, platform: str = None):
        """è®°å½•é”™è¯¯æ—¥å¿—"""
        self.log(LogLevel.ERROR, message, platform)

    def debug(self, message: str, platform: str = None):
        """è®°å½•è°ƒè¯•æ—¥å¿—"""
        self.log(LogLevel.DEBUG, message, platform)

    def get_logs(self, level: LogLevel = None, limit: int = None) -> list:
        """è·å–æ—¥å¿—"""
        with self.lock:
            if level:
                filtered = [log for log in self.logs if log.level == level]
            else:
                filtered = self.logs.copy()

            if limit:
                return filtered[-limit:]
            return filtered

    def get_stats(self) -> dict:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        with self.lock:
            return {
                'total': len(self.logs),
                'info': self.stats[LogLevel.INFO],
                'success': self.stats[LogLevel.SUCCESS],
                'warning': self.stats[LogLevel.WARNING],
                'error': self.stats[LogLevel.ERROR],
                'debug': self.stats[LogLevel.DEBUG]
            }

    def clear(self):
        """æ¸…ç©ºæ—¥å¿—"""
        with self.lock:
            self.logs.clear()
            for level in self.stats:
                self.stats[level] = 0

    def render_html(self, level: LogLevel = None, limit: int = 50) -> str:
        """æ¸²æŸ“ä¸ºHTML"""
        logs = self.get_logs(level, limit)
        if not logs:
            return '<div style="padding: 20px; text-align: center; color: #95a5a6;">æš‚æ— æ—¥å¿—</div>'

        html_parts = []
        for entry in logs:
            html_parts.append(entry.to_html())

        return ''.join(html_parts)


# =============================================================================
# Model Tree è¾…åŠ©å‡½æ•°ï¼ˆé‡æ„ï¼šå‡å°‘ä»£ç é‡å¤ï¼‰
# =============================================================================

def get_official_model_count(repo: str) -> int:
    """
    è·å–æŒ‡å®šå¹³å°çš„å®˜æ–¹æ¨¡å‹æ€»æ•°ï¼ˆå¸¦ç¼“å­˜ï¼‰

    Args:
        repo: å¹³å°åç§°ï¼ˆå¦‚ 'AI Studio', 'ModelScope'ï¼‰

    Returns:
        int: å®˜æ–¹æ¨¡å‹æ€»æ•°ï¼Œå¦‚æœæŸ¥è¯¢å¤±è´¥åˆ™è¿”å›1
    """
    cache_key = f"official_count_{repo}"

    # ä»session_stateç¼“å­˜ä¸­è¯»å–
    if cache_key in st.session_state:
        return st.session_state[cache_key]

    try:
        with sqlite3.connect(DB_PATH) as conn:
            cursor = conn.cursor()
            cursor.execute("""
                SELECT COUNT(DISTINCT model_name)
                FROM model_downloads
                WHERE repo = ?
                AND (
                    publisher IN ('ç™¾åº¦', 'baidu', 'Paddle', 'PaddlePaddle', 'yiyan', 'ä¸€è¨€')
                    OR publisher LIKE '%ç™¾åº¦%'
                    OR publisher LIKE '%baidu%'
                    OR publisher LIKE '%Paddle%'
                )
            """, (repo,))
            count = cursor.fetchone()[0] or 1
            st.session_state[cache_key] = count
            return count
    except sqlite3.Error as e:
        st.warning(f"æŸ¥è¯¢{repo}å®˜æ–¹æ¨¡å‹æ•°é‡å¤±è´¥: {e}")
        return 1
    except Exception as e:
        st.warning(f"è·å–{repo}å®˜æ–¹æ¨¡å‹æ•°é‡æ—¶å‡ºé”™: {e}")
        return 1


def run_model_tree_with_progress(
    platform_name: str,
    fetch_func,
    save_to_db: bool = False
) -> tuple:
    """
    é€šç”¨çš„Model Treeæ‰§è¡Œå‡½æ•°ï¼ˆå¸¦è¿›åº¦æ˜¾ç¤ºï¼‰

    Args:
        platform_name: å¹³å°åç§°ï¼ˆå¦‚ 'AI Studio', 'ModelScope'ï¼‰
        fetch_func: æŠ“å–å‡½æ•°ï¼Œæ¥å—progress_callbackå‚æ•°
        save_to_db: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        tuple: (df, count, elapsed_time)
            - df: è·å–çš„DataFrameï¼ˆå¯èƒ½ä¸ºNoneï¼‰
            - count: æ¨¡å‹æ•°é‡
            - elapsed_time: è€—æ—¶ï¼ˆç§’ï¼‰
    """
    # æ£€æŸ¥æ˜¯å¦å¯ç”¨Model Tree
    if not st.session_state.get('use_model_tree', True):
        return None, 0, 0

    # åˆ›å»ºè¿›åº¦æ˜¾ç¤ºåŒºåŸŸ
    st.markdown(f"### ğŸŒ³ {platform_name} Model Tree è¿›åº¦")
    status = st.empty()
    progress = st.progress(0)
    details = st.empty()

    start_time = time.time()

    try:
        status.info(f"ğŸ”„ æ­£åœ¨è·å– {platform_name} è¡ç”Ÿæ¨¡å‹...")

        def progress_callback(processed, discovered_total=None):
            """Model Treeè¿›åº¦å›è°ƒå‡½æ•°"""
            total_official = get_official_model_count(platform_name)
            progress_pct = min(processed / total_official, 1.0) if total_official > 0 else 0
            progress.progress(progress_pct)
            details.info(f"å·²å¤„ç† {processed} / {total_official} ä¸ªå®˜æ–¹æ¨¡å‹")

        # æ‰§è¡ŒModel TreeæŠ“å–
        model_tree_df, model_tree_count = fetch_func(progress_callback=progress_callback)

        elapsed = time.time() - start_time

        # æ˜¾ç¤ºç»“æœ
        if model_tree_count > 0:
            status.success(f"âœ… {platform_name} Model Tree å®Œæˆ")
            progress.progress(1.0)
            details.success(f"è·å– {model_tree_count} ä¸ªè¡ç”Ÿæ¨¡å‹ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’")
        else:
            status.info("â„¹ï¸  æœªæ‰¾åˆ°æ–°çš„è¡ç”Ÿæ¨¡å‹")
            progress.progress(1.0)
            details.info(f"ç”¨æ—¶ {elapsed:.2f} ç§’")

        return model_tree_df, model_tree_count, elapsed

    except Exception as e:
        elapsed = time.time() - start_time
        status.error(f"âŒ Model Tree å¤±è´¥")
        st.warning(f"âš ï¸  {platform_name} Model Tree å¤±è´¥ï¼ˆä¸å½±å“ä¸»æµç¨‹ï¼‰ï¼š{e}ï¼Œç”¨æ—¶ {elapsed:.2f} ç§’")
        return None, 0, elapsed


# é¡µé¢é…ç½®
st.set_page_config(page_title="ERNIEæ¨¡å‹ä¸‹è½½æ•°æ®ç»Ÿè®¡", layout="wide")
st.title("ğŸ“Š ERNIEæ¨¡å‹ä¸‹è½½æ•°æ®ç»Ÿè®¡")


def fetch_platform_data_only(platform_name, fetch_func, save_to_database=True, log_callback=None, progress_update_callback=None):
    """
    ä»…æ‰§è¡Œæ•°æ®æŠ“å–ï¼ˆä¸åŒ…å«UIæ“ä½œï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œï¼‰

    Args:
        platform_name: å¹³å°åç§°
        fetch_func: æŠ“å–å‡½æ•°
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        log_callback: æ—¥å¿—å›è°ƒå‡½æ•°ï¼ˆç”¨äºå®æ—¶è¾“å‡ºæ—¥å¿—ï¼‰
        progress_update_callback: è¿›åº¦æ›´æ–°å›è°ƒå‡½æ•°ï¼ˆç”¨äºå®æ—¶æ›´æ–°è¿›åº¦æ¡ï¼‰

    Returns:
        tuple: (platform_name, DataFrame, success, elapsed_time, error_message, progress_updates)
    """
    # è·å–ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡
    last_count = get_last_model_count(platform_name)

    # è¿›åº¦æ›´æ–°ä¿¡æ¯åˆ—è¡¨
    progress_updates = []

    # ä¿å­˜å½“å‰å‚è€ƒæ€»æ•°ï¼ˆä½¿ç”¨å­—å…¸é¿å…é—­åŒ…é—®é¢˜ï¼‰
    ref = {"denom": last_count}

    def progress_callback(processed, discovered_total=None):
        """è¿›åº¦å›è°ƒå‡½æ•°ï¼ˆæ”¶é›†è¿›åº¦ä¿¡æ¯å¹¶è¾“å‡ºæ—¥å¿—ï¼‰"""
        if ref["denom"]:  # æœ‰å‚è€ƒæ€»æ•°
            denom = ref["denom"]
            if processed > denom:
                if save_to_database:
                    update_last_model_count(platform_name, processed)
                ref["denom"] = processed
                denom = processed

            progress = min(processed / denom, 1.0)
            message = f"å·²å¤„ç† {processed} / å‚è€ƒæ€»æ•° {denom}"
            progress_data = {
                'processed': processed,
                'total': denom,
                'progress': progress,
                'message': message
            }
            progress_updates.append(progress_data)

            # å®æ—¶è¾“å‡ºæ—¥å¿—
            if log_callback:
                log_callback(f"[{platform_name}] {message}")

            # å®æ—¶æ›´æ–°è¿›åº¦æ¡
            if progress_update_callback:
                progress_update_callback(progress_data)
        else:  # é¦–æ¬¡è¿è¡Œ
            if discovered_total:
                progress = processed / discovered_total
                message = f"å·²å¤„ç† {processed} / å®é™…æ€»æ•° {discovered_total}"
                progress_data = {
                    'processed': processed,
                    'total': discovered_total,
                    'progress': progress,
                    'message': message
                }
                progress_updates.append(progress_data)
            else:
                message = f"å·²å¤„ç† {processed} ï¼ˆæ€»æ•°æœªçŸ¥ï¼‰"
                progress_data = {
                    'processed': processed,
                    'total': None,
                    'progress': None,
                    'message': message
                }
                progress_updates.append(progress_data)

            # å®æ—¶è¾“å‡ºæ—¥å¿—
            if log_callback:
                log_callback(f"[{platform_name}] {message}")

            # å®æ—¶æ›´æ–°è¿›åº¦æ¡
            if progress_update_callback:
                progress_update_callback(progress_data)

    # æ‰§è¡Œæ•°æ®è·å–
    start_time = time.time()
    try:
        df, total_count = fetch_func(progress_callback=progress_callback, progress_total=ref["denom"])
        elapsed_time = time.time() - start_time

        # ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_database:
            if total_count is not None and total_count != ref["denom"]:
                update_last_model_count(platform_name, total_count)
            save_to_db(df, DB_PATH)
            status_message = f"âœ… å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚"
        else:
            status_message = f"âœ… å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œä»…è·å–æ•°æ®ã€‚"

        progress_updates.append({
            'status': 'completed',
            'message': status_message
        })

        return platform_name, df, True, elapsed_time, None, progress_updates

    except Exception as e:
        error_message = f"âŒ çˆ¬å–å¤±è´¥: {e}"
        progress_updates.append({
            'status': 'error',
            'message': error_message
        })
        return platform_name, None, False, time.time() - start_time, error_message, progress_updates


def run_platform_fetcher(platform_name, fetch_func, save_to_database=True, ui_container=None):
    """
    è¿è¡Œå•ä¸ªå¹³å°çš„æ•°æ®æŠ“å–ï¼ˆåŒ…å«UIæ›´æ–°ï¼Œç”¨äºä¸²è¡Œæ¨¡å¼ï¼‰

    Args:
        platform_name: å¹³å°åç§°
        fetch_func: æŠ“å–å‡½æ•°
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“
        ui_container: UIå®¹å™¨ï¼ˆå…¼å®¹å‚æ•°ï¼‰

    Returns:
        DataFrame: æŠ“å–çš„æ•°æ®
    """
    if ui_container is None:
        # å…¼å®¹åŸæœ‰çš„ç‹¬ç«‹UIæ¨¡å¼
        st.subheader(platform_name)

    # è·å–ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡
    last_count = get_last_model_count(platform_name)

    # ä¸²è¡Œæ¨¡å¼ - åŸæœ‰UIæ˜¾ç¤ºæ–¹å¼
    st.write(
        f"ä¸Šæ¬¡è®°å½•çš„æ¨¡å‹æ•°é‡ï¼š{last_count if last_count is not None else 'æš‚æ— è®°å½•ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰'}"
    )
    status_placeholder = st.empty()
    progress_bar = st.progress(0)

    # ä¿å­˜å½“å‰å‚è€ƒæ€»æ•°
    ref = {"denom": last_count}

    def progress_callback(processed, discovered_total=None):
        """è¿›åº¦å›è°ƒå‡½æ•°"""
        if ref["denom"]:  # æœ‰å‚è€ƒæ€»æ•°
            denom = ref["denom"]
            if processed > denom:
                if save_to_database:
                    update_last_model_count(platform_name, processed)
                ref["denom"] = processed
                denom = processed

            progress = min(processed / denom, 1.0)
            progress_bar.progress(progress)
            status_placeholder.text(
                f"å·²å¤„ç† {processed} / å‚è€ƒæ€»æ•° {denom}"
            )
        else:  # é¦–æ¬¡è¿è¡Œ
            if discovered_total:
                progress_bar.progress(processed / discovered_total)
                status_placeholder.text(
                    f"å·²å¤„ç† {processed} / å®é™…æ€»æ•° {discovered_total}"
                )
            else:
                status_placeholder.text(f"å·²å¤„ç† {processed} ï¼ˆæ€»æ•°æœªçŸ¥ï¼‰")

    # æ‰§è¡Œæ•°æ®è·å–
    start_time = time.time()
    try:
        df, total_count = fetch_func(progress_callback=progress_callback, progress_total=last_count)
        elapsed_time = time.time() - start_time

        # ä¿å­˜åˆ°æ•°æ®åº“
        if save_to_database:
            if total_count is not None and total_count != last_count:
                update_last_model_count(platform_name, total_count)
            save_to_db(df, DB_PATH)
            status_message = f"å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œå·²ä¿å­˜åˆ°æ•°æ®åº“ã€‚"
        else:
            status_message = f"å®Œæˆï¼šå…±å‘ç° {total_count} ä¸ªæ¨¡å‹ï¼Œä»…è·å–æ•°æ®ã€‚"

        status_placeholder.text(status_message)
        progress_bar.progress(1.0)
        return df

    except Exception as e:
        st.error(f"{platform_name} çˆ¬å–å¤±è´¥: {e}")
        return None


def run_platforms_parallel(platforms, fetchers_to_use, save_to_database=True):
    """
    å¹¶è¡Œè¿è¡Œå¤šä¸ªå¹³å°çš„æ•°æ®æŠ“å–ï¼ˆä¿®å¤ç‰ˆï¼šå®æ—¶è¿›åº¦æ˜¾ç¤ºï¼‰

    Args:
        platforms: å¹³å°åç§°åˆ—è¡¨
        fetchers_to_use: å¹³å°æŠ“å–å‡½æ•°å­—å…¸
        save_to_database: æ˜¯å¦ä¿å­˜åˆ°æ•°æ®åº“

    Returns:
        tuple: (DataFrameåˆ—è¡¨, æ€»ç”¨æ—¶)
    """
    # æ”¯æŒModel Treeçš„å¹³å°åˆ—è¡¨
    model_tree_platforms = {"AI Studio", "ModelScope"}

    all_dfs = []
    total_start_time = time.time()

    # åˆ›å»ºUIå®¹å™¨ - ä½¿ç”¨st.statusæ¥æ˜¾ç¤ºå®æ—¶è¿›åº¦
    st.markdown("### â³ å¹¶è¡Œæ›´æ–°è¿›åº¦")

    # åˆ›å»ºç¾åŒ–çš„æ—¥å¿—ç³»ç»Ÿ
    logger = Logger(max_logs=200)

    # å…±äº«çš„è¿›åº¦çŠ¶æ€ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰
    progress_state = {}
    for platform in platforms:
        progress_state[platform] = {
            'latest_update': None,
            'lock': threading.Lock()
        }
        # ä¸ºæ”¯æŒModel Treeçš„å¹³å°æ·»åŠ Model Treeè¿›åº¦çŠ¶æ€
        if platform in model_tree_platforms:
            progress_state[f"{platform}_model_tree"] = {
                'latest_update': None,
                'lock': threading.Lock()
            }

    def log_callback_wrapper(message):
        """æ—¥å¿—å›è°ƒå‡½æ•°åŒ…è£…å™¨ï¼ˆè§£ææ—¥å¿—çº§åˆ«ï¼‰"""
        # è§£ææ—¥å¿—çº§åˆ«
        level = LogLevel.INFO
        if message.startswith("âœ…") or "å®Œæˆ" in message or "æˆåŠŸ" in message:
            level = LogLevel.SUCCESS
        elif message.startswith("âŒ") or "å¤±è´¥" in message or "é”™è¯¯" in message:
            level = LogLevel.ERROR
        elif message.startswith("âš ï¸") or "è­¦å‘Š" in message:
            level = LogLevel.WARNING

        # æå–å¹³å°åç§°
        platform_match = re.match(r'\[(.*?)\]', message)
        platform = platform_match.group(1) if platform_match else None

        logger.log(level, message, platform)

    def update_progress(platform_name, progress_data):
        """çº¿ç¨‹å®‰å…¨çš„è¿›åº¦æ›´æ–°å‡½æ•°"""
        with progress_state[platform_name]['lock']:
            progress_state[platform_name]['latest_update'] = progress_data

    # åˆ›å»ºä¸€ä¸ªå ä½å®¹å™¨ç”¨äºæ˜¾ç¤ºæ‰€æœ‰å¹³å°çš„çŠ¶æ€
    status_container = st.container()

    with status_container:
        # ä¸ºæ¯ä¸ªå¹³å°åˆ›å»ºçŠ¶æ€æ˜¾ç¤ºåŒºåŸŸ
        platform_status = {}
        for platform in platforms:
            with st.expander(f"ğŸ”„ {platform}", expanded=True):
                platform_status[platform] = {
                    'status': st.empty(),
                    'progress': st.progress(0),
                    'details': st.empty(),
                    'time': st.empty()
                }
                platform_status[platform]['status'].info(f"ğŸ”„ {platform} ç­‰å¾…ä¸­...")

                # ä¸ºæ”¯æŒModel Treeçš„å¹³å°æ·»åŠ Model Treeè¿›åº¦æ˜¾ç¤º
                if platform in model_tree_platforms:
                    st.markdown("---")
                    st.markdown(f"**ğŸŒ³ {platform} Model Tree**")
                    platform_status[f"{platform}_model_tree"] = {
                        'progress': st.progress(0),
                        'details': st.empty()
                    }
                    platform_status[f"{platform}_model_tree"]['details'].info("ç­‰å¾…Searchå®Œæˆ...")

        # æ·»åŠ ç¾åŒ–åçš„æ—¥å¿—è¾“å‡ºåŒºåŸŸ
        st.markdown("---")

        # æ—¥å¿—æ§åˆ¶æ 
        log_control_col1, log_control_col2, log_control_col3 = st.columns([1, 1, 2])

        with log_control_col1:
            show_logs = st.checkbox("æ˜¾ç¤ºæ—¥å¿—", value=True)

        with log_control_col2:
            log_level_filter = st.selectbox(
                "æ—¥å¿—çº§åˆ«",
                ["å…¨éƒ¨", "INFO", "SUCCESS", "WARNING", "ERROR"],
                index=0
            )

        st.markdown("#### ğŸ“ å®æ—¶æ—¥å¿—")
        log_stats_placeholder = st.empty()
        log_placeholder = st.empty()

    def fetch_platform_task(platform_name):
        """å•ä¸ªå¹³å°æŠ“å–ä»»åŠ¡ï¼ˆçº¯æ•°æ®å¤„ç†ï¼Œä¸åŒ…å«UIæ“ä½œï¼‰"""
        try:
            fetch_func = fetchers_to_use.get(platform_name)
            if fetch_func:
                return fetch_platform_data_only(
                    platform_name,
                    fetch_func,
                    save_to_database,
                    log_callback=log_callback_wrapper,
                    progress_update_callback=lambda data: update_progress(platform_name, data)
                )
            return platform_name, None, False, 0, "æŠ“å–å‡½æ•°æœªæ‰¾åˆ°", []
        except Exception as e:
            import traceback
            error_msg = f"ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(e)}\n{traceback.format_exc()}"
            log_callback_wrapper(f"âŒ [{platform_name}] {error_msg}")
            return platform_name, None, False, 0, error_msg, []

    def fetch_model_tree_task(platform_name):
        """å•ä¸ªå¹³å°çš„Model Treeä»»åŠ¡ï¼ˆçº¯æ•°æ®å¤„ç†ï¼‰"""
        try:
            # è·å–å®˜æ–¹æ¨¡å‹æ•°é‡ä½œä¸ºå‚è€ƒæ€»æ•°
            official_count = get_official_model_count(platform_name)

            # åˆ›å»ºModel Treeè¿›åº¦å›è°ƒå‡½æ•°
            def model_tree_progress_callback(p, **kwargs):
                # å¤„ç†ä¸¤ç§ç±»å‹çš„è°ƒç”¨ï¼š
                # 1. å­—ç¬¦ä¸² - æ—¥å¿—æ¶ˆæ¯ï¼ˆæ¥è‡ª fetch_aistudio_model_tree çš„ log() å‡½æ•°ï¼‰
                # 2. æ•´æ•° - è¿›åº¦æ›´æ–°
                if isinstance(p, str):
                    # å­—ç¬¦ä¸²ï¼šä»…è¾“å‡ºæ—¥å¿—
                    log_callback_wrapper(f"[{platform_name} Model Tree] {p}")
                else:
                    # æ•´æ•°ï¼šè¾“å‡ºæ—¥å¿—å¹¶æ›´æ–°è¿›åº¦æ¡
                    log_callback_wrapper(f"[{platform_name} Model Tree] å·²å¤„ç† {p} ä¸ªå®˜æ–¹æ¨¡å‹")
                    update_progress(f"{platform_name}_model_tree", {
                        'processed': p,
                        'total': official_count,
                        'progress': min(p / official_count, 1.0) if official_count > 0 else 0,
                        'message': f"å·²å¤„ç† {p} / {official_count} ä¸ªå®˜æ–¹æ¨¡å‹"
                    })

            # æ ¹æ®å¹³å°é€‰æ‹©å¯¹åº”çš„Model Treeå‡½æ•°
            if platform_name == "AI Studio":
                from ernie_tracker.fetchers.fetchers_modeltree import fetch_aistudio_model_tree
                df, count = fetch_aistudio_model_tree(
                    progress_callback=model_tree_progress_callback,
                    save_to_db=save_to_database,
                    test_mode=False
                )
                return platform_name, df, count > 0, 0, None, []
            elif platform_name == "ModelScope":
                from ernie_tracker.fetchers.fetchers_modeltree import update_modelscope_model_tree
                df, count = update_modelscope_model_tree(
                    save_to_db=save_to_database,
                    auto_discover=True,
                    progress_callback=model_tree_progress_callback
                )
                return platform_name, df, count > 0, 0, None, []
            else:
                # ä¸æ”¯æŒModel Treeçš„å¹³å°
                return platform_name, None, False, 0, "è¯¥å¹³å°ä¸æ”¯æŒModel Tree", []
        except Exception as e:
            import traceback
            error_msg = f"Model Treeæ‰§è¡Œå¼‚å¸¸: {str(e)}\n{traceback.format_exc()}"
            return platform_name, None, False, 0, error_msg, []

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œæ‰§è¡Œ
    platforms_with_model_tree = [p for p in platforms if p in model_tree_platforms]
    platforms_without_model_tree = [p for p in platforms if p not in model_tree_platforms]

    # ç»Ÿè®¡ä»»åŠ¡æ€»æ•°ï¼ˆSearchä»»åŠ¡ + Model Treeä»»åŠ¡ï¼‰
    search_count = len(platforms)
    model_tree_count = len(platforms_with_model_tree) if st.session_state.get('use_model_tree', True) else 0
    total_tasks = search_count + model_tree_count

    with concurrent.futures.ThreadPoolExecutor(max_workers=min(len(platforms) + model_tree_count, 6)) as executor:
        # æäº¤æ‰€æœ‰Searchä»»åŠ¡
        future_to_platform = {
            executor.submit(fetch_platform_task, platform): ('search', platform)
            for platform in platforms
        }

        completed_count = 0
        search_completed_count = 0

        # æ€»ä½“è¿›åº¦æ˜¾ç¤º
        overall_placeholder = st.empty()

        # å®æ—¶æ›´æ–°å„å¹³å°çŠ¶æ€
        while completed_count < total_tasks:
            # å…ˆæ£€æŸ¥å¹¶æ›´æ–°æ‰€æœ‰å¹³å°çš„è¿›åº¦ï¼ˆåŒ…æ‹¬æœªå®Œæˆçš„ï¼‰
            for platform in platforms:
                # æ›´æ–°Searchè¿›åº¦
                with progress_state[platform]['lock']:
                    latest = progress_state[platform]['latest_update']
                    if latest and 'progress' in latest:
                        try:
                            # æ›´æ–°è¿›åº¦æ¡
                            platform_status[platform]['progress'].progress(latest['progress'])
                            # æ›´æ–°è¯¦ç»†ä¿¡æ¯
                            if latest['message']:
                                platform_status[platform]['details'].info(latest['message'])
                        except Exception as e:
                            # å¿½ç•¥UIæ›´æ–°é”™è¯¯ï¼Œé¿å…ä¸­æ–­æµç¨‹
                            pass

                # æ›´æ–°Model Treeè¿›åº¦ï¼ˆå¦‚æœæ”¯æŒï¼‰
                if platform in model_tree_platforms:
                    model_tree_key = f"{platform}_model_tree"
                    with progress_state[model_tree_key]['lock']:
                        latest_mt = progress_state[model_tree_key]['latest_update']
                        if latest_mt and 'progress' in latest_mt:
                            try:
                                # æ›´æ–°Model Treeè¿›åº¦æ¡
                                platform_status[model_tree_key]['progress'].progress(latest_mt['progress'])
                                # æ›´æ–°Model Treeè¯¦ç»†ä¿¡æ¯
                                if latest_mt['message']:
                                    platform_status[model_tree_key]['details'].info(latest_mt['message'])
                            except Exception as e:
                                # å¿½ç•¥UIæ›´æ–°é”™è¯¯
                                pass

            # æ£€æŸ¥å·²å®Œæˆçš„ä»»åŠ¡
            for future in list(future_to_platform.keys()):
                if future.done():
                    task_type, platform_name = future_to_platform.pop(future)
                    completed_count += 1

                    try:
                        # è·å–ç»“æœ
                        _, df, success, elapsed_time, error_message, progress_updates = future.result()

                        if task_type == 'search':
                            # Searchä»»åŠ¡å®Œæˆ
                            search_completed_count += 1

                            # æ›´æ–°è¯¥å¹³å°çš„SearchçŠ¶æ€
                            if success:
                                platform_status[platform_name]['status'].info(f"âœ… {platform_name} Searchå®Œæˆ")
                                final_message = progress_updates[-1]['message'] if progress_updates else "Searchå®Œæˆ"
                                platform_status[platform_name]['details'].info(final_message)
                                platform_status[platform_name]['time'].info(f"â±ï¸ Searchç”¨æ—¶: {elapsed_time:.2f} ç§’")

                                if df is not None:
                                    all_dfs.append(df)

                                # å¦‚æœè¯¥å¹³å°æ”¯æŒModel Treeä¸”ç”¨æˆ·å¯ç”¨äº†Model Treeï¼Œç«‹å³æäº¤Model Treeä»»åŠ¡
                                if platform_name in model_tree_platforms and st.session_state.get('use_model_tree', True):
                                    platform_status[platform_name]['status'].info(f"ğŸŒ³ {platform_name} å¼€å§‹Model Tree...")
                                    # æ›´æ–°Model TreeçŠ¶æ€ä¸ºè¿è¡Œä¸­
                                    model_tree_key = f"{platform_name}_model_tree"
                                    platform_status[model_tree_key]['details'].info("ğŸ”„ Model Treeè¿è¡Œä¸­...")
                                    future_to_platform[executor.submit(fetch_model_tree_task, platform_name)] = ('model_tree', platform_name)
                                    log_callback_wrapper(f"[{platform_name}] Searchå®Œæˆï¼Œå¼€å§‹Model Tree")
                                else:
                                    # ä¸æ”¯æŒModel Treeçš„å¹³å°ï¼Œæ ‡è®°ä¸ºå®Œå…¨å®Œæˆ
                                    platform_status[platform_name]['status'].success(f"âœ… {platform_name} å®Œæˆ")
                                    platform_status[platform_name]['progress'].progress(1.0)
                            else:
                                # Searchå¤±è´¥
                                platform_status[platform_name]['status'].error(f"âŒ {platform_name} Searchå¤±è´¥")
                                platform_status[platform_name]['details'].error(error_message)
                                platform_status[platform_name]['time'].error(f"â±ï¸ ç”¨æ—¶: {elapsed_time:.2f} ç§’")

                        elif task_type == 'model_tree':
                            # Model Treeä»»åŠ¡å®Œæˆ
                            model_tree_key = f"{platform_name}_model_tree"
                            if success:
                                platform_status[platform_name]['status'].success(f"âœ… {platform_name} å®Œæˆï¼ˆå«Model Treeï¼‰")
                                platform_status[model_tree_key]['details'].success("âœ… Model Treeå®Œæˆ")
                                platform_status[platform_name]['time'].success(f"â±ï¸ Model Treeç”¨æ—¶: {elapsed_time:.2f} ç§’")
                                platform_status[platform_name]['progress'].progress(1.0)
                                platform_status[model_tree_key]['progress'].progress(1.0)

                                if df is not None and not df.empty:
                                    all_dfs.append(df)
                            else:
                                # Model Treeå¤±è´¥ï¼ˆä¸å½±å“Searchçš„æˆåŠŸçŠ¶æ€ï¼‰
                                platform_status[platform_name]['status'].warning(f"âš ï¸ {platform_name} Searchå®Œæˆï¼ŒModel Treeå¤±è´¥")
                                platform_status[model_tree_key]['details'].warning(f"âŒ Model Treeå¤±è´¥: {error_message}")
                                platform_status[model_tree_key]['progress'].progress(1.0)

                    except Exception as e:
                        if task_type == 'search':
                            platform_status[platform_name]['status'].error(f"âŒ {platform_name} å¼‚å¸¸")
                            platform_status[platform_name]['details'].error(f"æ‰§è¡Œå¼‚å¸¸: {e}")
                        else:
                            platform_status[platform_name]['status'].warning(f"âš ï¸ {platform_name} Model Treeå¼‚å¸¸")
                            platform_status[platform_name]['details'].warning(f"Model Treeå¼‚å¸¸: {e}")

                    # æ›´æ–°æ€»ä½“è¿›åº¦
                    overall_placeholder.info(f"ğŸ¯ æ€»ä½“è¿›åº¦ï¼š{completed_count}/{total_tasks} ä¸ªä»»åŠ¡å®Œæˆï¼ˆSearch: {search_completed_count}/{search_count}ï¼‰")

            # æ›´æ–°ç¾åŒ–åçš„æ—¥å¿—æ˜¾ç¤º
            if show_logs:
                # æ˜¾ç¤ºæ—¥å¿—ç»Ÿè®¡
                stats = logger.get_stats()
                stats_html = f"""
                <div style="padding: 10px; background: #f8f9fa; border-radius: 8px; margin-bottom: 10px;">
                    <strong>æ—¥å¿—ç»Ÿè®¡ï¼š</strong>
                    <span style="color: #3498db;">æ€»è®¡ {stats['total']}</span> |
                    <span style="color: #3498db;">â„¹ï¸ INFO {stats['info']}</span> |
                    <span style="color: #27ae60;">âœ… SUCCESS {stats['success']}</span> |
                    <span style="color: #f39c12;">âš ï¸ WARNING {stats['warning']}</span> |
                    <span style="color: #e74c3c;">âŒ ERROR {stats['error']}</span>
                </div>
                """
                log_stats_placeholder.markdown(stats_html, unsafe_allow_html=True)

                # æ ¹æ®ç­›é€‰æ¡ä»¶æ¸²æŸ“æ—¥å¿—
                level_map = {
                    "INFO": LogLevel.INFO,
                    "SUCCESS": LogLevel.SUCCESS,
                    "WARNING": LogLevel.WARNING,
                    "ERROR": LogLevel.ERROR
                }
                filter_level = level_map.get(log_level_filter) if log_level_filter != "å…¨éƒ¨" else None

                logs_html = logger.render_html(level=filter_level, limit=100)
                log_placeholder.markdown(logs_html, unsafe_allow_html=True)

            # çŸ­æš‚ä¼‘çœ é¿å…è¿‡åº¦å ç”¨CPU
            time.sleep(0.5)

    total_elapsed_time = time.time() - total_start_time

    # ========== æœ€ç»ˆæ€»ç»“ ==========
    final_elapsed_time = time.time() - total_start_time

    # ç»Ÿè®¡Model Treeä»»åŠ¡æ•°é‡
    model_tree_tasks_count = len(platforms_with_model_tree) if st.session_state.get('use_model_tree', True) else 0

    if model_tree_tasks_count > 0:
        overall_placeholder.success(
            f"ğŸ¯ å…¨éƒ¨å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{final_elapsed_time:.2f} ç§’"
            f"ï¼ˆå®Œæˆ {search_count} ä¸ªSearchä»»åŠ¡ + {model_tree_tasks_count} ä¸ªModel Treeä»»åŠ¡ï¼‰"
        )
        logger.success(f"å…¨éƒ¨å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{final_elapsed_time:.2f} ç§’", None)
    else:
        overall_placeholder.success(f"ğŸ¯ å¹¶è¡ŒæŠ“å–å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{total_elapsed_time:.2f} ç§’")
        logger.success(f"å¹¶è¡ŒæŠ“å–å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{total_elapsed_time:.2f} ç§’", None)

    # æ˜¾ç¤ºæœ€ç»ˆæ—¥å¿—ç»Ÿè®¡
    if show_logs:
        final_stats = logger.get_stats()
        st.markdown("---")
        st.markdown("### ğŸ“Š æ—¥å¿—ç»Ÿè®¡æ‘˜è¦")

        stat_col1, stat_col2, stat_col3, stat_col4, stat_col5 = st.columns(5)
        with stat_col1:
            st.metric("æ€»æ—¥å¿—æ•°", final_stats['total'])
        with stat_col2:
            st.metric("INFO", final_stats['info'], delta_color="normal")
        with stat_col3:
            st.metric("SUCCESS", final_stats['success'], delta_color="normal")
        with stat_col4:
            st.metric("WARNING", final_stats['warning'])
        with stat_col5:
            st.metric("ERROR", final_stats['error'])

    return all_dfs, total_elapsed_time


# åˆå§‹åŒ–æ•°æ®åº“
init_database()

# ä¾§è¾¹æ å¯¼èˆª
st.sidebar.title("ğŸ”§ åŠŸèƒ½é€‰æ‹©")
page = st.sidebar.radio(
    " ",
    [
        "ğŸ“¥ æ•°æ®æ›´æ–°",
        "ğŸ“Š ERNIE-4.5 åˆ†æ",
        "ğŸ“Š PaddleOCR-VL åˆ†æ",
        "ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€",
        "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†",
    ],
    index=0,
)


# ================= æ•°æ®æ›´æ–°æ¨¡å— =================
if page == "ğŸ“¥ æ•°æ®æ›´æ–°":
    from ernie_tracker.analysis import get_available_dates
    import os
    st.markdown("## ğŸ“¥ æ•°æ®æ›´æ–°")
    st.info("ğŸš€ **ä¼˜åŒ–æ›´æ–°æ¨¡å¼**ï¼šç°åœ¨ä¸€æ¬¡æ›´æ–°å³å¯è·å–æ‰€æœ‰PaddlePaddleæ¨¡å‹æ•°æ®ï¼ˆåŒ…å«ERNIE-4.5å’ŒPaddleOCR-VLï¼‰ï¼Œæ— éœ€åˆ†åˆ«é€‰æ‹©ï¼")

    # Model Tree é€‰é¡¹
    use_model_tree = st.checkbox(
        "ğŸŒ³ ä½¿ç”¨ Model Tree åŠŸèƒ½ï¼ˆè·å–è¡ç”Ÿæ¨¡å‹ï¼‰",
        value=True,
        key='use_model_tree',
        help="å¯ç”¨åä¼šè·å–ERNIE-4.5å’ŒPaddleOCR-VLçš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼ŒåŒ…æ‹¬Finetuneã€Adapterç­‰"
    )

    if use_model_tree:
        st.info("ğŸ” **Model Treeæ¨¡å¼**ï¼šå°†è·å–ERNIE-4.5å’ŒPaddleOCR-VLçš„æ‰€æœ‰è¡ç”Ÿæ¨¡å‹ï¼Œå¹¶è‡ªåŠ¨åˆ†ç±»è¯†åˆ«Finetuneã€Adapterã€LoRAç­‰ç±»å‹")

    # ä½¿ç”¨ç»Ÿä¸€çš„å¹³å°æŠ“å–å™¨
    fetchers_to_use = UNIFIED_PLATFORM_FETCHERS.copy()

    # æ ¹æ®Model Treeé€‰é¡¹æ›´æ–°Hugging Faceè·å–å™¨
    fetchers_to_use["Hugging Face"] = lambda **kwargs: fetch_hugging_face_data_unified(
        progress_callback=kwargs.get('progress_callback'),
        progress_total=kwargs.get('progress_total'),
        use_model_tree=use_model_tree  # ä¼ é€’ç”¨æˆ·çš„é€‰æ‹©
    )

    platform_options = list(fetchers_to_use.keys())

    # åˆå§‹åŒ– session_state
    if "select_all" not in st.session_state:
        st.session_state.select_all = False

    # å¹³å°é€‰æ‹©
    with st.container():
        toolbar_col1, toolbar_col2, toolbar_col3 = st.columns([1, 5, 1])

        with toolbar_col1:
            if st.button("âœ… å…¨é€‰ / å–æ¶ˆ"):
                st.session_state.select_all = not st.session_state.select_all

        with toolbar_col2:
            platforms = st.multiselect(
                "é€‰æ‹©éœ€è¦æ›´æ–°çš„å¹³å°",
                platform_options,
                default=platform_options if st.session_state.select_all else [],
                label_visibility="collapsed"
            )

        with toolbar_col3:
            run_all = st.button("ğŸš€ æ›´æ–°æ•°æ®", use_container_width=True)

    # æ•°æ®ä¿å­˜é€‰é¡¹
    st.markdown("### âš™ï¸ æ•°æ®ä¿å­˜è®¾ç½®")
    save_to_db_option = st.radio(
        "é€‰æ‹©æ•°æ®å¤„ç†æ–¹å¼ï¼š",
        options=["ä¿å­˜åˆ°æ•°æ®åº“", "ä»…è·å–æ•°æ®ï¼ˆä¸ä¿å­˜ï¼‰"],
        index=0,
        horizontal=True,
        help="é€‰æ‹©æ˜¯å¦å°†çˆ¬å–çš„æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ä¸­"
    )

    save_to_database = (save_to_db_option == "ä¿å­˜åˆ°æ•°æ®åº“")

    if save_to_database:
        st.info("ğŸ’¾ æ•°æ®å°†ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå¹¶æ›´æ–°å¹³å°ç»Ÿè®¡ä¿¡æ¯")
    else:
        st.warning("âš ï¸ æ•°æ®ä»…ç”¨äºé¢„è§ˆï¼Œä¸ä¼šä¿å­˜åˆ°æ•°æ®åº“")

    # æ‰§è¡Œæ¨¡å¼é€‰æ‹©
    st.markdown("### ğŸš€ æ‰§è¡Œæ¨¡å¼")
    execution_mode = st.radio(
        "é€‰æ‹©æ‰§è¡Œæ¨¡å¼ï¼š",
        options=["ğŸš€ å¹¶è¡Œæ‰§è¡Œï¼ˆæ¨èï¼‰", "ğŸ”„ ä¸²è¡Œæ‰§è¡Œ"],
        index=0,
        horizontal=True,
        help="å¹¶è¡Œæ‰§è¡Œå¯ä»¥å¤§å¹…æå‡å¤šå¹³å°æŠ“å–æ•ˆç‡"
    )

    use_parallel = (execution_mode == "ğŸš€ å¹¶è¡Œæ‰§è¡Œï¼ˆæ¨èï¼‰")

    if use_parallel:
        st.info("âš¡ å„å¹³å°å°†åŒæ—¶è¿›è¡Œæ•°æ®æŠ“å–ï¼Œå¤§å¹…æå‡æ•ˆç‡")
    else:
        st.warning("ğŸŒ å„å¹³å°å°†ä¾æ¬¡è¿›è¡Œæ•°æ®æŠ“å–ï¼Œè€—æ—¶è¾ƒé•¿")

    st.markdown("---")

    # æ‰§è¡Œæ›´æ–°
    if run_all:
        if not platforms:
            st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå¹³å°å†æ›´æ–°ã€‚")
        else:
            all_dfs = []
            total_elapsed_time = 0
            total_start_time = time.time()  # åˆå§‹åŒ–æ€»å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—æœ€ç»ˆç”¨æ—¶ï¼‰

            if use_parallel:
                # å¹¶è¡Œæ‰§è¡Œæ¨¡å¼
                all_dfs, total_elapsed_time = run_platforms_parallel(
                    platforms, fetchers_to_use, save_to_database
                )
            else:
                # ä¸²è¡Œæ‰§è¡Œæ¨¡å¼ï¼ˆæ”¹è¿›é€»è¾‘ï¼šæ¯ä¸ªå¹³å°Searchå®Œæˆåç«‹å³æ‰§è¡ŒModel Treeï¼‰
                st.markdown("### â³ ä¸²è¡Œæ›´æ–°è¿›åº¦")
                progress_placeholder = st.empty()

                # æ”¯æŒModel Treeçš„å¹³å°
                model_tree_platforms = {"AI Studio", "ModelScope"}

                for idx, platform in enumerate(platforms, start=1):
                    progress_placeholder.info(f"æ­£åœ¨æ›´æ–°ï¼š**{platform}** ({idx}/{len(platforms)})")

                    # æ­¥éª¤1: è°ƒç”¨å¹³å°SearchæŠ“å–å‡½æ•°
                    fetch_func = fetchers_to_use.get(platform)
                    if fetch_func:
                        df = run_platform_fetcher(platform, fetch_func, save_to_database)
                        if df is not None:
                            all_dfs.append(df)

                        elapsed = time.time() - total_start_time
                        status_msg = "æ•°æ®å·²ä¿å­˜" if save_to_database else "ä»…é¢„è§ˆ"
                        st.success(f"âœ… {platform} Searchå®Œæˆï¼Œç”¨æ—¶ {elapsed:.2f} ç§’ï¼Œ{status_msg}")

                        # æ­¥éª¤2: å¦‚æœè¯¥å¹³å°æ”¯æŒModel Treeä¸”ç”¨æˆ·å¯ç”¨äº†Model Treeï¼Œç«‹å³æ‰§è¡Œ
                        if platform in model_tree_platforms and st.session_state.get('use_model_tree', True):
                            st.info(f"ğŸŒ³ å¼€å§‹æ‰§è¡Œ {platform} Model Tree...")

                            if platform == "AI Studio":
                                from ernie_tracker.fetchers.fetchers_modeltree import fetch_aistudio_model_tree
                                df_mt, count_mt, elapsed_mt = run_model_tree_with_progress(
                                    "AI Studio",
                                    lambda progress_callback: fetch_aistudio_model_tree(
                                        progress_callback=progress_callback,
                                        save_to_db=save_to_database,
                                        test_mode=False
                                    ),
                                    save_to_db=False
                                )
                            elif platform == "ModelScope":
                                from ernie_tracker.fetchers.fetchers_modeltree import update_modelscope_model_tree
                                df_mt, count_mt, elapsed_mt = run_model_tree_with_progress(
                                    "ModelScope",
                                    lambda progress_callback: update_modelscope_model_tree(
                                        save_to_db=save_to_database,
                                        auto_discover=True,
                                        progress_callback=progress_callback
                                    ),
                                    save_to_db=False
                                )

                            if df_mt is not None and not df_mt.empty:
                                all_dfs.append(df_mt)

                            total_elapsed = time.time() - total_start_time
                            st.success(f"âœ… {platform} Model Treeå®Œæˆï¼Œæ€»ç”¨æ—¶ {total_elapsed:.2f} ç§’")

                total_elapsed_time = time.time() - total_start_time
                st.info(f"ğŸ¯ ä¸²è¡ŒæŠ“å–å®Œæˆï¼æ€»ç”¨æ—¶ï¼š{total_elapsed_time:.2f} ç§’")

            # æ•°æ®é¢„è§ˆ
            st.markdown("### ğŸ“„ æœ¬æ¬¡æ›´æ–°æ•°æ®é¢„è§ˆ")
            if all_dfs:
                final_df = pd.concat(all_dfs, ignore_index=True)
                st.dataframe(final_df, use_container_width=True)

                # ä¸‹è½½æŒ‰é’®
                csv_data = final_df.to_csv(index=False).encode("utf-8-sig")
                download_label = "â¬‡ï¸ ä¸‹è½½æœ¬æ¬¡æ›´æ–°æ•°æ® (CSV)" if save_to_database else "â¬‡ï¸ ä¸‹è½½è·å–çš„æ•°æ® (CSV)"

                st.download_button(
                    label=download_label,
                    data=csv_data,
                    file_name=f"paddlepaddle_models_downloads_{date.today().isoformat()}.csv",
                    mime="text/csv",
                    use_container_width=False
                )

    # å¯¼å‡ºæŒ‡å®šæ—¥æœŸæ•°æ®
    st.markdown("### ğŸ“ å¯¼å‡ºæŒ‡å®šæ—¥æœŸæ•°æ®åˆ°æœ¬åœ°")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates_export = get_available_dates()

    if not available_dates_export:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®å¯ä¾›å¯¼å‡ºã€‚")
    else:
        selected_date = st.selectbox(
            "é€‰æ‹©è¦å¯¼å‡ºçš„æ—¥æœŸ",
            options=available_dates_export,
            index=0,
            key="export_date_selector",
            help="é€‰æ‹©ä¸€ä¸ªæ—¥æœŸï¼Œå°†å…¶æ•°æ®å¯¼å‡ºä¸º Excel æ–‡ä»¶åˆ° Data æ–‡ä»¶å¤¹"
        )

        if st.button("ğŸ’¾ å¯¼å‡ºåˆ° Data æ–‡ä»¶å¤¹"):
            with st.spinner(f"æ­£åœ¨å¯¼å‡º {selected_date} çš„æ•°æ®..."):
                df_export = load_data_from_db(date_filter=selected_date)
                
                if df_export.empty:
                    st.error(f"âŒ æœªæ‰¾åˆ° {selected_date} çš„æ•°æ®ã€‚")
                else:
                    output_dir = "Data"
                    os.makedirs(output_dir, exist_ok=True)
                    output_path = os.path.join(output_dir, f"data_{selected_date}.xlsx")
                    
                    try:
                        # ä¿å­˜åˆ° Excel
                        df_export.to_excel(output_path, index=False, engine='openpyxl')
                        st.success(f"âœ… æ•°æ®æˆåŠŸå¯¼å‡ºåˆ°: `{output_path}`")
                        st.info(f"å…±å¯¼å‡º {len(df_export)} æ¡è®°å½•ã€‚")
                    except Exception as e:
                        st.error(f"å¯¼å‡ºæ–‡ä»¶æ—¶å‡ºé”™: {e}")


# ================= ERNIE-4.5 æ•°æ®åˆ†ææ¨¡å— =================
elif page == "ğŸ“Š ERNIE-4.5 åˆ†æ":
    from ernie_tracker.analysis import calculate_weekly_report, format_report_tables, get_available_dates, get_last_friday
    from datetime import datetime

    st.markdown("## ğŸ“ˆ å‘¨æŠ¥åˆ†æ")
    st.markdown("åˆ†æå½“å‰æ—¥æœŸä¸å¯¹æ¯”æ—¥æœŸä¹‹é—´çš„ä¸‹è½½é‡å¢é•¿æƒ…å†µ")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # æ—¥æœŸé€‰æ‹©
        col1, col2 = st.columns(2)

        with col1:
            current_date = st.selectbox(
                "ğŸ“… å½“å‰æ—¥æœŸ",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„å½“å‰æ—¥æœŸ"
            )

        with col2:
            # é»˜è®¤ä¸ºä¸Šå‘¨äº”
            default_previous = get_last_friday(current_date)
            if default_previous in available_dates:
                default_index = available_dates.index(default_previous)
            else:
                default_index = min(1, len(available_dates) - 1)

            previous_date = st.selectbox(
                "ğŸ“… å¯¹æ¯”æ—¥æœŸ",
                options=available_dates,
                index=default_index,
                help="é€‰æ‹©è¦å¯¹æ¯”çš„æ—¥æœŸï¼ˆé€šå¸¸ä¸ºä¸Šå‘¨äº”ï¼‰"
            )

        if st.button("ğŸ” ç”Ÿæˆå‘¨æŠ¥", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                report_data = calculate_weekly_report(current_date, previous_date, model_series='ERNIE-4.5')

            if report_data is None:
                st.error("âŒ æ— æ³•ç”Ÿæˆå‘¨æŠ¥ï¼Œè¯·æ£€æŸ¥é€‰æ‹©çš„æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®ã€‚")
            else:
                # ä¿å­˜åˆ°session_state
                st.session_state['report_data_ernie'] = report_data
                st.session_state['current_date'] = current_date
                st.session_state['previous_date'] = previous_date
                st.rerun()

        # æ˜¾ç¤ºå‘¨æŠ¥ç»“æœï¼ˆä»session_stateæˆ–æ–°ç”Ÿæˆçš„ï¼‰
        report_data = st.session_state.get('report_data_ernie')

        if report_data is not None:
            tables = format_report_tables(report_data)

            # è·å–ä¿å­˜çš„æ—¥æœŸ
            saved_current_date = st.session_state.get('current_date', current_date)
            saved_previous_date = st.session_state.get('previous_date', previous_date)

            st.success(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å¯¹æ¯”æ—¶é—´æ®µï¼š{saved_previous_date} â†’ {saved_current_date}")

            # æ£€æŸ¥å¹¶æ˜¾ç¤ºè´Ÿå¢é•¿è­¦å‘Š
            warnings_df = tables.get('negative_growth_warnings')
            if warnings_df is not None and not warnings_df.empty:
                st.markdown("### âš ï¸ è´Ÿå¢é•¿è­¦å‘Š")
                st.error(f"æ£€æµ‹åˆ° {len(warnings_df)} ä¸ªæ¨¡å‹å‡ºç°è´Ÿå¢é•¿ï¼è¿™å¯èƒ½è¡¨ç¤ºæ•°æ®é‡‡é›†é—®é¢˜æˆ–æ¨¡å‹è¢«ä¸‹æ¶ã€‚")
                st.dataframe(warnings_df, use_container_width=True)

                # ä¿å­˜warnings_dfåˆ°session_state
                st.session_state['warnings_df'] = warnings_df

                # æ·»åŠ é‡æ–°è·å–æŒ‰é’®
                with st.expander("ğŸ”„ é‡æ–°è·å–è´Ÿå¢é•¿æ¨¡å‹ä¸‹è½½é‡", expanded=False):
                    st.info("ğŸ’¡ æ­¤åŠŸèƒ½å°†é‡æ–°ä»å¹³å°APIè·å–è¿™äº›æ¨¡å‹çš„æœ€æ–°ä¸‹è½½é‡å¹¶æ›´æ–°åˆ°æ•°æ®åº“ã€‚ç›®å‰æ”¯æŒ Hugging Face å’Œ ModelScope å¹³å°ã€‚")

                    if st.button("ğŸš€ å¼€å§‹é‡æ–°è·å–", type="primary", key="refetch_ernie"):
                        # ç›´æ¥åœ¨æŒ‰é’®å›è°ƒä¸­æ‰§è¡Œï¼Œä¸è¦rerun
                        if 'warnings_df' in st.session_state:
                            warnings_data = st.session_state['warnings_df']

                            # è½¬æ¢warnings_dfä¸ºè´Ÿå¢é•¿æ¨¡å‹åˆ—è¡¨
                            negative_list = []
                            for idx, row in warnings_data.iterrows():
                                negative_list.append({
                                    'platform': row['å¹³å°'],
                                    'model_name': row['æ¨¡å‹åç§°'],
                                    'publisher': row['å‘å¸ƒè€…'],
                                    'current': row['æœ¬å‘¨ä¸‹è½½é‡']
                                })

                            # è·å–current_dateï¼Œç”¨äºä¿å­˜æ•°æ®
                            target_date = st.session_state.get('current_date', date.today().isoformat())

                            st.write(f"ğŸ”„ å‡†å¤‡é‡æ–°è·å– {len(negative_list)} ä¸ªæ¨¡å‹ï¼Œå°†ä¿å­˜åˆ°æ—¥æœŸ: {target_date}")

                            # æ‰§è¡Œé‡æ–°è·å–
                            try:
                                from ernie_tracker.fetchers.fetchers_single_model import refetch_models_batch
                                from ernie_tracker.db import save_to_db

                                with st.spinner("æ­£åœ¨é‡æ–°è·å–æ¨¡å‹ä¸‹è½½é‡..."):
                                    success_list, failed_list = refetch_models_batch(negative_list, target_date=target_date)

                                # ç›´æ¥ä¿å­˜æˆåŠŸçš„æ•°æ®åˆ°æ•°æ®åº“
                                if success_list:
                                    saved_count = 0
                                    for item in success_list:
                                        record = item['record']
                                        try:
                                            save_to_db(pd.DataFrame([record]), DB_PATH)
                                            saved_count += 1
                                        except Exception as e:
                                            st.error(f"âŒ ä¿å­˜ {item['model_name']} å¤±è´¥: {e}")
                                    st.success(f"âœ… æˆåŠŸé‡æ–°è·å–å¹¶ä¿å­˜ {saved_count} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼")

                                # æ˜¾ç¤ºç»“æœ
                                st.markdown("#### ğŸ“Š é‡æ–°è·å–ç»“æœ")

                                if success_list:
                                    st.info(f"âœ… æˆåŠŸé‡æ–°è·å– {len(success_list)} ä¸ªæ¨¡å‹")
                                    success_df = pd.DataFrame(success_list)[['platform', 'model_name', 'old_count', 'new_count', 'change']]
                                    success_df.columns = ['å¹³å°', 'æ¨¡å‹åç§°', 'åŸä¸‹è½½é‡', 'æ–°ä¸‹è½½é‡', 'å˜åŒ–']
                                    st.dataframe(success_df, use_container_width=True)

                                if failed_list:
                                    st.warning(f"âš ï¸ {len(failed_list)} ä¸ªæ¨¡å‹è·å–å¤±è´¥")
                                    failed_df = pd.DataFrame(failed_list)[['platform', 'model_name', 'publisher']]
                                    failed_df.columns = ['å¹³å°', 'æ¨¡å‹åç§°', 'å‘å¸ƒè€…']
                                    st.dataframe(failed_df, use_container_width=True)

                                # åˆ·æ–°é¡µé¢ä»¥æ˜¾ç¤ºæ›´æ–°åçš„æ•°æ®
                                st.rerun()

                            except Exception as e:
                                st.error(f"âŒ é‡æ–°è·å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
                                import traceback
                                st.error(traceback.format_exc())
                        else:
                            st.error("âŒ æœªæ‰¾åˆ° warnings_dfï¼Œè¯·é‡æ–°ç”Ÿæˆå‘¨æŠ¥")

                st.markdown("---")

            # æ˜¾ç¤ºæ€»ä½“æƒ…å†µæ‘˜è¦
            st.markdown("### ğŸ“ æ€»ä½“æƒ…å†µæ‘˜è¦")
            stats = report_data['summary_stats']

            # æ ¼å¼åŒ–æ•°å­—
            def format_num(n):
                return f"{n/10000:.2f}ä¸‡"

            def format_percent(p):
                return f"{p:.2%}"

            # è®¡ç®—ç™¾åˆ†æ¯”
            official_total_percent = stats['official_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
            derivative_total_percent = stats['derivative_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
            official_growth_percent = stats['official_growth'] / stats['all_growth'] if stats['all_growth'] else 0
            derivative_growth_percent = stats['derivative_growth'] / stats['all_growth'] if stats['all_growth'] else 0

            summary_text = f"""
            æˆªè‡³ **{saved_current_date}**ï¼Œæ¨¡å‹ç´¯è®¡ä¸‹è½½ **{format_num(stats['all_current_total'])}** æ¬¡
            ï¼ˆå«å®˜æ–¹æ¨¡å‹ **{format_num(stats['official_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_total_percent)}**ï¼Œ
            è¡ç”Ÿ **{format_num(stats['derivative_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_total_percent)}**ï¼‰ï¼Œ
            è¾ƒä¸Šå‘¨å¢é•¿ **{format_num(stats['all_growth'])}** æ¬¡
            ï¼ˆå®˜æ–¹æ¨¡å‹ **{format_num(stats['official_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_growth_percent)}**ï¼Œ
            è¡ç”Ÿæ¨¡å‹å¢é•¿ **{format_num(stats['derivative_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_growth_percent)}**ï¼‰ã€‚
            """
            st.markdown(summary_text)

            # ç´¯è®¡/æœ¬å‘¨æ–°å¢è¡ç”Ÿæ¨¡å‹æ•°é‡
            new_models_list_count = len(tables.get('all_new_models', pd.DataFrame()))
            st.info(
                f"ç´¯è®¡è¡ç”Ÿæ¨¡å‹ï¼š{int(stats.get('derivative_current_total_models', 0) or 0)} ä¸ªï½œ"
                f"æœ¬å‘¨æ–°å¢è¡ç”Ÿï¼ˆHFéå®˜æ–¹å·®é›†ï¼‰ï¼š{int(stats.get('derivative_new_models', 0) or 0)} ä¸ªï½œ"
                f"æ–°å¢åˆ—è¡¨å±•ç¤ºï¼š{new_models_list_count} ä¸ª"
            )

            # ç¤¾åŒºå’Œæ¨¡å‹ç»´åº¦æ‘˜è¦
            st.markdown("### ğŸ“ˆ ç¤¾åŒºä¸æ¨¡å‹ç»´åº¦æ‘˜è¦")
            community_summary = report_data['community_summary']

            # ç¤¾åŒºç»´åº¦
            community_text = f"""
            - **ç¤¾åŒºç»´åº¦**ï¼šHugging Faceä¸‹è½½é‡æœ€é«˜ï¼Œ**{community_summary['hf_top_model_name']}** ä¸ºæœ¬å‘¨HFå¹³å°ä¸‹è½½æœ€é«˜æ¨¡å‹ï¼Œå¢é•¿ **{community_summary['hf_top_model_growth']/10000:.2f}ä¸‡** æ¬¡ã€‚
            """
            st.markdown(community_text)

            # æ¨¡å‹ç»´åº¦
            top3_downloads_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_downloads_details'].items()])
            top3_growth_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_growth_details'].items()])

            model_text = f"""
            - **æ¨¡å‹ç»´åº¦**ï¼š
                - æ¨¡å‹ï¼ˆå®˜æ–¹ï¼‰ä¸‹è½½æ€»é‡å‰ä¸‰ä½ï¼š{top3_downloads_str}
                - æœ¬å‘¨ï¼ˆå®˜æ–¹ï¼‰å¢é•¿æœ€å¿«å‰ä¸‰ä½ï¼š{top3_growth_str}
            """
            st.markdown(model_text)

            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            st.markdown("### ğŸ“Š å¹³å°æ±‡æ€»")
            st.dataframe(tables['platform_summary'], use_container_width=True)

            # Topæ¦œå•
            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### ğŸ† Top 5 å¢é•¿æœ€é«˜çš„æ¨¡å‹")
                st.dataframe(tables['top5_growth'], use_container_width=True)

            with col2:
                st.markdown("### ğŸ¥‡ Top 3 æ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹")
                st.dataframe(tables['top3_downloads'], use_container_width=True)

            # å„å¹³å°æ¦œé¦–
            st.markdown("### ğŸ¯ å„å¹³å°æ¦œé¦–æ¨¡å‹")
            st.dataframe(
                tables['platform_top_models'],
                use_container_width=True,
                column_config={
                    "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                        "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                        "å¢é•¿æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "å¢é•¿æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæœ¬å‘¨å¢é•¿é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                    }
                )

                # è¯¦ç»†æ•°æ®è¡¨æ ¼
            st.markdown("### ğŸ“‹ å„å¹³å°æ¨¡å‹ä¸‹è½½é‡è¯¦æƒ… (æ€»/å‘¨å¢)")
            st.dataframe(tables['combined_downloads_growth'], use_container_width=True)

            # æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹å±•ç¤º
            st.markdown("### ğŸŒŸ æœ¬å‘¨æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹")

            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            summary = tables.get('new_models_summary', 'æ— æ–°å¢æ¨¡å‹ä¿¡æ¯')
            st.info(f"ğŸ“Š {summary}")

            # åˆ†åˆ—æ˜¾ç¤ºä¸åŒç±»å‹çš„æ–°å¢æ¨¡å‹
            col1, col2, col3 = st.columns(3)

            with col1:
                st.markdown("#### ğŸ”§ æ–°å¢Finetuneæ¨¡å‹")
                finetune_df = tables.get('new_finetune_models')
                if finetune_df is not None and not finetune_df.empty:
                    st.dataframe(finetune_df, use_container_width=True)
                else:
                    st.info("æœ¬å‘¨æ— æ–°å¢Finetuneæ¨¡å‹")

            with col2:
                st.markdown("#### ğŸ”Œ æ–°å¢Adapteræ¨¡å‹")
                adapter_df = tables.get('new_adapter_models')
                if adapter_df is not None and not adapter_df.empty:
                    st.dataframe(adapter_df, use_container_width=True)
                else:
                    st.info("æœ¬å‘¨æ— æ–°å¢Adapteræ¨¡å‹")

            with col3:
                st.markdown("#### ğŸ¯ æ–°å¢LoRAæ¨¡å‹")
                lora_df = tables.get('new_lora_models')
                if lora_df is not None and not lora_df.empty:
                    st.dataframe(lora_df, use_container_width=True)
                else:
                    st.info("æœ¬å‘¨æ— æ–°å¢LoRAæ¨¡å‹")

            # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
            st.markdown("### ğŸ“‹ æœ¬å‘¨æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨")

            # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
            all_new_summary = tables.get('all_new_models_summary', 'æ— æ–°å¢æ¨¡å‹')
            st.info(f"ğŸ“Š {all_new_summary}")

            # æ˜¾ç¤ºæ‰€æœ‰æ–°å¢æ¨¡å‹è¡¨æ ¼
            all_new_df = tables.get('all_new_models')
            if all_new_df is not None and not all_new_df.empty:
                st.dataframe(all_new_df, use_container_width=True, height=400)
            else:
                st.info("æœ¬å‘¨æ²¡æœ‰æ–°å¢ERNIE-4.5æ¨¡å‹")

            # ğŸ†• å·²åˆ é™¤/éšè—çš„æ¨¡å‹åˆ—è¡¨
            st.markdown("### ğŸ—‘ï¸ å·²åˆ é™¤/éšè—çš„è¡ç”Ÿæ¨¡å‹")
            st.info("ğŸ“Œ è¿™äº›æ¨¡å‹åœ¨å†å²è®°å½•ä¸­å­˜åœ¨ï¼Œä½†åœ¨å½“å‰æ—¥æœŸå·²ä¸å¯è§ï¼ˆå¯èƒ½è¢«åˆ é™¤æˆ–éšè—ï¼‰")

            from ernie_tracker.analysis import get_deleted_or_hidden_models
            deleted_models = get_deleted_or_hidden_models(current_date, model_series='ERNIE-4.5')

            if deleted_models:
                deleted_df = pd.DataFrame(deleted_models)
                deleted_df.index = deleted_df.index + 1

                # é‡å‘½ååˆ—
                column_mapping = {
                    'model_name': 'æ¨¡å‹åç§°',
                    'publisher': 'å‘å¸ƒè€…',
                    'repo': 'å¹³å°',
                    'model_type': 'æ¨¡å‹ç±»å‹',
                    'base_model': 'åŸºç¡€æ¨¡å‹',
                    'last_seen_date': 'æœ€åå‡ºç°æ—¥æœŸ',
                    'last_download_count': 'æœ€åä¸‹è½½é‡'
                }
                deleted_df = deleted_df.rename(columns={k: v for k, v in column_mapping.items() if k in deleted_df.columns})

                st.warning(f"âš ï¸ å‘ç° {len(deleted_models)} ä¸ªæ¨¡å‹å·²è¢«åˆ é™¤æˆ–éšè—")
                st.dataframe(deleted_df, use_container_width=True, height=400)
            else:
                st.success("âœ… æ‰€æœ‰å†å²æ¨¡å‹åœ¨å½“å‰æ—¥æœŸä»ç„¶å¯è§")

            # å¯¼å‡ºåŠŸèƒ½
            st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥è¡¨")

            # åˆå¹¶æ‰€æœ‰è¡¨æ ¼ä¸ºä¸€ä¸ªExcel
            from io import BytesIO

            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                tables['platform_summary'].to_excel(writer, sheet_name='å¹³å°æ±‡æ€»')
                tables['top5_growth'].to_excel(writer, sheet_name='Top5å¢é•¿')
                tables['top3_downloads'].to_excel(writer, sheet_name='Top3ä¸‹è½½é‡')
                tables['platform_top_models'].to_excel(writer, sheet_name='å„å¹³å°æ¦œé¦–', index=False)
                tables['combined_downloads_growth'].to_excel(writer, sheet_name='ä¸‹è½½é‡è¯¦æƒ…')
                # æ–°å¢æ¨¡å‹è¡¨æ ¼
                if not tables.get('new_finetune_models', pd.DataFrame()).empty:
                    tables['new_finetune_models'].to_excel(writer, sheet_name='æ–°å¢Finetuneæ¨¡å‹')
                if not tables.get('new_adapter_models', pd.DataFrame()).empty:
                    tables['new_adapter_models'].to_excel(writer, sheet_name='æ–°å¢Adapteræ¨¡å‹')
                if not tables.get('new_lora_models', pd.DataFrame()).empty:
                    tables['new_lora_models'].to_excel(writer, sheet_name='æ–°å¢LoRAæ¨¡å‹')
                # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                if not tables.get('all_new_models', pd.DataFrame()).empty:
                    tables['all_new_models'].to_excel(writer, sheet_name='æ‰€æœ‰æ–°å¢æ¨¡å‹')

            excel_data = output.getvalue()

            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´å‘¨æŠ¥ (Excel)",
                data=excel_data,
                file_name=f"ERNIE-4.5_å‘¨æŠ¥_{previous_date}_to_{current_date}.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )

# ================= PaddleOCR-VL æ•°æ®åˆ†ææ¨¡å— =================
elif page == "ğŸ“Š PaddleOCR-VL åˆ†æ":
    from ernie_tracker.analysis import calculate_paddleocr_vl_weekly_report, format_report_tables, get_available_dates, get_last_friday
    from datetime import datetime

    st.markdown("## ğŸ“ˆ PaddleOCR-VL å‘¨æŠ¥åˆ†æ")
    st.markdown("åˆ†æå½“å‰æ—¥æœŸä¸å¯¹æ¯”æ—¥æœŸä¹‹é—´çš„ä¸‹è½½é‡å¢é•¿æƒ…å†µ")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # æ—¥æœŸé€‰æ‹©
        col1, col2 = st.columns(2)

        with col1:
            current_date = st.selectbox(
                "ğŸ“… å½“å‰æ—¥æœŸ (PaddleOCR-VL)",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„å½“å‰æ—¥æœŸ"
            )

        with col2:
            # é»˜è®¤ä¸ºä¸Šå‘¨äº”
            default_previous = get_last_friday(current_date)
            if default_previous in available_dates:
                default_index = available_dates.index(default_previous)
            else:
                default_index = min(1, len(available_dates) - 1)

            previous_date = st.selectbox(
                "ğŸ“… å¯¹æ¯”æ—¥æœŸ (PaddleOCR-VL)",
                options=available_dates,
                index=default_index,
                help="é€‰æ‹©è¦å¯¹æ¯”çš„æ—¥æœŸï¼ˆé€šå¸¸ä¸ºä¸Šå‘¨äº”ï¼‰"
            )

        if st.button("ğŸ” ç”Ÿæˆ PaddleOCR-VL å‘¨æŠ¥", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†ææ•°æ®..."):
                report_data = calculate_paddleocr_vl_weekly_report(current_date, previous_date)

            if report_data is None:
                st.error("âŒ æ— æ³•ç”Ÿæˆå‘¨æŠ¥ï¼Œè¯·æ£€æŸ¥é€‰æ‹©çš„æ—¥æœŸæ˜¯å¦æœ‰æ•°æ®ã€‚")
            else:
                tables = format_report_tables(report_data)

                st.success(f"âœ… å‘¨æŠ¥ç”ŸæˆæˆåŠŸï¼å¯¹æ¯”æ—¶é—´æ®µï¼š{previous_date} â†’ {current_date}")

                # ä¿å­˜å…³é”®æ•°æ®åˆ°session_stateï¼Œç”¨äºé‡æ–°è·å–åŠŸèƒ½
                st.session_state['current_date'] = current_date
                st.session_state['previous_date'] = previous_date

                # æ£€æŸ¥å¹¶æ˜¾ç¤ºè´Ÿå¢é•¿è­¦å‘Š
                warnings_df = tables.get('negative_growth_warnings')
                if warnings_df is not None and not warnings_df.empty:
                    st.markdown("### âš ï¸ è´Ÿå¢é•¿è­¦å‘Š")
                    st.error(f"æ£€æµ‹åˆ° {len(warnings_df)} ä¸ªæ¨¡å‹å‡ºç°è´Ÿå¢é•¿ï¼è¿™å¯èƒ½è¡¨ç¤ºæ•°æ®é‡‡é›†é—®é¢˜æˆ–æ¨¡å‹è¢«ä¸‹æ¶ã€‚")
                    st.dataframe(warnings_df, use_container_width=True)

                    # ä¿å­˜warnings_dfåˆ°session_state
                    st.session_state['warnings_df'] = warnings_df

                    # æ·»åŠ é‡æ–°è·å–æŒ‰é’®
                    with st.expander("ğŸ”„ é‡æ–°è·å–è´Ÿå¢é•¿æ¨¡å‹ä¸‹è½½é‡", expanded=False):
                        st.info("ğŸ’¡ æ­¤åŠŸèƒ½å°†é‡æ–°ä»å¹³å°APIè·å–è¿™äº›æ¨¡å‹çš„æœ€æ–°ä¸‹è½½é‡å¹¶æ›´æ–°åˆ°æ•°æ®åº“ã€‚ç›®å‰æ”¯æŒ Hugging Face å’Œ ModelScope å¹³å°ã€‚")

                        if st.button("ğŸš€ å¼€å§‹é‡æ–°è·å–", type="primary", key="refetch_ernie"):
                            # ä»session_stateè·å–warnings_df
                            if 'warnings_df' in st.session_state:
                                warnings_data = st.session_state['warnings_df']

                                # è½¬æ¢warnings_dfä¸ºè´Ÿå¢é•¿æ¨¡å‹åˆ—è¡¨
                                negative_list = []
                                for idx, row in warnings_data.iterrows():
                                    negative_list.append({
                                        'platform': row['å¹³å°'],
                                        'model_name': row['æ¨¡å‹åç§°'],
                                        'publisher': row['å‘å¸ƒè€…'],
                                        'current': row['æœ¬å‘¨ä¸‹è½½é‡']
                                    })

                                # æ‰§è¡Œé‡æ–°è·å–
                                with st.spinner("æ­£åœ¨é‡æ–°è·å–æ¨¡å‹ä¸‹è½½é‡..."):
                                    from ernie_tracker.fetchers.fetchers_single_model import refetch_models_batch
                                    from ernie_tracker.db import save_to_db

                                    success_list, failed_list, unsupported_list = refetch_models_batch(negative_list)

                                    # ä¿å­˜ç»“æœåˆ°session_state
                                    st.session_state['refetch_success'] = success_list
                                    st.session_state['refetch_failed'] = failed_list
                                    st.session_state['refetch_unsupported'] = unsupported_list
                                    st.session_state['refetch_done'] = True

                                    # é‡æ–°è¿è¡Œé¡µé¢ä»¥æ˜¾ç¤ºç»“æœ
                                    st.rerun()

                    # æ˜¾ç¤ºé‡æ–°è·å–ç»“æœï¼ˆå¦‚æœå·²æ‰§è¡Œï¼‰
                    if st.session_state.get('refetch_done', False):
                        st.markdown("#### ğŸ“Š é‡æ–°è·å–ç»“æœ")

                        success_list = st.session_state.get('refetch_success', [])
                        failed_list = st.session_state.get('refetch_failed', [])
                        unsupported_list = st.session_state.get('refetch_unsupported', [])

                        if success_list:
                            st.success(f"âœ… æˆåŠŸé‡æ–°è·å– {len(success_list)} ä¸ªæ¨¡å‹")
                            success_df = pd.DataFrame(success_list)[['platform', 'model_name', 'old_count', 'new_count', 'change']]
                            success_df.columns = ['å¹³å°', 'æ¨¡å‹åç§°', 'åŸä¸‹è½½é‡', 'æ–°ä¸‹è½½é‡', 'å˜åŒ–']
                            st.dataframe(success_df, use_container_width=True)

                            # ä¿å­˜åˆ°æ•°æ®åº“
                            if st.button("ğŸ’¾ ä¿å­˜æ›´æ–°åˆ°æ•°æ®åº“", key="save_ernie"):
                                saved_count = 0
                                for item in success_list:
                                    record = item['record']
                                    try:
                                        save_to_db(pd.DataFrame([record]), DB_PATH, DATA_TABLE)
                                        saved_count += 1
                                    except Exception as e:
                                        st.error(f"ä¿å­˜ {item['model_name']} å¤±è´¥: {e}")
                                st.success(f"âœ… å·²ä¿å­˜ {saved_count} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼")
                                # æ¸…é™¤session_state
                                st.session_state['refetch_done'] = False
                                st.rerun()

                        if failed_list:
                            st.warning(f"âš ï¸ {len(failed_list)} ä¸ªæ¨¡å‹è·å–å¤±è´¥")
                            failed_df = pd.DataFrame(failed_list)[['platform', 'model_name', 'publisher']]
                            failed_df.columns = ['å¹³å°', 'æ¨¡å‹åç§°', 'å‘å¸ƒè€…']
                            st.dataframe(failed_df, use_container_width=True)

                        if unsupported_list:
                            st.info(f"â„¹ï¸ {len(unsupported_list)} ä¸ªæ¨¡å‹çš„å¹³å°æš‚ä¸æ”¯æŒè‡ªåŠ¨é‡æ–°è·å–")
                            unsupported_df = pd.DataFrame(unsupported_list)[['platform', 'model_name', 'publisher']]
                            unsupported_df.columns = ['å¹³å°', 'æ¨¡å‹åç§°', 'å‘å¸ƒè€…']
                            st.dataframe(unsupported_df, use_container_width=True)

                            # æ˜¾ç¤ºæ‰‹åŠ¨æ£€æŸ¥å»ºè®®
                            st.markdown("#### ğŸ” æ‰‹åŠ¨æ£€æŸ¥å»ºè®®")
                            for item in unsupported_list:
                                repo = item['platform']
                                model_name = item['model_name']
                                publisher = item['publisher']

                                url = None
                                if repo == "AI Studio":
                                    # AI Studioæ¨¡å‹URLéœ€è¦æ ¹æ®å®é™…æƒ…å†µæ„é€ 
                                    url = f"https://aistudio.baidu.com/modeldetail/{model_name}"
                                elif repo == "GitCode":
                                    from ernie_tracker.config import GITCODE_MODEL_LINKS
                                    for link in GITCODE_MODEL_LINKS:
                                        if model_name in link:
                                            url = link
                                            break

                                if url:
                                    st.markdown(f"- **{repo} | {model_name}**: [æ‰“å¼€æ¨¡å‹é¡µé¢]({url})")

                        # æ¸…é™¤æŒ‰é’®
                        if st.button("ğŸ—‘ï¸ æ¸…é™¤ç»“æœ", key="clear_ernie"):
                            st.session_state['refetch_done'] = False
                            st.rerun()

                    st.markdown("---")

                # æ˜¾ç¤ºæ€»ä½“æƒ…å†µæ‘˜è¦
                st.markdown("### ğŸ“ æ€»ä½“æƒ…å†µæ‘˜è¦")
                stats = report_data['summary_stats']
                
                # æ ¼å¼åŒ–æ•°å­—
                def format_num(n):
                    return f"{n/10000:.2f}ä¸‡"

                def format_percent(p):
                    return f"{p:.2%}"

                # è®¡ç®—ç™¾åˆ†æ¯”
                official_total_percent = stats['official_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                derivative_total_percent = stats['derivative_current_total'] / stats['all_current_total'] if stats['all_current_total'] else 0
                official_growth_percent = stats['official_growth'] / stats['all_growth'] if stats['all_growth'] else 0
                derivative_growth_percent = stats['derivative_growth'] / stats['all_growth'] if stats['all_growth'] else 0

                summary_text = f"""
                æˆªè‡³ **{current_date}**ï¼Œæ¨¡å‹ç´¯è®¡ä¸‹è½½ **{format_num(stats['all_current_total'])}** æ¬¡
                ï¼ˆå«å®˜æ–¹æ¨¡å‹ **{format_num(stats['official_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_total_percent)}**ï¼Œ
                è¡ç”Ÿ **{format_num(stats['derivative_current_total'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_total_percent)}**ï¼‰ï¼Œ
                è¾ƒä¸Šå‘¨å¢é•¿ **{format_num(stats['all_growth'])}** æ¬¡
                ï¼ˆå®˜æ–¹æ¨¡å‹ **{format_num(stats['official_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(official_growth_percent)}**ï¼Œ
                è¡ç”Ÿæ¨¡å‹å¢é•¿ **{format_num(stats['derivative_growth'])}** æ¬¡ï¼Œå æ¯” **{format_percent(derivative_growth_percent)}**ï¼‰ã€‚
                """
                st.markdown(summary_text)

                # ç´¯è®¡/æœ¬å‘¨æ–°å¢è¡ç”Ÿæ¨¡å‹æ•°é‡
                new_models_list_count = len(tables.get('all_new_models', pd.DataFrame()))
                st.info(
                    f"ç´¯è®¡è¡ç”Ÿæ¨¡å‹ï¼š{int(stats.get('derivative_current_total_models', 0) or 0)} ä¸ªï½œ"
                    f"æœ¬å‘¨æ–°å¢è¡ç”Ÿï¼ˆHFéå®˜æ–¹å·®é›†ï¼‰ï¼š{int(stats.get('derivative_new_models', 0) or 0)} ä¸ªï½œ"
                    f"æ–°å¢åˆ—è¡¨å±•ç¤ºï¼š{new_models_list_count} ä¸ª"
                )

                # ç¤¾åŒºå’Œæ¨¡å‹ç»´åº¦æ‘˜è¦
                st.markdown("### ğŸ“ˆ ç¤¾åŒºä¸æ¨¡å‹ç»´åº¦æ‘˜è¦")
                community_summary = report_data['community_summary']
                
                # ç¤¾åŒºç»´åº¦
                community_text = f"""
                - **ç¤¾åŒºç»´åº¦**ï¼šHugging Faceä¸‹è½½é‡æœ€é«˜ï¼Œ**{community_summary['hf_top_model_name']}** ä¸ºæœ¬å‘¨HFå¹³å°ä¸‹è½½æœ€é«˜æ¨¡å‹ï¼Œå¢é•¿ **{community_summary['hf_top_model_growth']/10000:.2f}ä¸‡** æ¬¡ã€‚
                """
                st.markdown(community_text)

                # æ¨¡å‹ç»´åº¦
                top3_downloads_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_downloads_details'].items()])
                top3_growth_str = " > ".join([f"{name}({int(val)})" for name, val in community_summary['top3_growth_details'].items()])
                
                model_text = f"""
                - **æ¨¡å‹ç»´åº¦**ï¼š
                    - æ¨¡å‹ï¼ˆå®˜æ–¹ï¼‰ä¸‹è½½æ€»é‡å‰ä¸‰ä½ï¼š{top3_downloads_str}
                    - æœ¬å‘¨ï¼ˆå®˜æ–¹ï¼‰å¢é•¿æœ€å¿«å‰ä¸‰ä½ï¼š{top3_growth_str}
                """
                st.markdown(model_text)

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                st.markdown("### ğŸ“Š å¹³å°æ±‡æ€»")
                st.dataframe(tables['platform_summary'], use_container_width=True)

                # Topæ¦œå•
                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("### ğŸ† Top 5 å¢é•¿æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top5_growth'], use_container_width=True)

                with col2:
                    st.markdown("### ğŸ¥‡ Top 3 æ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹")
                    st.dataframe(tables['top3_downloads'], use_container_width=True)

                # å„å¹³å°æ¦œé¦–
                st.markdown("### ğŸ¯ å„å¹³å°æ¦œé¦–æ¨¡å‹")
                st.dataframe(
                    tables['platform_top_models'],
                    use_container_width=True,
                    column_config={
                        "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "ä¸‹è½½é‡æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæ€»ä¸‹è½½é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                        "å¢é•¿æœ€é«˜æ¨¡å‹": st.column_config.TextColumn(
                            "å¢é•¿æœ€é«˜æ¨¡å‹",
                            help="å„å¹³å°å®˜æ–¹/è¡ç”Ÿæ¨¡å‹ä¸­ï¼Œæœ¬å‘¨å¢é•¿é‡æœ€é«˜çš„æ¨¡å‹",
                            width="large",
                        ),
                    }
                )

                # è¯¦ç»†æ•°æ®è¡¨æ ¼
                st.markdown("### ğŸ“‹ å„å¹³å°æ¨¡å‹ä¸‹è½½é‡è¯¦æƒ… (æ€»/å‘¨å¢)")
                st.dataframe(tables['combined_downloads_growth'], use_container_width=True)

                # ğŸ”§ æ–°å¢ï¼šPaddleOCR-VL çš„ Finetune å’Œ Adapter æ¨¡å‹å±•ç¤º
                st.markdown("### ğŸŒŸ æœ¬å‘¨æ–°å¢Finetuneå’ŒAdapteræ¨¡å‹")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                summary = tables.get('new_models_summary', 'æ— æ–°å¢æ¨¡å‹ä¿¡æ¯')
                st.info(f"ğŸ“Š {summary}")

                # åˆ†åˆ—æ˜¾ç¤ºä¸åŒç±»å‹çš„æ–°å¢æ¨¡å‹
                col1, col2, col3 = st.columns(3)

                with col1:
                    st.markdown("#### ğŸ”§ æ–°å¢Finetuneæ¨¡å‹")
                    finetune_df = tables.get('new_finetune_models')
                    if finetune_df is not None and not finetune_df.empty:
                        st.dataframe(finetune_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Finetuneæ¨¡å‹")

                with col2:
                    st.markdown("#### ğŸ”Œ æ–°å¢Adapteræ¨¡å‹")
                    adapter_df = tables.get('new_adapter_models')
                    if adapter_df is not None and not adapter_df.empty:
                        st.dataframe(adapter_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢Adapteræ¨¡å‹")

                with col3:
                    st.markdown("#### ğŸ¯ æ–°å¢LoRAæ¨¡å‹")
                    lora_df = tables.get('new_lora_models')
                    if lora_df is not None and not lora_df.empty:
                        st.dataframe(lora_df, use_container_width=True)
                    else:
                        st.info("æœ¬å‘¨æ— æ–°å¢LoRAæ¨¡å‹")

                # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                st.markdown("### ğŸ“‹ æœ¬å‘¨æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨")

                # æ˜¾ç¤ºæ±‡æ€»ä¿¡æ¯
                all_new_summary = tables.get('all_new_models_summary', 'æ— æ–°å¢æ¨¡å‹')
                st.info(f"ğŸ“Š {all_new_summary}")

                # æ˜¾ç¤ºæ‰€æœ‰æ–°å¢æ¨¡å‹è¡¨æ ¼
                all_new_df = tables.get('all_new_models')
                if all_new_df is not None and not all_new_df.empty:
                    st.dataframe(all_new_df, use_container_width=True, height=400)
                else:
                    st.info("æœ¬å‘¨æ²¡æœ‰æ–°å¢PaddleOCR-VLæ¨¡å‹")

                # ğŸ†• å·²åˆ é™¤/éšè—çš„æ¨¡å‹åˆ—è¡¨
                st.markdown("### ğŸ—‘ï¸ å·²åˆ é™¤/éšè—çš„è¡ç”Ÿæ¨¡å‹")
                st.info("ğŸ“Œ è¿™äº›æ¨¡å‹åœ¨å†å²è®°å½•ä¸­å­˜åœ¨ï¼Œä½†åœ¨å½“å‰æ—¥æœŸå·²ä¸å¯è§ï¼ˆå¯èƒ½è¢«åˆ é™¤æˆ–éšè—ï¼‰")

                from ernie_tracker.analysis import get_deleted_or_hidden_models
                deleted_models = get_deleted_or_hidden_models(current_date, model_series='PaddleOCR-VL')

                if deleted_models:
                    deleted_df = pd.DataFrame(deleted_models)
                    deleted_df.index = deleted_df.index + 1

                    # é‡å‘½ååˆ—
                    column_mapping = {
                        'model_name': 'æ¨¡å‹åç§°',
                        'publisher': 'å‘å¸ƒè€…',
                        'repo': 'å¹³å°',
                        'model_type': 'æ¨¡å‹ç±»å‹',
                        'base_model': 'åŸºç¡€æ¨¡å‹',
                        'last_seen_date': 'æœ€åå‡ºç°æ—¥æœŸ',
                        'last_download_count': 'æœ€åä¸‹è½½é‡'
                    }
                    deleted_df = deleted_df.rename(columns={k: v for k, v in column_mapping.items() if k in deleted_df.columns})

                    st.warning(f"âš ï¸ å‘ç° {len(deleted_models)} ä¸ªæ¨¡å‹å·²è¢«åˆ é™¤æˆ–éšè—")
                    st.dataframe(deleted_df, use_container_width=True, height=400)
                else:
                    st.success("âœ… æ‰€æœ‰å†å²æ¨¡å‹åœ¨å½“å‰æ—¥æœŸä»ç„¶å¯è§")

                # å¯¼å‡ºåŠŸèƒ½
                st.markdown("### ğŸ’¾ å¯¼å‡ºæŠ¥è¡¨")

                # åˆå¹¶æ‰€æœ‰è¡¨æ ¼ä¸ºä¸€ä¸ªExcel
                from io import BytesIO

                output = BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    tables['platform_summary'].to_excel(writer, sheet_name='å¹³å°æ±‡æ€»')
                    tables['top5_growth'].to_excel(writer, sheet_name='Top5å¢é•¿')
                    tables['top3_downloads'].to_excel(writer, sheet_name='Top3ä¸‹è½½é‡')
                    tables['platform_top_models'].to_excel(writer, sheet_name='å„å¹³å°æ¦œé¦–', index=False)
                    tables['combined_downloads_growth'].to_excel(writer, sheet_name='ä¸‹è½½é‡è¯¦æƒ…')
                    # ğŸ”§ æ–°å¢ï¼šå¯¼å‡ºæ–°å¢æ¨¡å‹è¡¨æ ¼
                    if not tables.get('new_finetune_models', pd.DataFrame()).empty:
                        tables['new_finetune_models'].to_excel(writer, sheet_name='æ–°å¢Finetuneæ¨¡å‹')
                    if not tables.get('new_adapter_models', pd.DataFrame()).empty:
                        tables['new_adapter_models'].to_excel(writer, sheet_name='æ–°å¢Adapteræ¨¡å‹')
                    if not tables.get('new_lora_models', pd.DataFrame()).empty:
                        tables['new_lora_models'].to_excel(writer, sheet_name='æ–°å¢LoRAæ¨¡å‹')
                    if not tables.get('new_model_tree_models', pd.DataFrame()).empty:
                        tables['new_model_tree_models'].to_excel(writer, sheet_name='ModelTreeæ–°å¢æ¨¡å‹')
                    # ğŸ†• æ‰€æœ‰æ–°å¢æ¨¡å‹å®Œæ•´åˆ—è¡¨
                    if not tables.get('all_new_models', pd.DataFrame()).empty:
                        tables['all_new_models'].to_excel(writer, sheet_name='æ‰€æœ‰æ–°å¢æ¨¡å‹')

                excel_data = output.getvalue()

        st.download_button(
            label="ğŸ“¥ ä¸‹è½½ PaddleOCR-VL å®Œæ•´å‘¨æŠ¥ (Excel)",
            data=excel_data,
            file_name=f"PaddleOCR-VL_å‘¨æŠ¥_{previous_date}_to_{current_date}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ================= æ•°æ®åº“ç®¡ç†æ¨¡å— =================
elif page == "ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†":
    from ernie_tracker.db_manager import (
        backup_database, restore_database, delete_data_by_date,
        delete_data_by_platform, get_database_stats, get_available_backups,
        delete_backup, vacuum_database, export_database_to_excel,
        get_duplicate_records, remove_duplicate_records, insert_single_record,
        import_from_excel
    )
    from ernie_tracker.analysis import get_available_dates
    from io import BytesIO
    import os

    st.markdown("## ğŸ—„ï¸ æ•°æ®åº“ç®¡ç†")
    st.info("ğŸ’¡ æä¾›æ•°æ®åº“å¤‡ä»½ã€æ¢å¤ã€åˆ é™¤ã€ä¼˜åŒ–ç­‰ç®¡ç†åŠŸèƒ½")

    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "ğŸ“Š æ•°æ®åº“æ¦‚è§ˆ",
        "ğŸ’¾ å¤‡ä»½ä¸æ¢å¤",
        "ğŸ—‘ï¸ æ•°æ®åˆ é™¤",
        "ğŸ”§ æ•°æ®ç»´æŠ¤",
        "ğŸ“¤ æ•°æ®å¯¼å‡º",
        "ğŸ“ æ•°æ®å½•å…¥",
        "âœï¸ æ•°æ®ç¼–è¾‘"
    ])
    
    # ========== Tab 1: æ•°æ®åº“æ¦‚è§ˆ ==========
    with tab1:
        st.markdown("### ğŸ“Š æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
        
        if st.button("ğŸ”„ åˆ·æ–°ç»Ÿè®¡", key="refresh_stats"):
            st.rerun()
        
        stats = get_database_stats()
        
        if 'error' in stats:
            st.error(f"è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {stats['error']}")
        else:
            # æ˜¾ç¤ºå…³é”®æŒ‡æ ‡
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.metric("æ€»è®°å½•æ•°", f"{stats['total_records']:,}")
            
            with col2:
                st.metric("æ•°æ®åº“å¤§å°", f"{stats['db_size_mb']} MB")
            
            with col3:
                st.metric("æœ€æ—©æ—¥æœŸ", stats['min_date'] or "æ— æ•°æ®")
            
            with col4:
                st.metric("æœ€æ–°æ—¥æœŸ", stats['max_date'] or "æ— æ•°æ®")
            
            st.markdown("---")
            
            # æŒ‰æ—¥æœŸç»Ÿè®¡
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("#### ğŸ“… æŒ‰æ—¥æœŸç»Ÿè®¡")
                if not stats['date_stats'].empty:
                    st.dataframe(
                        stats['date_stats'].rename(columns={'date': 'æ—¥æœŸ', 'count': 'è®°å½•æ•°'}),
                        use_container_width=True,
                        height=300
                    )
                else:
                    st.info("æš‚æ— æ•°æ®")
            
            with col2:
                st.markdown("#### ğŸŒ æŒ‰å¹³å°ç»Ÿè®¡")
                if not stats['platform_stats'].empty:
                    st.dataframe(
                        stats['platform_stats'].rename(columns={'repo': 'å¹³å°', 'count': 'è®°å½•æ•°'}),
                        use_container_width=True,
                        height=300
                    )
                else:
                    st.info("æš‚æ— æ•°æ®")
    
    # ========== Tab 2: å¤‡ä»½ä¸æ¢å¤ ==========
    with tab2:
        st.markdown("### ğŸ’¾ æ•°æ®åº“å¤‡ä»½")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            backup_dir = st.text_input(
                "å¤‡ä»½ç›®å½•",
                value="backups",
                help="æ•°æ®åº“å¤‡ä»½æ–‡ä»¶å°†ä¿å­˜åˆ°è¿™ä¸ªç›®å½•"
            )
        
        with col2:
            st.write("")
            st.write("")
            if st.button("ğŸ“¦ ç«‹å³å¤‡ä»½", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨å¤‡ä»½æ•°æ®åº“..."):
                    success, result = backup_database(backup_dir)
                
                if success:
                    st.success(f"âœ… å¤‡ä»½æˆåŠŸï¼\næ–‡ä»¶è·¯å¾„: `{result}`")
                else:
                    st.error(f"âŒ å¤‡ä»½å¤±è´¥: {result}")
        
        st.markdown("---")
        st.markdown("### ğŸ“‚ å·²æœ‰å¤‡ä»½")
        
        backups = get_available_backups(backup_dir)
        
        if not backups:
            st.info("æš‚æ— å¤‡ä»½æ–‡ä»¶")
        else:
            st.write(f"å…±æ‰¾åˆ° **{len(backups)}** ä¸ªå¤‡ä»½æ–‡ä»¶:")
            
            for backup in backups:
                with st.expander(f"ğŸ“ {backup['filename']}", expanded=False):
                    col1, col2, col3 = st.columns([2, 1, 1])
                    
                    with col1:
                        st.write(f"**åˆ›å»ºæ—¶é—´**: {backup['created_time']}")
                        st.write(f"**æ–‡ä»¶å¤§å°**: {backup['size_mb']} MB")
                        st.write(f"**æ–‡ä»¶è·¯å¾„**: `{backup['filepath']}`")
                    
                    with col2:
                        if st.button("ğŸ”„ æ¢å¤æ­¤å¤‡ä»½", key=f"restore_{backup['filename']}"):
                            if st.session_state.get(f"confirm_restore_{backup['filename']}", False):
                                with st.spinner("æ­£åœ¨æ¢å¤æ•°æ®åº“..."):
                                    success, message = restore_database(backup['filepath'])
                                
                                if success:
                                    st.success(f"âœ… {message}")
                                    st.rerun()
                                else:
                                    st.error(f"âŒ æ¢å¤å¤±è´¥: {message}")
                                
                                st.session_state[f"confirm_restore_{backup['filename']}"] = False
                            else:
                                st.warning("âš ï¸ è¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤æ¢å¤")
                                st.session_state[f"confirm_restore_{backup['filename']}"] = True
                    
                    with col3:
                        if st.button("ğŸ—‘ï¸ åˆ é™¤å¤‡ä»½", key=f"delete_{backup['filename']}"):
                            success, message = delete_backup(backup['filepath'])
                            if success:
                                st.success(message)
                                st.rerun()
                            else:
                                st.error(f"åˆ é™¤å¤±è´¥: {message}")
    
    # ========== Tab 3: æ•°æ®åˆ é™¤ ==========
    with tab3:
        st.markdown("### ğŸ—‘ï¸ æ•°æ®åˆ é™¤")
        st.warning("âš ï¸ **è­¦å‘Š**: åˆ é™¤æ“ä½œä¸å¯é€†ï¼Œå»ºè®®å…ˆå¤‡ä»½æ•°æ®åº“ï¼")
        
        # åˆ é™¤æŒ‡å®šæ—¥æœŸçš„æ•°æ®
        st.markdown("#### ğŸ—“ï¸ æŒ‰æ—¥æœŸåˆ é™¤")
        
        available_dates = get_available_dates()
        
        if not available_dates:
            st.info("æ•°æ®åº“ä¸­æš‚æ— æ•°æ®")
        else:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                delete_date = st.selectbox(
                    "é€‰æ‹©è¦åˆ é™¤çš„æ—¥æœŸ",
                    options=available_dates,
                    key="delete_date_selector"
                )
            
            with col2:
                st.write("")
                st.write("")
                if st.button("ğŸ—‘ï¸ åˆ é™¤è¯¥æ—¥æœŸæ•°æ®", key="delete_by_date", use_container_width=True):
                    if st.session_state.get("confirm_delete_date", False):
                        with st.spinner(f"æ­£åœ¨åˆ é™¤ {delete_date} çš„æ•°æ®..."):
                            success, message, count = delete_data_by_date(delete_date)
                        
                        if success:
                            st.success(f"âœ… {message}")
                            st.rerun()
                        else:
                            st.error(f"âŒ åˆ é™¤å¤±è´¥: {message}")
                        
                        st.session_state["confirm_delete_date"] = False
                    else:
                        st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤ {delete_date} çš„æ‰€æœ‰æ•°æ®ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                        st.session_state["confirm_delete_date"] = True
        
        st.markdown("---")
        
        # åˆ é™¤æŒ‡å®šå¹³å°çš„æ•°æ®
        st.markdown("#### ğŸŒ æŒ‰å¹³å°åˆ é™¤")
        
        col1, col2, col3 = st.columns([2, 2, 1])
        
        with col1:
            delete_platform = st.selectbox(
                "é€‰æ‹©å¹³å°",
                options=list(PLATFORM_NAMES.values()),
                key="delete_platform_selector"
            )
        
        with col2:
            delete_platform_date = st.selectbox(
                "é€‰æ‹©æ—¥æœŸï¼ˆå¯é€‰ï¼‰",
                options=["å…¨éƒ¨æ—¥æœŸ"] + (available_dates if available_dates else []),
                key="delete_platform_date_selector"
            )
        
        with col3:
            st.write("")
            st.write("")
            if st.button("ğŸ—‘ï¸ åˆ é™¤å¹³å°æ•°æ®", key="delete_by_platform", use_container_width=True):
                if st.session_state.get("confirm_delete_platform", False):
                    target_date = None if delete_platform_date == "å…¨éƒ¨æ—¥æœŸ" else delete_platform_date
                    
                    with st.spinner(f"æ­£åœ¨åˆ é™¤ {delete_platform} çš„æ•°æ®..."):
                        success, message, count = delete_data_by_platform(delete_platform, target_date)
                    
                    if success:
                        st.success(f"âœ… {message}")
                        st.rerun()
                    else:
                        st.error(f"âŒ åˆ é™¤å¤±è´¥: {message}")
                    
                    st.session_state["confirm_delete_platform"] = False
                else:
                    date_info = f" ({delete_platform_date})" if delete_platform_date != "å…¨éƒ¨æ—¥æœŸ" else ""
                    st.warning(f"âš ï¸ ç¡®è®¤åˆ é™¤ {delete_platform}{date_info} çš„æ•°æ®ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                    st.session_state["confirm_delete_platform"] = True
    
    # ========== Tab 4: æ•°æ®ç»´æŠ¤ ==========
    with tab4:
        st.markdown("### ğŸ”§ æ•°æ®ç»´æŠ¤")
        
        # æ£€æŸ¥é‡å¤è®°å½•
        st.markdown("#### ğŸ” é‡å¤è®°å½•æ£€æµ‹")

        col1, col2 = st.columns([3, 1])

        with col1:
            st.write("æ£€æŸ¥å¹¶æ¸…ç†æ•°æ®åº“ä¸­çš„é‡å¤è®°å½•ï¼ˆç›¸åŒçš„æ—¥æœŸã€å¹³å°ã€å‘å¸ƒè€…ã€æ¨¡å‹åç§°ï¼‰")

        with col2:
            if st.button("ğŸ” æ£€æŸ¥é‡å¤è®°å½•", key="check_duplicates", use_container_width=True):
                with st.spinner("æ­£åœ¨æ£€æŸ¥é‡å¤è®°å½•..."):
                    duplicates = get_duplicate_records()

                if duplicates.empty:
                    st.success("âœ… æ²¡æœ‰å‘ç°é‡å¤è®°å½•")
                else:
                    total_duplicates = duplicates['count'].sum() - len(duplicates)
                    st.session_state['duplicates_found'] = duplicates
                    st.session_state['duplicate_count'] = total_duplicates
                    st.rerun()

        # æ˜¾ç¤ºæ£€æŸ¥ç»“æœ
        if 'duplicates_found' in st.session_state and not st.session_state['duplicates_found'].empty:
            duplicates = st.session_state['duplicates_found']
            total_duplicates = st.session_state['duplicate_count']

            st.warning(f"âš ï¸ å‘ç° {len(duplicates)} ç»„é‡å¤è®°å½•ï¼Œå…± {total_duplicates} æ¡é‡å¤æ•°æ®éœ€è¦æ¸…ç†")
            st.dataframe(
                duplicates.rename(columns={
                    'date': 'æ—¥æœŸ',
                    'repo': 'å¹³å°',
                    'publisher': 'å‘å¸ƒè€…',
                    'model_name': 'æ¨¡å‹åç§°',
                    'count': 'é‡å¤æ¬¡æ•°'
                }),
                use_container_width=True
            )

            col1, col2 = st.columns([3, 1])
            with col2:
                if st.button("ğŸ§¹ æ¸…é™¤é‡å¤è®°å½•", key="remove_duplicates", type="primary", use_container_width=True):
                    with st.spinner("æ­£åœ¨æ¸…é™¤é‡å¤è®°å½•..."):
                        success, message, count = remove_duplicate_records()

                    if success:
                        st.success(f"âœ… {message}")
                        # æ¸…é™¤session state
                        if 'duplicates_found' in st.session_state:
                            del st.session_state['duplicates_found']
                        if 'duplicate_count' in st.session_state:
                            del st.session_state['duplicate_count']
                        st.rerun()
                    else:
                        st.error(f"âŒ æ¸…é™¤å¤±è´¥: {message}")
        
        st.markdown("---")
        
        # æ•°æ®åº“ä¼˜åŒ–
        st.markdown("#### âš¡ æ•°æ®åº“ä¼˜åŒ–")
        st.info("æ•°æ®åº“ä¼˜åŒ–ï¼ˆVACUUMï¼‰å¯ä»¥å›æ”¶åˆ é™¤æ•°æ®åçš„ç©ºé—´ï¼Œå‡å°æ•°æ®åº“æ–‡ä»¶å¤§å°")
        
        if st.button("âš¡ ä¼˜åŒ–æ•°æ®åº“", key="vacuum_db"):
            with st.spinner("æ­£åœ¨ä¼˜åŒ–æ•°æ®åº“..."):
                success, message = vacuum_database()
            
            if success:
                st.success(f"âœ… {message}")
                st.rerun()
            else:
                st.error(f"âŒ ä¼˜åŒ–å¤±è´¥: {message}")
    
    # ========== Tab 5: æ•°æ®å¯¼å‡º ==========
    with tab5:
        st.markdown("### ğŸ“¤ æ•°æ®å¯¼å‡º")
        
        col1, col2 = st.columns([2, 1])
        
        with col1:
            export_date = st.selectbox(
                "é€‰æ‹©å¯¼å‡ºæ—¥æœŸ",
                options=["å…¨éƒ¨æ—¥æœŸ"] + (available_dates if available_dates else []),
                key="export_date_selector"
            )
        
        with col2:
            export_filename = st.text_input(
                "æ–‡ä»¶å",
                value=f"database_export_{date.today().isoformat()}.xlsx",
                key="export_filename"
            )
        
        if st.button("ğŸ“¥ å¯¼å‡ºåˆ° Excel", type="primary", key="export_excel"):
            output_path = os.path.join("exports", export_filename)
            os.makedirs("exports", exist_ok=True)
            
            target_date = None if export_date == "å…¨éƒ¨æ—¥æœŸ" else export_date
            
            with st.spinner("æ­£åœ¨å¯¼å‡ºæ•°æ®..."):
                success, message = export_database_to_excel(output_path, target_date)
            
            if success:
                st.success(f"âœ… {message}")
                
                # æä¾›ä¸‹è½½
                with open(output_path, 'rb') as f:
                    st.download_button(
                        label="â¬‡ï¸ ä¸‹è½½å¯¼å‡ºæ–‡ä»¶",
                        data=f.read(),
                        file_name=export_filename,
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
            else:
                st.error(f"âŒ {message}")

    
    # ========== Tab 6: æ•°æ®å½•å…¥ ==========
    with tab6:
        st.markdown("### ğŸ“ æ•°æ®å½•å…¥")
        st.info("ğŸ’¡ æ”¯æŒå•æ¡æ•°æ®å½•å…¥å’Œ Excel æ‰¹é‡å¯¼å…¥")
        
        # åˆ›å»ºå­æ ‡ç­¾
        subtab1, subtab2 = st.tabs(["â• å•æ¡å½•å…¥", "ğŸ“„ æ‰¹é‡å¯¼å…¥"])
        
        # ========== å­Tab 1: å•æ¡å½•å…¥ ==========
        with subtab1:
            st.markdown("#### â• å•æ¡æ•°æ®å½•å…¥")
            st.markdown("---")
            
            # å¿…å¡«å­—æ®µ
            col1, col2 = st.columns(2)
            
            with col1:
                input_date = st.date_input(
                    "æ—¥æœŸ *",
                    value=date.today(),
                    help="æ•°æ®é‡‡é›†çš„æ—¥æœŸ"
                )
                input_date_str = input_date.strftime('%Y-%m-%d')
                
                input_repo = st.selectbox(
                    "å¹³å° *",
                    options=list(PLATFORM_NAMES.values()),
                    help="æ¨¡å‹æ‰€åœ¨çš„å¹³å°"
                )
            
            with col2:
                input_model_name = st.text_input(
                    "æ¨¡å‹åç§° *",
                    help="æ¨¡å‹çš„å®Œæ•´åç§°"
                )
                
                input_publisher = st.text_input(
                    "å‘å¸ƒè€… *",
                    help="æ¨¡å‹çš„å‘å¸ƒè€…/ä½œè€…"
                )
            
            input_download_count = st.number_input(
                "ä¸‹è½½é‡ *",
                min_value=0,
                value=0,
                step=1,
                help="æ¨¡å‹çš„ä¸‹è½½æ¬¡æ•°"
            )
            
            st.markdown("---")
            st.markdown("#### å¯é€‰å­—æ®µï¼ˆModel Tree ç›¸å…³ï¼‰")
            
            col3, col4, col5 = st.columns(3)
            
            with col3:
                input_base_model = st.text_input(
                    "åŸºç¡€æ¨¡å‹",
                    help="è¡ç”Ÿæ¨¡å‹çš„åŸºç¡€æ¨¡å‹åç§°"
                )
            
            with col4:
                input_model_type = st.selectbox(
                    "æ¨¡å‹ç±»å‹",
                    options=["", "original", "finetune", "adapter", "lora", "other"],
                    help="æ¨¡å‹çš„ç±»å‹åˆ†ç±»"
                )
            
            with col5:
                input_model_category = st.selectbox(
                    "æ¨¡å‹åˆ†ç±»",
                    options=["", "ernie-4.5", "paddleocr-vl", "other-ernie", "other"],
                    help="æ¨¡å‹çš„ç³»åˆ—åˆ†ç±»"
                )
            
            st.markdown("---")
            
            col_btn1, col_btn2 = st.columns([3, 1])
            
            with col_btn2:
                if st.button("ğŸ’¾ ä¿å­˜æ•°æ®", type="primary", use_container_width=True, key="insert_single"):
                    # è½¬æ¢ç©ºå­—ç¬¦ä¸²ä¸º None
                    base_model = input_base_model if input_base_model else None
                    model_type = input_model_type if input_model_type else None
                    model_category = input_model_category if input_model_category else None
                    
                    with st.spinner("æ­£åœ¨ä¿å­˜æ•°æ®..."):
                        success, message = insert_single_record(
                            date=input_date_str,
                            repo=input_repo,
                            model_name=input_model_name,
                            publisher=input_publisher,
                            download_count=input_download_count,
                            base_model=base_model,
                            model_type=model_type,
                            model_category=model_category
                        )
                    
                    if success:
                        st.success(f"âœ… {message}")
                        st.balloons()
                    else:
                        st.error(f"âŒ {message}")
        
        # ========== å­Tab 2: æ‰¹é‡å¯¼å…¥ ==========
        with subtab2:
            st.markdown("#### ğŸ“„ Excel æ‰¹é‡å¯¼å…¥")
            st.markdown("---")
            
            # è¯´æ˜ä¿¡æ¯
            st.info("""
            ğŸ“‹ **Excel æ–‡ä»¶æ ¼å¼è¦æ±‚ï¼š**
            
            **å¿…éœ€åˆ—**ï¼ˆç¼ºä¸€ä¸å¯ï¼‰ï¼š
            - `date`: æ—¥æœŸï¼ˆæ ¼å¼ï¼šYYYY-MM-DDï¼‰
            - `repo`: å¹³å°åç§°
            - `model_name`: æ¨¡å‹åç§°
            - `publisher`: å‘å¸ƒè€…
            - `download_count`: ä¸‹è½½é‡ï¼ˆæ•°å­—ï¼‰
            
            **å¯é€‰åˆ—**ï¼š
            - `base_model`: åŸºç¡€æ¨¡å‹ï¼ˆç”¨äºè¡ç”Ÿæ¨¡å‹ï¼‰
            - `model_type`: æ¨¡å‹ç±»å‹ï¼ˆoriginal, finetune, adapter, lora, otherï¼‰
            - `model_category`: æ¨¡å‹åˆ†ç±»ï¼ˆernie-4.5, paddleocr-vl, other-ernie, otherï¼‰
            """)
            
            # ä¸‹è½½æ¨¡æ¿
            template_data = {
                'date': ['2025-01-01', '2025-01-01'],
                'repo': ['Hugging Face', 'ModelScope'],
                'model_name': ['ç¤ºä¾‹æ¨¡å‹1', 'ç¤ºä¾‹æ¨¡å‹2'],
                'publisher': ['ç¤ºä¾‹å‘å¸ƒè€…1', 'ç¤ºä¾‹å‘å¸ƒè€…2'],
                'download_count': [1000, 2000],
                'base_model': ['', ''],
                'model_type': ['', ''],
                'model_category': ['', '']
            }
            template_df = pd.DataFrame(template_data)
            
            template_buffer = BytesIO()
            with pd.ExcelWriter(template_buffer, engine='openpyxl') as writer:
                template_df.to_excel(writer, index=False, sheet_name='æ¨¡å‹æ•°æ®')
            
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½ Excel æ¨¡æ¿",
                data=template_buffer.getvalue(),
                file_name="å¯¼å…¥æ¨¡æ¿.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="ä¸‹è½½åŒ…å«ç¤ºä¾‹æ•°æ®çš„ Excel æ¨¡æ¿"
            )
            
            st.markdown("---")
            
            # æ–‡ä»¶ä¸Šä¼ 
            uploaded_file = st.file_uploader(
                "é€‰æ‹© Excel æ–‡ä»¶",
                type=['xlsx', 'xls'],
                help="ä¸Šä¼ åŒ…å«æ¨¡å‹æ•°æ®çš„ Excel æ–‡ä»¶"
            )
            
            if uploaded_file is not None:
                # é¢„è§ˆä¸Šä¼ çš„æ–‡ä»¶
                st.markdown("##### ğŸ“Š æ–‡ä»¶é¢„è§ˆ")
                try:
                    preview_df = pd.read_excel(uploaded_file, engine='openpyxl')
                    st.dataframe(preview_df.head(10), use_container_width=True)
                    st.info(f"æ–‡ä»¶åŒ…å« {len(preview_df)} è¡Œæ•°æ®")
                    
                    # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                    uploaded_file.seek(0)
                except Exception as e:
                    st.error(f"æ— æ³•è¯»å–æ–‡ä»¶: {e}")
                    uploaded_file = None
            
            if uploaded_file is not None:
                st.markdown("---")
                
                # å¯¼å…¥é€‰é¡¹
                col_opt1, col_opt2 = st.columns(2)
                
                with col_opt1:
                    skip_duplicates = st.radio(
                        "é‡åˆ°é‡å¤è®°å½•æ—¶",
                        options=[True, False],
                        format_func=lambda x: "è·³è¿‡ï¼ˆæ¨èï¼‰" if x else "è¦†ç›–",
                        help="é€‰æ‹©å¦‚ä½•å¤„ç†ä¸æ•°æ®åº“ä¸­å·²å­˜åœ¨è®°å½•ç›¸åŒçš„æ•°æ®"
                    )
                
                col_import1, col_import2 = st.columns([3, 1])
                
                with col_import2:
                    if st.button("ğŸ“¤ å¼€å§‹å¯¼å…¥", type="primary", use_container_width=True, key="import_excel"):
                        with st.spinner("æ­£åœ¨å¯¼å…¥æ•°æ®..."):
                            # é‡ç½®æ–‡ä»¶æŒ‡é’ˆ
                            uploaded_file.seek(0)
                            success, message, stats = import_from_excel(uploaded_file, skip_duplicates)
                        
                        if success:
                            st.success("âœ… å¯¼å…¥å®Œæˆï¼")

                            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                            col_stat1, col_stat2, col_stat3, col_stat4 = st.columns(4)

                            with col_stat1:
                                st.metric("æ€»è®°å½•æ•°", stats['total'])

                            with col_stat2:
                                st.metric("æˆåŠŸæ’å…¥", stats['inserted'], delta=stats['inserted'])

                            with col_stat3:
                                st.metric("è·³è¿‡é‡å¤", stats['skipped'])

                            with col_stat4:
                                st.metric("é”™è¯¯è®°å½•", stats['errors'], delta=-stats['errors'] if stats['errors'] > 0 else 0)

                            # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                            with st.expander("ğŸ“‹ è¯¦ç»†ä¿¡æ¯"):
                                st.text(message)

                            if stats['inserted'] > 0:
                                st.balloons()
                        else:
                            st.error(f"âŒ å¯¼å…¥å¤±è´¥")
                            st.error(message)

    # ========== Tab 7: æ•°æ®ç¼–è¾‘ ==========
    with tab7:
        from ernie_tracker.db_manager import search_records, get_record_by_rowid, update_record, delete_record_by_rowid

        st.markdown("### âœï¸ æ•°æ®ç¼–è¾‘")
        st.info("ğŸ’¡ æœç´¢å¹¶ç¼–è¾‘æ•°æ®åº“ä¸­çš„è®°å½•")

        # æœç´¢åŒºåŸŸ
        st.markdown("#### ğŸ” æœç´¢è®°å½•")

        col1, col2, col3, col4 = st.columns(4)

        with col1:
            search_date = st.selectbox(
                "æ—¥æœŸ",
                options=["å…¨éƒ¨"] + (available_dates if available_dates else []),
                key="search_date"
            )

        with col2:
            search_repo = st.selectbox(
                "å¹³å°",
                options=["å…¨éƒ¨"] + list(PLATFORM_NAMES.values()),
                key="search_repo"
            )

        with col3:
            search_model_name = st.text_input(
                "æ¨¡å‹åç§°ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰",
                key="search_model_name"
            )

        with col4:
            search_publisher = st.text_input(
                "å‘å¸ƒè€…ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰",
                key="search_publisher"
            )

        # æœç´¢æŒ‰é’®
        col_search1, col_search2 = st.columns([3, 1])
        with col_search2:
            search_button = st.button("ğŸ” æœç´¢", type="primary", use_container_width=True, key="search_btn")

        # æ‰§è¡Œæœç´¢
        if search_button or 'search_results' in st.session_state:
            # æ„å»ºæœç´¢å‚æ•°
            search_params = {}

            if search_date != "å…¨éƒ¨":
                search_params['date_filter'] = search_date

            if search_repo != "å…¨éƒ¨":
                search_params['repo_filter'] = search_repo

            if search_model_name:
                search_params['model_name_filter'] = search_model_name

            if search_publisher:
                search_params['publisher_filter'] = search_publisher

            # æ‰§è¡Œæœç´¢
            if search_button:
                with st.spinner("æ­£åœ¨æœç´¢..."):
                    results = search_records(**search_params)
                    st.session_state['search_results'] = results
            else:
                results = st.session_state.get('search_results', pd.DataFrame())

            # æ˜¾ç¤ºæœç´¢ç»“æœ
            st.markdown("---")
            st.markdown("#### ğŸ“‹ æœç´¢ç»“æœ")

            if results.empty:
                st.info("æœªæ‰¾åˆ°åŒ¹é…çš„è®°å½•")
            else:
                st.success(f"æ‰¾åˆ° {len(results)} æ¡è®°å½•")

                # æ˜¾ç¤ºæœç´¢ç»“æœè¡¨æ ¼ï¼ˆå¯é€‰æ‹©ï¼‰
                # é€‰æ‹©è¦ç¼–è¾‘çš„è®°å½•
                st.markdown("##### é€‰æ‹©è¦ç¼–è¾‘çš„è®°å½•ï¼š")

                # åˆ›å»ºä¸€ä¸ªæ›´å‹å¥½çš„æ˜¾ç¤ºæ ¼å¼
                display_df = results.copy()
                display_df['é€‰æ‹©'] = False

                # é‡æ–°æ’åˆ—åˆ—é¡ºåºï¼ŒæŠŠ rowid æ”¾åœ¨å‰é¢
                cols = ['rowid', 'date', 'repo', 'model_name', 'publisher', 'download_count']
                optional_cols = ['base_model', 'model_type', 'model_category', 'tags']

                for col in optional_cols:
                    if col in display_df.columns:
                        cols.append(col)

                display_df = display_df[cols]

                # ä½¿ç”¨ data_editor æ˜¾ç¤ºå¯é€‰æ‹©çš„è¡¨æ ¼
                st.dataframe(
                    display_df,
                    use_container_width=True,
                    height=300
                )

                # è¾“å…¥è¦ç¼–è¾‘çš„è®°å½• rowid
                st.markdown("---")
                st.markdown("#### âœï¸ ç¼–è¾‘è®°å½•")

                col_edit1, col_edit2 = st.columns([2, 2])

                with col_edit1:
                    edit_rowid = st.number_input(
                        "è¾“å…¥è¦ç¼–è¾‘çš„è®°å½• rowid",
                        min_value=1,
                        value=int(results.iloc[0]['rowid']) if not results.empty else 1,
                        step=1,
                        key="edit_rowid"
                    )

                with col_edit2:
                    st.write("")
                    st.write("")
                    load_button = st.button("ğŸ“¥ åŠ è½½è®°å½•", use_container_width=True, key="load_record")

                # åŠ è½½è®°å½•è¿›è¡Œç¼–è¾‘
                if load_button or 'editing_record' in st.session_state:
                    if load_button:
                        record = get_record_by_rowid(edit_rowid)
                        if record:
                            st.session_state['editing_record'] = record
                            st.session_state['editing_rowid'] = edit_rowid
                        else:
                            st.error(f"æœªæ‰¾åˆ° rowid={edit_rowid} çš„è®°å½•")
                            if 'editing_record' in st.session_state:
                                del st.session_state['editing_record']

                    if 'editing_record' in st.session_state:
                        record = st.session_state['editing_record']

                        st.markdown(f"##### æ­£åœ¨ç¼–è¾‘ rowid={st.session_state['editing_rowid']} çš„è®°å½•")
                        st.markdown("---")

                        # ç¼–è¾‘è¡¨å•
                        col_form1, col_form2 = st.columns(2)

                        with col_form1:
                            edit_date = st.date_input(
                                "æ—¥æœŸ *",
                                value=pd.to_datetime(record['date']).date() if record['date'] else date.today(),
                                key="edit_date_input"
                            )
                            edit_date_str = edit_date.strftime('%Y-%m-%d')

                            edit_repo = st.selectbox(
                                "å¹³å° *",
                                options=list(PLATFORM_NAMES.values()),
                                index=list(PLATFORM_NAMES.values()).index(record['repo']) if record['repo'] in list(PLATFORM_NAMES.values()) else 0,
                                key="edit_repo_input"
                            )

                            edit_model_name = st.text_input(
                                "æ¨¡å‹åç§° *",
                                value=record['model_name'] or "",
                                key="edit_model_name_input"
                            )

                        with col_form2:
                            edit_publisher = st.text_input(
                                "å‘å¸ƒè€… *",
                                value=record['publisher'] or "",
                                key="edit_publisher_input"
                            )

                            edit_download_count = st.number_input(
                                "ä¸‹è½½é‡ *",
                                min_value=0,
                                value=int(record['download_count']) if record['download_count'] else 0,
                                step=1,
                                key="edit_download_count_input"
                            )

                        st.markdown("##### Model Tree ç›¸å…³å­—æ®µï¼ˆå¯é€‰ï¼‰")

                        col_form3, col_form4, col_form5 = st.columns(3)

                        with col_form3:
                            edit_base_model = st.text_input(
                                "åŸºç¡€æ¨¡å‹",
                                value=record['base_model'] or "",
                                key="edit_base_model_input"
                            )

                        with col_form4:
                            model_type_options = ["", "original", "finetune", "adapter", "lora", "other"]
                            current_type = record['model_type'] or ""
                            edit_model_type = st.selectbox(
                                "æ¨¡å‹ç±»å‹",
                                options=model_type_options,
                                index=model_type_options.index(current_type) if current_type in model_type_options else 0,
                                key="edit_model_type_input"
                            )

                        with col_form5:
                            category_options = ["", "ernie-4.5", "paddleocr-vl", "other-ernie", "other"]
                            current_category = record['model_category'] or ""
                            edit_model_category = st.selectbox(
                                "æ¨¡å‹åˆ†ç±»",
                                options=category_options,
                                index=category_options.index(current_category) if current_category in category_options else 0,
                                key="edit_model_category_input"
                            )

                        edit_tags = st.text_input(
                            "æ ‡ç­¾",
                            value=record['tags'] or "",
                            key="edit_tags_input"
                        )

                        st.markdown("---")

                        # æ“ä½œæŒ‰é’®
                        col_btn1, col_btn2, col_btn3 = st.columns([2, 1, 1])

                        with col_btn2:
                            if st.button("ğŸ’¾ ä¿å­˜æ›´æ”¹", type="primary", use_container_width=True, key="save_edit"):
                                # è½¬æ¢ç©ºå­—ç¬¦ä¸²ä¸º None
                                base_model_value = edit_base_model if edit_base_model else None
                                model_type_value = edit_model_type if edit_model_type else None
                                model_category_value = edit_model_category if edit_model_category else None
                                tags_value = edit_tags if edit_tags else None

                                with st.spinner("æ­£åœ¨ä¿å­˜..."):
                                    success, message = update_record(
                                        rowid=st.session_state['editing_rowid'],
                                        date=edit_date_str,
                                        repo=edit_repo,
                                        model_name=edit_model_name,
                                        publisher=edit_publisher,
                                        download_count=edit_download_count,
                                        base_model=base_model_value,
                                        model_type=model_type_value,
                                        model_category=model_category_value,
                                        tags=tags_value
                                    )

                                if success:
                                    st.success(f"âœ… {message}")
                                    # æ¸…é™¤ç¼–è¾‘çŠ¶æ€
                                    if 'editing_record' in st.session_state:
                                        del st.session_state['editing_record']
                                    if 'editing_rowid' in st.session_state:
                                        del st.session_state['editing_rowid']
                                    # é‡æ–°æœç´¢
                                    results = search_records(**search_params)
                                    st.session_state['search_results'] = results
                                    st.rerun()
                                else:
                                    st.error(f"âŒ {message}")

                        with col_btn3:
                            if st.button("ğŸ—‘ï¸ åˆ é™¤è®°å½•", use_container_width=True, key="delete_edit"):
                                if st.session_state.get("confirm_delete_edit", False):
                                    with st.spinner("æ­£åœ¨åˆ é™¤..."):
                                        success, message = delete_record_by_rowid(st.session_state['editing_rowid'])

                                    if success:
                                        st.success(f"âœ… {message}")
                                        # æ¸…é™¤ç¼–è¾‘çŠ¶æ€
                                        if 'editing_record' in st.session_state:
                                            del st.session_state['editing_record']
                                        if 'editing_rowid' in st.session_state:
                                            del st.session_state['editing_rowid']
                                        st.session_state["confirm_delete_edit"] = False
                                        # é‡æ–°æœç´¢
                                        results = search_records(**search_params)
                                        st.session_state['search_results'] = results
                                        st.rerun()
                                    else:
                                        st.error(f"âŒ {message}")
                                        st.session_state["confirm_delete_edit"] = False
                                else:
                                    st.warning("âš ï¸ ç¡®è®¤åˆ é™¤ï¼Ÿè¯·å†æ¬¡ç‚¹å‡»ç¡®è®¤ï¼")
                                    st.session_state["confirm_delete_edit"] = True


# ================= è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†ææ¨¡å— =================
elif page == "ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€":
    from ernie_tracker.analysis import (
        get_available_dates,
        analyze_derivative_models_all_platforms,
        calculate_periodic_stats,
        get_deleted_derivative_models_all_platforms,
        get_models_needing_backfill
    )
    import plotly.express as px
    import plotly.graph_objects as go
    from io import BytesIO

    st.markdown("## ğŸŒ³ è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†æï¼ˆå…¨å¹³å°ï¼‰")
    st.info("ğŸ“Š åˆ†æå…¨å¹³å°ï¼ˆHugging Faceã€ModelScopeã€AI Studioã€GitCodeã€é²¸æ™ºã€é­”ä¹ã€Giteeï¼‰çš„è¡ç”Ÿæ¨¡å‹ç”Ÿæ€ã€‚è¡ç”Ÿæ¨¡å‹å®šä¹‰ï¼šéå®˜æ–¹å‘å¸ƒè€…å‘å¸ƒçš„æ¨¡å‹ã€‚")

    # è·å–å¯ç”¨æ—¥æœŸ
    available_dates = get_available_dates()

    if not available_dates:
        st.warning("âš ï¸ æ•°æ®åº“ä¸­æš‚æ— æ•°æ®ï¼Œè¯·å…ˆåœ¨ã€Œæ•°æ®æ›´æ–°ã€é¡µé¢æŠ“å–æ•°æ®ã€‚")
    else:
        # é…ç½®é€‰é¡¹
        col_config1, col_config2 = st.columns([2, 2])

        with col_config1:
            # æ—¥æœŸé€‰æ‹©
            selected_date = st.selectbox(
                "ğŸ“… é€‰æ‹©åˆ†ææ—¥æœŸ",
                options=available_dates,
                index=0,
                help="é€‰æ‹©è¦åˆ†æçš„æ•°æ®æ—¥æœŸ"
            )

        with col_config2:
            # æ¨¡å‹ç³»åˆ—ç­›é€‰
            selected_series = st.multiselect(
                "ğŸ¯ æ¨¡å‹ç³»åˆ—ç­›é€‰",
                options=["ERNIE-4.5", "PaddleOCR-VL"],
                default=["ERNIE-4.5", "PaddleOCR-VL"],
                help="å¯ä»¥é€‰æ‹©ä¸€ä¸ªæˆ–å¤šä¸ªæ¨¡å‹ç³»åˆ—è¿›è¡Œåˆ†æ"
            )

        if not selected_series:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªæ¨¡å‹ç³»åˆ—")
            st.stop()

        # æ˜¾ç¤ºç­›é€‰è¯´æ˜
        series_info = "ã€".join(selected_series)
        st.info(f"ğŸ“Š **åˆ†æç³»åˆ—**: {series_info} | **æ•°æ®èŒƒå›´**: æ‰€æœ‰å¹³å° | **è¡ç”Ÿæ¨¡å‹å®šä¹‰**: éå®˜æ–¹å‘å¸ƒè€…å‘å¸ƒçš„æ¨¡å‹")

        if st.button("ğŸ” å¼€å§‹åˆ†æ", type="primary"):
            with st.spinner("æ­£åœ¨åˆ†æè¡ç”Ÿæ¨¡å‹ç”Ÿæ€..."):
                # åŠ è½½æ•°æ®ï¼ˆä½¿ç”¨å›å¡«é€»è¾‘ï¼‰
                df = load_data_from_db(date_filter=selected_date, last_value_per_model=True)

                if df.empty:
                    st.error(f"âŒ {selected_date} æ²¡æœ‰æ•°æ®")
                else:
                    st.success(f"âœ… åŠ è½½äº† {len(df)} æ¡è®°å½•")

                    # ä½¿ç”¨æ–°çš„åˆ†æå‡½æ•°
                    analysis_result = analyze_derivative_models_all_platforms(df, selected_series=selected_series)

                    if analysis_result['total_models'] == 0:
                        st.warning(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆé€‰æ‹©çš„æ¨¡å‹ç³»åˆ—ï¼ˆ{series_info}ï¼‰çš„æ•°æ®")
                        st.stop()

                    st.success(f"âœ… åˆ†æå®Œæˆï¼åˆ†ææ—¥æœŸï¼š{selected_date}")

                    # ========== 1. æ€»ä½“æ¦‚è§ˆ ==========
                    st.markdown("### ğŸ“Š æ€»ä½“æ¦‚è§ˆ")

                    col1, col2, col3 = st.columns(3)

                    with col1:
                        st.metric("æ€»æ¨¡å‹æ•°", f"{analysis_result['total_models']:,}")

                    with col2:
                        st.metric("è¡ç”Ÿæ¨¡å‹æ•°", f"{analysis_result['total_derivative_models']:,}")

                    with col3:
                        st.metric("è¡ç”Ÿç‡", f"{analysis_result['derivative_rate']:.1f}%")

                    st.markdown("---")

                    # ========== 2. å‘¨æœŸæ€§ç»Ÿè®¡ï¼ˆæœ¬å‘¨æ–°å¢ã€å½“å‰å­£åº¦æ–°å¢ï¼‰ ==========
                    st.markdown("### ğŸ“… å‘¨æœŸæ€§ç»Ÿè®¡")

                    with st.spinner("æ­£åœ¨è®¡ç®—å‘¨æœŸæ€§ç»Ÿè®¡å’Œæ£€æµ‹åˆ é™¤æ¨¡å‹..."):
                        # å…ˆè·å–å·²åˆ é™¤æ¨¡å‹åˆ—è¡¨ï¼Œç”¨äºç»Ÿè®¡
                        deleted_models = get_deleted_derivative_models_all_platforms(
                            selected_date,
                            selected_series=selected_series
                        )

                        # æŒ‰ç³»åˆ—ç»Ÿè®¡å·²åˆ é™¤æ¨¡å‹æ•°é‡
                        deleted_by_category = {}
                        for model in deleted_models:
                            cat = model.get('model_category', '')
                            deleted_by_category[cat] = deleted_by_category.get(cat, 0) + 1

                        # è®¡ç®—å‘¨æœŸæ€§ç»Ÿè®¡
                        periodic_stats = calculate_periodic_stats(selected_date, selected_series=selected_series)

                        if periodic_stats:
                            # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡æ‘˜è¦
                            total_deleted = len(deleted_models)
                            current_available = periodic_stats['total_count'] - total_deleted

                            if total_deleted > 0:
                                summary_text = f"""
                                **æˆªæ­¢ {selected_date}**ï¼Œç´¯è®¡å‡ºç°è¿‡è¡ç”Ÿæ¨¡å‹ **{periodic_stats['total_count']:,}** ä¸ªï¼ˆå½“å‰å¯ç”¨ **{current_available:,}** ä¸ªï¼Œå·²åˆ é™¤ **{total_deleted:,}** ä¸ªï¼‰ï¼Œ
                                æœ¬å‘¨æ–°å¢ **{periodic_stats['weekly_new_count']:,}** ä¸ªï¼Œ
                                {periodic_stats['quarter_name']} æ–°å¢ **{periodic_stats['quarter_new_count']:,}** ä¸ª
                                """
                            else:
                                summary_text = f"""
                                **æˆªæ­¢ {selected_date}**ï¼Œç´¯è®¡è¡ç”Ÿæ¨¡å‹ **{periodic_stats['total_count']:,}** ä¸ªï¼Œ
                                æœ¬å‘¨æ–°å¢ **{periodic_stats['weekly_new_count']:,}** ä¸ªï¼Œ
                                {periodic_stats['quarter_name']} æ–°å¢ **{periodic_stats['quarter_new_count']:,}** ä¸ª
                                """

                            st.markdown(summary_text)

                            # æŒ‰ç³»åˆ—è¯¦ç»†ç»Ÿè®¡
                            if periodic_stats['stats_by_series']:
                                st.markdown("#### ğŸ“Š åˆ†ç³»åˆ—ç»Ÿè®¡")
                                for category, stats in periodic_stats['stats_by_series'].items():
                                    deleted_count = deleted_by_category.get(category, 0)
                                    available_count = stats['total_count'] - deleted_count

                                    if deleted_count > 0:
                                        detail_text = f"ï¼ˆå½“å‰å¯ç”¨ **{available_count:,}** ä¸ªï¼Œå·²åˆ é™¤ **{deleted_count:,}** ä¸ªï¼‰"
                                    else:
                                        detail_text = ""

                                    st.markdown(f"""
                                    - **{category}** è¡ç”Ÿæ¨¡å‹ç´¯è®¡ **{stats['total_count']:,}** ä¸ª{detail_text}ï¼Œ
                                      æœ¬å‘¨æ–°å¢ **{stats['weekly_new_count']:,}** ä¸ªï¼Œ
                                      {periodic_stats['quarter_name']} æ–°å¢ **{stats['quarter_new_count']:,}** ä¸ª
                                    """)

                            # æœ¬å‘¨æ–°å¢æ¨¡å‹åˆ—è¡¨
                            if periodic_stats['weekly_new_models']:
                                with st.expander(f"ğŸ“‹ æœ¬å‘¨æ–°å¢æ¨¡å‹åˆ—è¡¨ ({periodic_stats['weekly_new_count']} ä¸ª)", expanded=False):
                                    weekly_new_df = pd.DataFrame(periodic_stats['weekly_new_models'])
                                    weekly_new_df['download_count'] = pd.to_numeric(
                                        weekly_new_df['download_count'], errors='coerce'
                                    ).fillna(0).astype(int)
                                    weekly_new_df = weekly_new_df.sort_values('download_count', ascending=False)

                                    # é€‰æ‹©è¦æ˜¾ç¤ºçš„åˆ—
                                    weekly_display_cols = ['model_name', 'publisher', 'repo', 'download_count']
                                    if 'model_category' in weekly_new_df.columns:
                                        weekly_display_cols.append('model_category')
                                    if 'model_type' in weekly_new_df.columns:
                                        weekly_display_cols.append('model_type')
                                    if 'base_model' in weekly_new_df.columns:
                                        weekly_display_cols.append('base_model')
                                    if 'url' in weekly_new_df.columns:
                                        weekly_display_cols.append('url')

                                    # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
                                    weekly_display_cols = [col for col in weekly_display_cols if col in weekly_new_df.columns]

                                    # é‡å‘½ååˆ—ä»¥ä¾¿æ›´å¥½åœ°æ˜¾ç¤º
                                    rename_dict = {
                                        'model_name': 'æ¨¡å‹åç§°',
                                        'publisher': 'å‘å¸ƒè€…',
                                        'repo': 'å¹³å°',
                                        'download_count': 'ä¸‹è½½é‡',
                                        'model_category': 'æ¨¡å‹ç³»åˆ—',
                                        'model_type': 'æ¨¡å‹ç±»å‹',
                                        'base_model': 'Base Model',
                                        'url': 'æ¨¡å‹URL'
                                    }
                                    display_df = weekly_new_df[weekly_display_cols].copy()
                                    display_df = display_df.rename(columns=rename_dict)

                                    st.dataframe(display_df, use_container_width=True, height=300)
                            else:
                                st.info("âœ… æœ¬å‘¨æš‚æ— æ–°å¢è¡ç”Ÿæ¨¡å‹")

                    st.markdown("---")

                    # ========== 3. å·²åˆ é™¤æ¨¡å‹æ£€æµ‹ ==========
                    st.markdown("### ğŸ—‘ï¸ å·²åˆ é™¤æ¨¡å‹")

                    # ä½¿ç”¨ä¹‹å‰å·²ç»è·å–çš„ deleted_models
                    if deleted_models:
                        st.warning(f"âš ï¸ æ£€æµ‹åˆ° {len(deleted_models)} ä¸ªæ¨¡å‹å·²è¢«åˆ é™¤æˆ–éšè—")
                        with st.expander(f"ğŸ“‹ å·²åˆ é™¤æ¨¡å‹åˆ—è¡¨ ({len(deleted_models)} ä¸ª)", expanded=False):
                            deleted_df = pd.DataFrame(deleted_models)
                            deleted_df['last_download_count'] = pd.to_numeric(
                                deleted_df['last_download_count'], errors='coerce'
                            ).fillna(0).astype(int)
                            st.dataframe(deleted_df, use_container_width=True, height=300)
                    else:
                        st.success("âœ… æœªæ£€æµ‹åˆ°å·²åˆ é™¤çš„æ¨¡å‹")

                    st.markdown("---")

                    # ========== 4. éœ€è¦å›å¡«çš„æ¨¡å‹ ==========
                    st.markdown("### ğŸ”„ éœ€è¦å›å¡«çš„æ¨¡å‹")

                    with st.spinner("æ­£åœ¨æ£€æµ‹éœ€è¦å›å¡«çš„æ¨¡å‹..."):
                        models_needing_backfill = get_models_needing_backfill(
                            selected_date,
                            selected_series=selected_series
                        )

                        if models_needing_backfill:
                            st.info(f"ğŸ“Š æ£€æµ‹åˆ° {len(models_needing_backfill)} ä¸ªæ¨¡å‹çš„å½“å‰ä¸‹è½½é‡ä½äºå†å²æœ€å¤§å€¼")
                            with st.expander(f"ğŸ“‹ éœ€è¦å›å¡«çš„æ¨¡å‹åˆ—è¡¨ ({len(models_needing_backfill)} ä¸ª)", expanded=False):
                                backfill_df = pd.DataFrame(models_needing_backfill)
                                backfill_df['å·®å€¼'] = backfill_df['max_download_count'] - backfill_df['current_download_count']
                                backfill_df = backfill_df.rename(columns={
                                    'model_name': 'æ¨¡å‹åç§°',
                                    'publisher': 'å‘å¸ƒè€…',
                                    'model_category': 'æ¨¡å‹ç³»åˆ—',
                                    'repo': 'å¹³å°',
                                    'current_download_count': 'å½“å‰ä¸‹è½½é‡',
                                    'max_download_count': 'å†å²æœ€å¤§ä¸‹è½½é‡',
                                    'max_download_date': 'æœ€å¤§ä¸‹è½½é‡æ—¥æœŸ'
                                })
                                st.dataframe(backfill_df, use_container_width=True, height=300)
                        else:
                            st.success("âœ… æ‰€æœ‰æ¨¡å‹çš„ä¸‹è½½é‡å‡ä¸ºå†å²æœ€å¤§å€¼ï¼Œæ— éœ€å›å¡«")

                    st.markdown("---")

                    # ========== 5. æŒ‰å¹³å°ç»Ÿè®¡ ==========
                    st.markdown("### ğŸŒ æŒ‰å¹³å°ç»Ÿè®¡")

                    if analysis_result['by_platform']:
                        # åˆ›å»ºå¹³å°ç»Ÿè®¡è¡¨æ ¼
                        platform_data = []

                        # åˆ¤æ–­æ˜¯å¦é€‰æ‹©äº†å¤šä¸ªç³»åˆ—
                        is_multi_series = len(selected_series) > 1

                        for platform, stats in analysis_result['by_platform'].items():
                            row_data = {
                                'å¹³å°': platform,
                                'è¡ç”Ÿæ¨¡å‹æ€»æ•°': stats['derivative_models'],
                                'è¡ç”Ÿæ¨¡å‹æ€»ä¸‹è½½é‡': f"{stats['total_downloads']:,}"
                            }

                            # å¦‚æœé€‰æ‹©äº†å¤šä¸ªç³»åˆ—ï¼Œæ·»åŠ åˆ†ç³»åˆ—ç»Ÿè®¡
                            if is_multi_series and 'by_series' in stats and stats['by_series']:
                                series_mapping = {
                                    "ernie-4.5": "ERNIE-4.5",
                                    "paddleocr-vl": "PaddleOCR-VL",
                                    "other-ernie": "å…¶ä»–ERNIE"
                                }

                                for category, category_stats in stats['by_series'].items():
                                    display_name = series_mapping.get(category, category)
                                    row_data[f'{display_name}è¡ç”Ÿæ¨¡å‹æ•°'] = category_stats['count']
                                    row_data[f'{display_name}è¡ç”Ÿæ¨¡å‹ä¸‹è½½é‡'] = f"{category_stats['downloads']:,}"

                            platform_data.append(row_data)

                        platform_df = pd.DataFrame(platform_data)

                        # æ’åºåˆ—ï¼šä¼˜å…ˆæŒ‰è¡ç”Ÿæ¨¡å‹æ€»æ•°æ’åº
                        if is_multi_series:
                            platform_df = platform_df.sort_values('è¡ç”Ÿæ¨¡å‹æ€»æ•°', ascending=False)
                        else:
                            # å•ç³»åˆ—æ—¶ä¿æŒåŸæœ‰æ’åºé€»è¾‘
                            platform_df = platform_df.sort_values('è¡ç”Ÿæ¨¡å‹æ€»æ•°', ascending=False)

                        # å±•ç¤ºè¡¨æ ¼
                        st.dataframe(platform_df, use_container_width=True, height=300)

                        # å¯è§†åŒ–ï¼šè¡ç”Ÿæ¨¡å‹æ•°é‡å¯¹æ¯”
                        col_chart1, col_chart2 = st.columns(2)

                        with col_chart1:
                            fig_platform = px.bar(
                                platform_df,
                                x='å¹³å°',
                                y='è¡ç”Ÿæ¨¡å‹æ€»æ•°',
                                title="å„å¹³å°è¡ç”Ÿæ¨¡å‹æ•°é‡",
                                text='è¡ç”Ÿæ¨¡å‹æ€»æ•°'
                            )
                            fig_platform.update_traces(texttemplate='%{text}', textposition='outside')
                            fig_platform.update_layout(showlegend=False)
                            st.plotly_chart(fig_platform, use_container_width=True)

                        with col_chart2:
                            # é‡æ–°è®¡ç®—è¡ç”Ÿç‡æ•°æ®
                            rate_data = []
                            for platform, stats in analysis_result['by_platform'].items():
                                rate_data.append({
                                    'å¹³å°': platform,
                                    'è¡ç”Ÿç‡': stats['derivative_rate']
                                })

                            rate_df = pd.DataFrame(rate_data)

                            fig_rate = px.bar(
                                rate_df,
                                x='å¹³å°',
                                y='è¡ç”Ÿç‡',
                                title="å„å¹³å°è¡ç”Ÿç‡",
                                labels={'y': 'è¡ç”Ÿç‡ (%)'},
                                text=rate_df['è¡ç”Ÿç‡'].apply(lambda x: f'{x:.1f}%')
                            )
                            fig_rate.update_traces(texttemplate='%{text}', textposition='outside')
                            fig_rate.update_layout(showlegend=False)
                            st.plotly_chart(fig_rate, use_container_width=True)

                        # ========== 6. å„å¹³å°Topæ¨¡å‹ ==========
                        st.markdown("### ğŸ† å„å¹³å°ä¸‹è½½é‡Topæ¨¡å‹")

                        for platform, stats in analysis_result['by_platform'].items():
                            if stats['derivative_models'] > 0 and stats['top_models']:
                                with st.expander(f"ğŸ“Š {platform} (è¡ç”Ÿæ¨¡å‹: {stats['derivative_models']} ä¸ª)", expanded=False):
                                    top_models_df = pd.DataFrame(stats['top_models'])
                                    if not top_models_df.empty:
                                        top_models_df['download_count'] = pd.to_numeric(
                                            top_models_df['download_count'], errors='coerce'
                                        ).fillna(0).astype(int)
                                        st.dataframe(top_models_df, use_container_width=True)
                                    else:
                                        st.info("æš‚æ— æ•°æ®")

                    st.markdown("---")

                    # ========== 7. æŒ‰ç³»åˆ—ç»Ÿè®¡ ==========
                    if analysis_result['by_series']:
                        st.markdown("### ğŸ“ˆ æŒ‰æ¨¡å‹ç³»åˆ—ç»Ÿè®¡")

                        series_data = []
                        for series, stats in analysis_result['by_series'].items():
                            series_data.append({
                                'æ¨¡å‹ç³»åˆ—': series,
                                'æ€»æ¨¡å‹æ•°': stats['total_models'],
                                'å®˜æ–¹æ¨¡å‹': stats['official_models'],
                                'è¡ç”Ÿæ¨¡å‹': stats['derivative_models'],
                                'è¡ç”Ÿç‡': f"{stats['derivative_rate']:.1f}%"
                            })

                        series_df = pd.DataFrame(series_data)
                        st.dataframe(series_df, use_container_width=True)

                        st.markdown("---")

                    # ========== 8. è¡ç”Ÿæ¨¡å‹è¯¦ç»†åˆ—è¡¨ ==========
                    st.markdown("### ğŸ“‹ è¡ç”Ÿæ¨¡å‹è¯¦ç»†åˆ—è¡¨")

                    derivative_models_df = analysis_result['derivative_models_df']

                    if not derivative_models_df.empty:
                        # ç­›é€‰å™¨
                        col_filter1, col_filter2 = st.columns(2)

                        with col_filter1:
                            platform_options = ['å…¨éƒ¨'] + sorted(derivative_models_df['repo'].unique().tolist())
                            selected_platform = st.selectbox("ç­›é€‰å¹³å°", platform_options, key="filter_platform")

                        with col_filter2:
                            if 'model_category' in derivative_models_df.columns:
                                category_options = ['å…¨éƒ¨'] + sorted(
                                    derivative_models_df['model_category'].dropna().unique().tolist()
                                )
                                selected_category = st.selectbox("ç­›é€‰æ¨¡å‹ç³»åˆ—", category_options, key="filter_category")
                            else:
                                selected_category = 'å…¨éƒ¨'

                        # åº”ç”¨ç­›é€‰
                        filtered_derivatives = derivative_models_df.copy()

                        if selected_platform != 'å…¨éƒ¨':
                            filtered_derivatives = filtered_derivatives[
                                filtered_derivatives['repo'] == selected_platform
                            ]

                        if selected_category != 'å…¨éƒ¨' and 'model_category' in filtered_derivatives.columns:
                            filtered_derivatives = filtered_derivatives[
                                filtered_derivatives['model_category'] == selected_category
                            ]

                        st.info(f"ğŸ“Š å…± {len(filtered_derivatives)} ä¸ªè¡ç”Ÿæ¨¡å‹ç¬¦åˆç­›é€‰æ¡ä»¶")

                        # ä»æ•°æ®åº“è·å–æ¯ä¸ªæ¨¡å‹çš„é¦–æ¬¡å…¥åº“æ—¥æœŸï¼ˆä½¿ç”¨åŸå§‹æ•°æ®ï¼Œä¸æ˜¯å›å¡«åçš„ï¼‰
                        from ernie_tracker.db import DB_PATH, DATA_TABLE
                        import sqlite3

                        # è·å–å½“å‰ç­›é€‰ç»“æœä¸­çš„æ¨¡å‹å”¯ä¸€æ ‡è¯†
                        if not filtered_derivatives.empty:
                            model_keys = filtered_derivatives[['repo', 'publisher', 'model_name']].drop_duplicates()

                            # æ„å»º SQL æŸ¥è¯¢ï¼Œè·å–æ¯ä¸ªæ¨¡å‹é¦–æ¬¡å‡ºç°çš„æ—¥æœŸ
                            first_seen_dates = {}
                            conn = sqlite3.connect(DB_PATH)
                            for _, row in model_keys.iterrows():
                                repo = row['repo']
                                publisher = row['publisher']
                                model_name = row['model_name']

                                # æŸ¥è¯¢è¯¥æ¨¡å‹åœ¨æ•°æ®åº“ä¸­æœ€æ—©å‡ºç°çš„æ—¥æœŸ
                                query = f"""
                                SELECT MIN(date) as first_date
                                FROM {DATA_TABLE}
                                WHERE repo = ? AND publisher = ? AND model_name = ?
                                """
                                cursor = conn.execute(query, (repo, publisher, model_name))
                                result = cursor.fetchone()
                                if result and result[0]:
                                    first_seen_dates[(repo, publisher, model_name)] = result[0]
                            conn.close()

                            # æ·»åŠ é¦–æ¬¡å…¥åº“æ—¥æœŸåˆ—
                            filtered_derivatives['first_seen_date'] = filtered_derivatives.apply(
                                lambda row: first_seen_dates.get((row['repo'], row['publisher'], row['model_name']), ''),
                                axis=1
                            )

                        # å®šä¹‰æ˜¾ç¤ºå­—æ®µï¼ˆç§»é™¤å¤§é‡ç¼ºå¤±çš„å­—æ®µï¼‰
                        all_possible_cols = [
                            'model_name', 'publisher', 'repo', 'download_count',
                            'model_category', 'model_type', 'base_model',
                            'data_source', 'url', 'first_seen_date'
                        ]

                        # åªæ˜¾ç¤ºå­˜åœ¨çš„åˆ—
                        display_cols = [col for col in all_possible_cols if col in filtered_derivatives.columns]

                        # è½¬æ¢ä¸‹è½½é‡ä¸ºæ•°å€¼ç±»å‹ç”¨äºæ’åº
                        filtered_derivatives['download_count_num'] = pd.to_numeric(
                            filtered_derivatives['download_count'], errors='coerce'
                        ).fillna(0)

                        # æŒ‰ä¸‹è½½é‡é™åºæ’åºï¼Œæ˜¾ç¤ºæ‰€æœ‰å­—æ®µ
                        display_df = filtered_derivatives.sort_values('download_count_num', ascending=False)[display_cols].reset_index(drop=True)

                        # æ˜¾ç¤ºæ‰€æœ‰æ¨¡å‹
                        st.dataframe(display_df, use_container_width=True, height=500)

                        # å¯¼å‡ºåŠŸèƒ½
                        st.markdown("### ğŸ“¥ å¯¼å‡ºæŠ¥å‘Š")

                        if st.button("ç”ŸæˆExcelæŠ¥å‘Š", type="secondary"):
                            from openpyxl import Workbook
                            output = BytesIO()

                            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                                # Sheet 1: æ€»ä½“æ¦‚è§ˆ
                                overview_data = {
                                    'æŒ‡æ ‡': ['æ€»æ¨¡å‹æ•°', 'è¡ç”Ÿæ¨¡å‹æ•°', 'å®˜æ–¹æ¨¡å‹æ•°', 'è¡ç”Ÿç‡'],
                                    'æ•°å€¼': [
                                        analysis_result['total_models'],
                                        analysis_result['total_derivative_models'],
                                        analysis_result['total_official_models'],
                                        f"{analysis_result['derivative_rate']:.1f}%"
                                    ]
                                }
                                pd.DataFrame(overview_data).to_excel(writer, sheet_name='æ€»ä½“æ¦‚è§ˆ', index=False)

                                # Sheet 2: å¹³å°ç»Ÿè®¡
                                platform_df.to_excel(writer, sheet_name='å¹³å°ç»Ÿè®¡', index=False)

                                # Sheet 3: ç³»åˆ—ç»Ÿè®¡
                                if analysis_result['by_series']:
                                    series_df.to_excel(writer, sheet_name='ç³»åˆ—ç»Ÿè®¡', index=False)

                                # Sheet 4: è¡ç”Ÿæ¨¡å‹åˆ—è¡¨ï¼ˆå¯¼å‡ºå½“å‰ç­›é€‰ç»“æœï¼ŒåŒ…å«æ‰€æœ‰å­—æ®µï¼‰
                                export_df = display_df.copy()
                                # ç§»é™¤ä¸´æ—¶æ’åºåˆ—
                                if 'download_count_num' in export_df.columns:
                                    export_df = export_df.drop(columns=['download_count_num'])
                                export_df.to_excel(writer, sheet_name='è¡ç”Ÿæ¨¡å‹åˆ—è¡¨', index=False)

                            excel_data = output.getvalue()

                            st.download_button(
                                label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Š",
                                data=excel_data,
                                file_name=f"è¡ç”Ÿæ¨¡å‹ç”Ÿæ€åˆ†æ_{selected_date}.xlsx",
                                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                use_container_width=True
                            )
                    else:
                        st.info("è¯¥æ—¥æœŸæ²¡æœ‰è¡ç”Ÿæ¨¡å‹æ•°æ®")
